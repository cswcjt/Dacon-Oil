{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "18LDMcZEAlxwxLfSImd30e_G6l9jgOJ1b",
      "authorship_tag": "ABX9TyNm/4rwVxzaB7btZM7fhyu/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjooki/Dacon-Oil/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ho5iula1EwoD"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA # 차원축소\n",
        "\n",
        "from imblearn.under_sampling import * # 임벨런스\n",
        "from imblearn.over_sampling import * # 임벨런스\n",
        "from imblearn.combine import * # 임벨런스\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/dacon/oil"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_krJFTRE2xw",
        "outputId": "75da9d9b-dbf9-47e0-b52d-28db1cc60d1c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/dacon/oil\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcE_9l5iF3NX",
        "outputId": "bd7502cb-c240-4752-c5eb-a8043deaab7a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/dacon/oil\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JcNVrzGGB5Z",
        "outputId": "e659202e-9e07-40a5-f0c8-634986fce434"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.0.3-py3-none-any.whl (348 kB)\n",
            "\u001b[K     |████████████████████████████████| 348 kB 14.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.44)\n",
            "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.1)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: importlib-metadata<5.0.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (4.13.0)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.9.0-py3-none-any.whl (23 kB)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 12.5 MB/s \n",
            "\u001b[?25hCollecting alembic>=1.5.0\n",
            "  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 73.9 MB/s \n",
            "\u001b[?25hCollecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (5.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 54.3 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.2-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.8 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 74.6 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.0)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=9e867ba9f708e311a44e82a0863574752ba78f066552e157f2ea08ea2317259e\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.8.1 autopage-0.5.1 cliff-3.10.1 cmaes-0.9.0 cmd2-2.4.2 colorlog-6.7.0 optuna-3.0.3 pbr-5.11.0 pyperclip-1.8.2 stevedore-3.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from jtlearn import Preprocessing\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "ofZIUq5JF3_g"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/drive/MyDrive/dacon/oil/'\n",
        "load_path = base_path + 'data/'\n",
        "save_path = base_path + 'submission/'\n",
        "\n",
        "train = pd.read_csv(load_path + 'train.csv')\n",
        "test = pd.read_csv(load_path + 'test.csv')\n",
        "submission = pd.read_csv(load_path + 'sample_submission.csv')"
      ],
      "metadata": {
        "id": "SoMLvScsF7Rp"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "\n",
        "train = train.fillna(0)\n",
        "\n",
        "X = train.drop(columns=[\"ID\", \"Y_LABEL\"])\n",
        "y = train[\"Y_LABEL\"]\n",
        "test = test.drop(columns=['ID'])\n",
        "\n",
        "train_num_cols = X.drop(columns=['COMPONENT_ARBITRARY']).columns.tolist()\n",
        "test_num_cols = test.drop(columns=['COMPONENT_ARBITRARY']).columns.tolist()\n",
        "\n",
        "ss = StandardScaler()\n",
        "ss2 = StandardScaler()\n",
        "\n",
        "ss2.fit(X[test_num_cols])\n",
        "X[train_num_cols] = ss.fit_transform(X[train_num_cols])\n",
        "test[test_num_cols] = ss2.transform(test[test_num_cols])\n",
        "\n",
        "X.COMPONENT_ARBITRARY = X.COMPONENT_ARBITRARY.map({\"COMPONENT1\" : 1, \"COMPONENT2\" : 2, \"COMPONENT3\" : 3, \"COMPONENT4\" : 4})\n",
        "test.COMPONENT_ARBITRARY = test.COMPONENT_ARBITRARY.map({\"COMPONENT1\" : 1, \"COMPONENT2\" : 2, \"COMPONENT3\" : 3, \"COMPONENT4\" : 4})"
      ],
      "metadata": {
        "id": "FG7Gc3wlKFW8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "S3KnDys9sW8E",
        "outputId": "5caa334c-8e82-4fe0-fae3-7ed4a4f54b54"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       COMPONENT_ARBITRARY  ANONYMOUS_1      YEAR  SAMPLE_TRANSFER_DAY  \\\n",
              "0                        3    -0.393763 -0.669043            -0.051413   \n",
              "1                        2    -0.426022  1.853268             3.715319   \n",
              "2                        2    -0.173409  0.339881            -0.479451   \n",
              "3                        3     1.006399 -0.921274            -0.479451   \n",
              "4                        3     0.191634  0.339881            -0.308236   \n",
              "...                    ...          ...       ...                  ...   \n",
              "14090                    3    -0.362928  0.087650             0.034194   \n",
              "14091                    1    -0.085884 -0.164581            -0.479451   \n",
              "14092                    3    -0.322130 -1.425737             0.119802   \n",
              "14093                    2    -0.153722 -1.173506             0.975877   \n",
              "14094                    2    -0.295090 -0.416812             0.633447   \n",
              "\n",
              "       ANONYMOUS_2        AG        AL         B        BA        BE  ...  \\\n",
              "0        -0.340760 -0.150214 -0.111628  0.281646 -0.238453 -0.041491  ...   \n",
              "1        -0.022576 -0.150214 -0.123127 -0.437686 -0.238453 -0.041491  ...   \n",
              "2        -0.340760 -0.150214  1.118753 -0.612659  0.105735 -0.041491  ...   \n",
              "3        -0.340760 -0.150214 -0.054133 -0.593217 -0.238453 -0.041491  ...   \n",
              "4        -0.340760 -0.150214 -0.134626  0.903771 -0.238453 -0.041491  ...   \n",
              "...            ...       ...       ...       ...       ...       ...  ...   \n",
              "14090    -0.340760 -0.150214 -0.123127  1.331482  0.105735 -0.041491  ...   \n",
              "14091    -0.340760 -0.150214 -0.111628  0.203880 -0.238453 -0.041491  ...   \n",
              "14092     0.295608 -0.150214 -0.077131 -0.622379  0.105735 -0.041491  ...   \n",
              "14093     0.295608 -0.150214 -0.123127 -0.583497 -0.238453 -0.041491  ...   \n",
              "14094    -0.340760 -0.150214 -0.146124  0.126115 -0.238453 -0.041491  ...   \n",
              "\n",
              "            U50        U25        U20        U14         U6         U4  \\\n",
              "0     -0.067643  -0.119657  -0.118804  -0.129231  -0.130716  -0.171264   \n",
              "1     -0.001086  -0.070899  -0.067218  -0.107725  -0.096483  -0.085911   \n",
              "2     -0.067643  -0.119657  -0.080114   0.010557   1.654031   2.240286   \n",
              "3     -0.067643  -0.119657  -0.118804  -0.129231  -0.130716  -0.171264   \n",
              "4     -0.067643  -0.119657  -0.118804  -0.129231  -0.130716  -0.171264   \n",
              "...         ...        ...        ...        ...        ...        ...   \n",
              "14090 -0.067643  -0.119657  -0.118804  -0.129231  -0.130716  -0.171264   \n",
              "14091 -0.067643  -0.119657  -0.118804  -0.129231  -0.130716  -0.171264   \n",
              "14092 -0.067643  -0.119657  -0.118804  -0.129231  -0.130716  -0.171264   \n",
              "14093 -0.067643   0.050996  -0.015631   0.229201   0.126829   0.937623   \n",
              "14094 -0.067643  28.233039  32.961259  40.359205  28.558378  18.955304   \n",
              "\n",
              "             V      V100       V40        ZN  \n",
              "0     -0.10655 -0.596701  0.899892 -0.966002  \n",
              "1     -0.10655 -0.596701 -1.317376  0.119147  \n",
              "2     -0.10655 -0.596701 -0.740886 -0.332215  \n",
              "3     -0.10655 -0.596701  0.482642 -1.093888  \n",
              "4     -0.10655 -0.596701  0.478611 -0.866326  \n",
              "...        ...       ...       ...       ...  \n",
              "14090 -0.10655 -0.596701  0.524972 -1.076961  \n",
              "14091 -0.10655  1.815431  0.164162  1.540935  \n",
              "14092 -0.10655 -0.596701 -1.115806  1.339703  \n",
              "14093 -0.10655 -0.596701 -1.311328  0.119147  \n",
              "14094 -0.10655 -0.596701 -1.256905  0.043920  \n",
              "\n",
              "[14095 rows x 52 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-69aaf4c2-d587-48b0-a1a5-ce54b3cb34c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COMPONENT_ARBITRARY</th>\n",
              "      <th>ANONYMOUS_1</th>\n",
              "      <th>YEAR</th>\n",
              "      <th>SAMPLE_TRANSFER_DAY</th>\n",
              "      <th>ANONYMOUS_2</th>\n",
              "      <th>AG</th>\n",
              "      <th>AL</th>\n",
              "      <th>B</th>\n",
              "      <th>BA</th>\n",
              "      <th>BE</th>\n",
              "      <th>...</th>\n",
              "      <th>U50</th>\n",
              "      <th>U25</th>\n",
              "      <th>U20</th>\n",
              "      <th>U14</th>\n",
              "      <th>U6</th>\n",
              "      <th>U4</th>\n",
              "      <th>V</th>\n",
              "      <th>V100</th>\n",
              "      <th>V40</th>\n",
              "      <th>ZN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.393763</td>\n",
              "      <td>-0.669043</td>\n",
              "      <td>-0.051413</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.111628</td>\n",
              "      <td>0.281646</td>\n",
              "      <td>-0.238453</td>\n",
              "      <td>-0.041491</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.067643</td>\n",
              "      <td>-0.119657</td>\n",
              "      <td>-0.118804</td>\n",
              "      <td>-0.129231</td>\n",
              "      <td>-0.130716</td>\n",
              "      <td>-0.171264</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>-0.596701</td>\n",
              "      <td>0.899892</td>\n",
              "      <td>-0.966002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.426022</td>\n",
              "      <td>1.853268</td>\n",
              "      <td>3.715319</td>\n",
              "      <td>-0.022576</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.123127</td>\n",
              "      <td>-0.437686</td>\n",
              "      <td>-0.238453</td>\n",
              "      <td>-0.041491</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001086</td>\n",
              "      <td>-0.070899</td>\n",
              "      <td>-0.067218</td>\n",
              "      <td>-0.107725</td>\n",
              "      <td>-0.096483</td>\n",
              "      <td>-0.085911</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>-0.596701</td>\n",
              "      <td>-1.317376</td>\n",
              "      <td>0.119147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.173409</td>\n",
              "      <td>0.339881</td>\n",
              "      <td>-0.479451</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>1.118753</td>\n",
              "      <td>-0.612659</td>\n",
              "      <td>0.105735</td>\n",
              "      <td>-0.041491</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.067643</td>\n",
              "      <td>-0.119657</td>\n",
              "      <td>-0.080114</td>\n",
              "      <td>0.010557</td>\n",
              "      <td>1.654031</td>\n",
              "      <td>2.240286</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>-0.596701</td>\n",
              "      <td>-0.740886</td>\n",
              "      <td>-0.332215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1.006399</td>\n",
              "      <td>-0.921274</td>\n",
              "      <td>-0.479451</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.054133</td>\n",
              "      <td>-0.593217</td>\n",
              "      <td>-0.238453</td>\n",
              "      <td>-0.041491</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.067643</td>\n",
              "      <td>-0.119657</td>\n",
              "      <td>-0.118804</td>\n",
              "      <td>-0.129231</td>\n",
              "      <td>-0.130716</td>\n",
              "      <td>-0.171264</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>-0.596701</td>\n",
              "      <td>0.482642</td>\n",
              "      <td>-1.093888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0.191634</td>\n",
              "      <td>0.339881</td>\n",
              "      <td>-0.308236</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.134626</td>\n",
              "      <td>0.903771</td>\n",
              "      <td>-0.238453</td>\n",
              "      <td>-0.041491</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.067643</td>\n",
              "      <td>-0.119657</td>\n",
              "      <td>-0.118804</td>\n",
              "      <td>-0.129231</td>\n",
              "      <td>-0.130716</td>\n",
              "      <td>-0.171264</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>-0.596701</td>\n",
              "      <td>0.478611</td>\n",
              "      <td>-0.866326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14090</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.362928</td>\n",
              "      <td>0.087650</td>\n",
              "      <td>0.034194</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.123127</td>\n",
              "      <td>1.331482</td>\n",
              "      <td>0.105735</td>\n",
              "      <td>-0.041491</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.067643</td>\n",
              "      <td>-0.119657</td>\n",
              "      <td>-0.118804</td>\n",
              "      <td>-0.129231</td>\n",
              "      <td>-0.130716</td>\n",
              "      <td>-0.171264</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>-0.596701</td>\n",
              "      <td>0.524972</td>\n",
              "      <td>-1.076961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14091</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.085884</td>\n",
              "      <td>-0.164581</td>\n",
              "      <td>-0.479451</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.111628</td>\n",
              "      <td>0.203880</td>\n",
              "      <td>-0.238453</td>\n",
              "      <td>-0.041491</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.067643</td>\n",
              "      <td>-0.119657</td>\n",
              "      <td>-0.118804</td>\n",
              "      <td>-0.129231</td>\n",
              "      <td>-0.130716</td>\n",
              "      <td>-0.171264</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>1.815431</td>\n",
              "      <td>0.164162</td>\n",
              "      <td>1.540935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14092</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.322130</td>\n",
              "      <td>-1.425737</td>\n",
              "      <td>0.119802</td>\n",
              "      <td>0.295608</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.077131</td>\n",
              "      <td>-0.622379</td>\n",
              "      <td>0.105735</td>\n",
              "      <td>-0.041491</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.067643</td>\n",
              "      <td>-0.119657</td>\n",
              "      <td>-0.118804</td>\n",
              "      <td>-0.129231</td>\n",
              "      <td>-0.130716</td>\n",
              "      <td>-0.171264</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>-0.596701</td>\n",
              "      <td>-1.115806</td>\n",
              "      <td>1.339703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14093</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.153722</td>\n",
              "      <td>-1.173506</td>\n",
              "      <td>0.975877</td>\n",
              "      <td>0.295608</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.123127</td>\n",
              "      <td>-0.583497</td>\n",
              "      <td>-0.238453</td>\n",
              "      <td>-0.041491</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.067643</td>\n",
              "      <td>0.050996</td>\n",
              "      <td>-0.015631</td>\n",
              "      <td>0.229201</td>\n",
              "      <td>0.126829</td>\n",
              "      <td>0.937623</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>-0.596701</td>\n",
              "      <td>-1.311328</td>\n",
              "      <td>0.119147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14094</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.295090</td>\n",
              "      <td>-0.416812</td>\n",
              "      <td>0.633447</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.146124</td>\n",
              "      <td>0.126115</td>\n",
              "      <td>-0.238453</td>\n",
              "      <td>-0.041491</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.067643</td>\n",
              "      <td>28.233039</td>\n",
              "      <td>32.961259</td>\n",
              "      <td>40.359205</td>\n",
              "      <td>28.558378</td>\n",
              "      <td>18.955304</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>-0.596701</td>\n",
              "      <td>-1.256905</td>\n",
              "      <td>0.043920</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14095 rows × 52 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69aaf4c2-d587-48b0-a1a5-ce54b3cb34c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-69aaf4c2-d587-48b0-a1a5-ce54b3cb34c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-69aaf4c2-d587-48b0-a1a5-ce54b3cb34c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "JUI1ORblssRC",
        "outputId": "e76d1f79-2298-478c-fd9b-7f4765c6f5f7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      COMPONENT_ARBITRARY  ANONYMOUS_1      YEAR  ANONYMOUS_2        AG  \\\n",
              "0                       1    -0.226304  0.592112    -0.340760 -0.150214   \n",
              "1                       3    -0.083512 -0.669043    -0.340760 -0.150214   \n",
              "2                       2    -0.276115 -0.921274    -0.340760 -0.150214   \n",
              "3                       3    -0.413213 -1.173506    -0.340760 -0.150214   \n",
              "4                       2     1.204694 -0.164581    -0.340760 -0.150214   \n",
              "...                   ...          ...       ...          ...       ...   \n",
              "6036                    3    -0.339683  0.087650    -0.340760 -0.150214   \n",
              "6037                    3     0.233617  0.592112    -0.340760 -0.150214   \n",
              "6038                    3     0.279633  0.087650    -0.340760 -0.150214   \n",
              "6039                    2    -0.422701 -0.164581    -0.340760 -0.150214   \n",
              "6040                    1    -0.177679  0.592112     2.199256  5.666438   \n",
              "\n",
              "            CO        CR        CU        FE       H2O        MN        MO  \\\n",
              "0    -0.089633 -0.115388 -0.260252 -0.311651 -0.041588 -0.250456 -0.400998   \n",
              "1    -0.089633 -0.045445 -0.260252  0.187233 -0.041588  0.019051 -0.400998   \n",
              "2    -0.089633 -0.115388 -0.143932 -0.324780 -0.041588 -0.250456 -0.400998   \n",
              "3    -0.089633 -0.010473 -0.236988 -0.028450 -0.041588  0.108886 -0.350857   \n",
              "4    -0.089633 -0.115388 -0.221479 -0.309776 -0.041588 -0.250456 -0.400998   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "6036 -0.089633 -0.010473  0.740102  1.629495 -0.041588  5.588859 -0.317430   \n",
              "6037 -0.089633  0.059471 -0.252497  1.046214 -0.041588  0.198722 -0.400998   \n",
              "6038 -0.089633 -0.115388 -0.268007 -0.234755 -0.041588 -0.250456 -0.400998   \n",
              "6039 -0.089633 -0.115388  0.212784 -0.330406 -0.041588 -0.250456 -0.400998   \n",
              "6040 -0.089633 -0.115388 -0.268007 -0.326655 -0.041588 -0.250456 -0.367571   \n",
              "\n",
              "            NI   PQINDEX        TI        V       V40        ZN  \n",
              "0    -0.191804 -0.265133 -0.102635 -0.10655 -0.363951  0.944762  \n",
              "1    -0.191804  1.516121  0.042348 -0.10655  0.353638 -1.084484  \n",
              "2    -0.191804 -0.264479 -0.102635 -0.10655 -1.311328  0.235748  \n",
              "3    -0.191804  4.968037 -0.102635 -0.10655  0.674134 -0.930269  \n",
              "4    -0.191804 -0.261207 -0.102635 -0.10655 -0.926330 -0.225017  \n",
              "...        ...       ...       ...      ...       ...       ...  \n",
              "6036  0.333602  1.036452 -0.102635 -0.10655 -0.769106  1.080171  \n",
              "6037 -0.191804  0.181816 -0.102635 -0.10655  0.573349 -1.082603  \n",
              "6038 -0.191804 -0.226524 -0.102635 -0.10655  3.887155 -1.082603  \n",
              "6039 -0.191804 -0.268405 -0.102635 -0.10655 -1.174261 -0.208091  \n",
              "6040 -0.191804 -0.262516 -0.102635 -0.10655 -0.591724  0.717201  \n",
              "\n",
              "[6041 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f22b4a5-9434-4921-a10a-f40d30ac603d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COMPONENT_ARBITRARY</th>\n",
              "      <th>ANONYMOUS_1</th>\n",
              "      <th>YEAR</th>\n",
              "      <th>ANONYMOUS_2</th>\n",
              "      <th>AG</th>\n",
              "      <th>CO</th>\n",
              "      <th>CR</th>\n",
              "      <th>CU</th>\n",
              "      <th>FE</th>\n",
              "      <th>H2O</th>\n",
              "      <th>MN</th>\n",
              "      <th>MO</th>\n",
              "      <th>NI</th>\n",
              "      <th>PQINDEX</th>\n",
              "      <th>TI</th>\n",
              "      <th>V</th>\n",
              "      <th>V40</th>\n",
              "      <th>ZN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.226304</td>\n",
              "      <td>0.592112</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>-0.115388</td>\n",
              "      <td>-0.260252</td>\n",
              "      <td>-0.311651</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>-0.250456</td>\n",
              "      <td>-0.400998</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>-0.265133</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>-0.363951</td>\n",
              "      <td>0.944762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.083512</td>\n",
              "      <td>-0.669043</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>-0.045445</td>\n",
              "      <td>-0.260252</td>\n",
              "      <td>0.187233</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>0.019051</td>\n",
              "      <td>-0.400998</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>1.516121</td>\n",
              "      <td>0.042348</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>0.353638</td>\n",
              "      <td>-1.084484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.276115</td>\n",
              "      <td>-0.921274</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>-0.115388</td>\n",
              "      <td>-0.143932</td>\n",
              "      <td>-0.324780</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>-0.250456</td>\n",
              "      <td>-0.400998</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>-0.264479</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>-1.311328</td>\n",
              "      <td>0.235748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.413213</td>\n",
              "      <td>-1.173506</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>-0.010473</td>\n",
              "      <td>-0.236988</td>\n",
              "      <td>-0.028450</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>0.108886</td>\n",
              "      <td>-0.350857</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>4.968037</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>0.674134</td>\n",
              "      <td>-0.930269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>1.204694</td>\n",
              "      <td>-0.164581</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>-0.115388</td>\n",
              "      <td>-0.221479</td>\n",
              "      <td>-0.309776</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>-0.250456</td>\n",
              "      <td>-0.400998</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>-0.261207</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>-0.926330</td>\n",
              "      <td>-0.225017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6036</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.339683</td>\n",
              "      <td>0.087650</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>-0.010473</td>\n",
              "      <td>0.740102</td>\n",
              "      <td>1.629495</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>5.588859</td>\n",
              "      <td>-0.317430</td>\n",
              "      <td>0.333602</td>\n",
              "      <td>1.036452</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>-0.769106</td>\n",
              "      <td>1.080171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6037</th>\n",
              "      <td>3</td>\n",
              "      <td>0.233617</td>\n",
              "      <td>0.592112</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>0.059471</td>\n",
              "      <td>-0.252497</td>\n",
              "      <td>1.046214</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>0.198722</td>\n",
              "      <td>-0.400998</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>0.181816</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>0.573349</td>\n",
              "      <td>-1.082603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6038</th>\n",
              "      <td>3</td>\n",
              "      <td>0.279633</td>\n",
              "      <td>0.087650</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>-0.115388</td>\n",
              "      <td>-0.268007</td>\n",
              "      <td>-0.234755</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>-0.250456</td>\n",
              "      <td>-0.400998</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>-0.226524</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>3.887155</td>\n",
              "      <td>-1.082603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6039</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.422701</td>\n",
              "      <td>-0.164581</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>-0.115388</td>\n",
              "      <td>0.212784</td>\n",
              "      <td>-0.330406</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>-0.250456</td>\n",
              "      <td>-0.400998</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>-0.268405</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>-1.174261</td>\n",
              "      <td>-0.208091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6040</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.177679</td>\n",
              "      <td>0.592112</td>\n",
              "      <td>2.199256</td>\n",
              "      <td>5.666438</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>-0.115388</td>\n",
              "      <td>-0.268007</td>\n",
              "      <td>-0.326655</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>-0.250456</td>\n",
              "      <td>-0.367571</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>-0.262516</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>-0.591724</td>\n",
              "      <td>0.717201</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6041 rows × 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f22b4a5-9434-4921-a10a-f40d30ac603d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4f22b4a5-9434-4921-a10a-f40d30ac603d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4f22b4a5-9434-4921-a10a-f40d30ac603d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preparation for preprocessing\n",
        "sampler_dic = {\n",
        "    \"under\": {\n",
        "        'RandomUnderSampler': RandomUnderSampler,\n",
        "        'TomekLinks': TomekLinks,\n",
        "         # 'CondensedNearestNeighbour': CondensedNearestNeighbour, \n",
        "        'OneSidedSelection': OneSidedSelection,\n",
        "        'EditedNearestNeighbours': EditedNearestNeighbours,\n",
        "        'NeighbourhoodCleaningRule': NeighbourhoodCleaningRule\n",
        "    },\n",
        "\n",
        "    \"over\": {\n",
        "        'RandomOverSampler': RandomOverSampler,\n",
        "        'ADASYN': ADASYN,\n",
        "        'NeighbourhoodCleaningRule': NeighbourhoodCleaningRule\n",
        "    },\n",
        "\n",
        "    \"hybrid\": {\n",
        "        'SMOTEENN': SMOTEENN,\n",
        "        'SMOTETomek': SMOTETomek\n",
        "    }\n",
        "}\n",
        "# sampler 하나 \n",
        "variable_dict = {\n",
        "    \"categorical_feature\": \"COMPONENT_ARBITRARY\", \n",
        "    \"test_size\": 0.1, \n",
        "    \"learner\": (\"classification\", \"XGB\"), \n",
        "    \"sampler\": (\"under\", \"RandomUnderSampler\"), \n",
        "    \"random_state_\": 42,\n",
        "    \"dimensionality\": PCA\n",
        "}"
      ],
      "metadata": {
        "id": "_XKv-UHDKGlC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_try = Preprocessing(**variable_dict)\n",
        "print()\n",
        "\n",
        "# 샘플링 그룹핑 스플릿\n",
        "X2, y2 = first_try.sampling(X, y)\n",
        "grouped_dic = first_try.grouping_df(X2, y2, y_column='Y_LABEL')\n",
        "split_X_y_bundle = first_try.split_X_y_bundle(grouped_dic)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVD0eIvUKLvg",
        "outputId": "8032c342-2948-4881-e965-f4a2aa21427e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RandomUnderSampler(random_state=42) completed resampling X and y\n",
            "COMPONENT_ARBITRARY\n",
            "dividing my df on 1\n",
            "dividing my df on 2\n",
            "dividing my df on 3\n",
            "dividing my df on 4\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 피처임포턴스 확인\n",
        "result_ = first_try.feature_importance_for_groups(split_X_y_bundle)\n",
        "features = result_[1]\n",
        "drop_target_list = first_try.chose_drop_features(features, draw=False)\n",
        "print()\n",
        "print(drop_target_list)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Djpw-SHyKPB-",
        "outputId": "352d615b-9598-45b2-f01b-145482e72e1c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1_score : 0.737\n",
            "f1_score : 0.667\n",
            "f1_score : 0.752\n",
            "f1_score : 0.250\n",
            "\n",
            "['U100', 'CD', 'FH2O', 'U20', 'MN', 'U14', 'U50', 'FUEL', 'FTBN', 'FOPTIMETHGLY', 'SOOTPERCENTAGE', 'CO', 'FNOX', 'V', 'H2O', 'V100', 'U25', 'AG', 'SN', 'TI', 'U6', 'U75', 'BE', 'U4', 'FSO4', 'ANONYMOUS_2', 'FOXID', 'LI', 'SB', 'NA', 'CR', 'NI', 'PB']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파이프라인 결과 확인\n",
        "print(first_try.print_report(split_X_y_bundle))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPIlBT3mKS9j",
        "outputId": "97e8f13b-97c1-4532-e9f3-edce010f3046"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomUnderSampler(random_state=42)\n",
            "XGBClassifier()\n",
            "<class 'sklearn.decomposition._pca.PCA'>\n",
            "PCA() 사용한 pipe line\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.88      0.79        33\n",
            "           1       0.83      0.65      0.73        31\n",
            "\n",
            "    accuracy                           0.77        64\n",
            "   macro avg       0.78      0.76      0.76        64\n",
            "weighted avg       0.78      0.77      0.76        64\n",
            "\n",
            "PCA() 사용한 pipe line\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.85      0.81        27\n",
            "           1       0.67      0.53      0.59        15\n",
            "\n",
            "    accuracy                           0.74        42\n",
            "   macro avg       0.72      0.69      0.70        42\n",
            "weighted avg       0.73      0.74      0.73        42\n",
            "\n",
            "PCA() 사용한 pipe line\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.85      0.77        67\n",
            "           1       0.77      0.57      0.65        58\n",
            "\n",
            "    accuracy                           0.72       125\n",
            "   macro avg       0.73      0.71      0.71       125\n",
            "weighted avg       0.73      0.72      0.71       125\n",
            "\n",
            "PCA() 사용한 pipe line\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.71      0.63         7\n",
            "           1       0.33      0.20      0.25         5\n",
            "\n",
            "    accuracy                           0.50        12\n",
            "   macro avg       0.44      0.46      0.44        12\n",
            "weighted avg       0.46      0.50      0.47        12\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sampler 전부다 \n",
        "from tqdm import tqdm\n",
        "\n",
        "for key, value in tqdm(sampler_dic.items(), desc=\"\\n첫 번째 반복문\"):\n",
        "    for name, function in tqdm(value.items(), desc=\"\\n두 번째 반복문\"):\n",
        "        variable_dict = {\n",
        "            \"categorical_feature\": \"COMPONENT_ARBITRARY\", \n",
        "            \"test_size\": 0.1, \n",
        "            \"learner\": (\"classification\", \"XGB\"), \n",
        "            \"sampler\": (key, name), \n",
        "            \"random_state_\": 42,\n",
        "            \"dimensionality\": PCA\n",
        "        }\n",
        "\n",
        "        first_try = Preprocessing(**variable_dict)\n",
        "        print()\n",
        "\n",
        "        # 샘플링 그룹핑 스플릿\n",
        "        X2, y2 = first_try.sampling(X, y)\n",
        "        grouped_dic = first_try.grouping_df(X2, y2, y_column='Y_LABEL')\n",
        "        split_X_y_bundle = first_try.split_X_y_bundle(grouped_dic)\n",
        "        print()\n",
        "\n",
        "        # 피처임포턴스 확인\n",
        "        result_ = first_try.feature_importance_for_groups(split_X_y_bundle)\n",
        "        features = result_[1]\n",
        "        drop_target_list = first_try.chose_drop_features(features, draw=False)\n",
        "        print()\n",
        "        print(drop_target_list)\n",
        "        print()\n",
        "\n",
        "        # 파이프라인 결과 확인\n",
        "        print(first_try.print_report(split_X_y_bundle))\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcpugSDTLHhQ",
        "outputId": "ad45831d-094a-44be-e347-33b9588f0255"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r\n",
            "첫 번째 반복문:   0%|          | 0/3 [00:00<?, ?it/s]\n",
            "\n",
            "두 번째 반복문:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RandomUnderSampler(random_state=42) completed resampling X and y\n",
            "COMPONENT_ARBITRARY\n",
            "dividing my df on 1\n",
            "dividing my df on 2\n",
            "dividing my df on 3\n",
            "dividing my df on 4\n",
            "\n",
            "f1_score : 0.737\n",
            "f1_score : 0.667\n",
            "f1_score : 0.752\n",
            "f1_score : 0.250\n",
            "\n",
            "['U100', 'CD', 'FH2O', 'U20', 'MN', 'U14', 'U50', 'FUEL', 'FTBN', 'FOPTIMETHGLY', 'SOOTPERCENTAGE', 'CO', 'FNOX', 'V', 'H2O', 'V100', 'U25', 'AG', 'SN', 'TI', 'U6', 'U75', 'BE', 'U4', 'FSO4', 'ANONYMOUS_2', 'FOXID', 'LI', 'SB', 'NA', 'CR', 'NI', 'PB']\n",
            "\n",
            "RandomUnderSampler(random_state=42)\n",
            "XGBClassifier()\n",
            "<class 'sklearn.decomposition._pca.PCA'>\n",
            "PCA() 사용한 pipe line\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.88      0.79        33\n",
            "           1       0.83      0.65      0.73        31\n",
            "\n",
            "    accuracy                           0.77        64\n",
            "   macro avg       0.78      0.76      0.76        64\n",
            "weighted avg       0.78      0.77      0.76        64\n",
            "\n",
            "PCA() 사용한 pipe line\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.85      0.81        27\n",
            "           1       0.67      0.53      0.59        15\n",
            "\n",
            "    accuracy                           0.74        42\n",
            "   macro avg       0.72      0.69      0.70        42\n",
            "weighted avg       0.73      0.74      0.73        42\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "두 번째 반복문:   0%|          | 0/5 [00:01<?, ?it/s]\n",
            "\n",
            "첫 번째 반복문:  33%|███▎      | 1/3 [00:01<00:02,  1.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PCA() 사용한 pipe line\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.85      0.77        67\n",
            "           1       0.77      0.57      0.65        58\n",
            "\n",
            "    accuracy                           0.72       125\n",
            "   macro avg       0.73      0.71      0.71       125\n",
            "weighted avg       0.73      0.72      0.71       125\n",
            "\n",
            "PCA() 사용한 pipe line\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.71      0.63         7\n",
            "           1       0.33      0.20      0.25         5\n",
            "\n",
            "    accuracy                           0.50        12\n",
            "   macro avg       0.44      0.46      0.44        12\n",
            "weighted avg       0.46      0.50      0.47        12\n",
            "\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "두 번째 반복문:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RandomOverSampler(random_state=42) completed resampling X and y\n",
            "COMPONENT_ARBITRARY\n",
            "dividing my df on 1\n",
            "dividing my df on 2\n",
            "dividing my df on 3\n",
            "dividing my df on 4\n",
            "\n",
            "f1_score : 0.902\n",
            "f1_score : 0.939\n",
            "f1_score : 0.844\n",
            "f1_score : 0.964\n",
            "\n",
            "['U100', 'CD', 'FH2O', 'U20', 'MN', 'U14', 'U50', 'FUEL', 'FTBN', 'FOPTIMETHGLY', 'SOOTPERCENTAGE', 'CO', 'FNOX', 'V', 'H2O', 'V100', 'U25', 'AG', 'SN', 'TI', 'U6', 'U75', 'BE', 'U4', 'FSO4', 'FOXID', 'LI', 'K', 'NI', 'MO']\n",
            "\n",
            "RandomOverSampler(random_state=42)\n",
            "XGBClassifier()\n",
            "<class 'sklearn.decomposition._pca.PCA'>\n",
            "PCA() 사용한 pipe line\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.92      0.93       386\n",
            "           1       0.91      0.92      0.91       312\n",
            "\n",
            "    accuracy                           0.92       698\n",
            "   macro avg       0.92      0.92      0.92       698\n",
            "weighted avg       0.92      0.92      0.92       698\n",
            "\n",
            "PCA() 사용한 pipe line\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.97      0.89       215\n",
            "           1       0.97      0.79      0.87       217\n",
            "\n",
            "    accuracy                           0.88       432\n",
            "   macro avg       0.89      0.88      0.88       432\n",
            "weighted avg       0.89      0.88      0.88       432\n",
            "\n",
            "PCA() 사용한 pipe line\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.90      0.86       664\n",
            "           1       0.88      0.80      0.84       656\n",
            "\n",
            "    accuracy                           0.85      1320\n",
            "   macro avg       0.85      0.85      0.85      1320\n",
            "weighted avg       0.85      0.85      0.85      1320\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "두 번째 반복문:   0%|          | 0/3 [00:08<?, ?it/s]\n",
            "\n",
            "첫 번째 반복문:  67%|██████▋   | 2/3 [00:09<00:05,  5.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PCA() 사용한 pipe line\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.94      0.96        77\n",
            "           1       0.91      0.98      0.95        54\n",
            "\n",
            "    accuracy                           0.95       131\n",
            "   macro avg       0.95      0.96      0.95       131\n",
            "weighted avg       0.96      0.95      0.95       131\n",
            "\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "두 번째 반복문:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SMOTEENN(random_state=42) completed resampling X and y\n",
            "COMPONENT_ARBITRARY\n",
            "dividing my df on 1\n",
            "dividing my df on 2\n",
            "dividing my df on 3\n",
            "dividing my df on 4\n",
            "\n",
            "f1_score : 0.969\n",
            "f1_score : 0.963\n",
            "f1_score : 0.968\n",
            "f1_score : 0.961\n",
            "\n",
            "['U100', 'CD', 'FH2O', 'U20', 'U14', 'PB', 'U50', 'FUEL', 'FTBN', 'FOPTIMETHGLY', 'SOOTPERCENTAGE', 'CO', 'FNOX', 'V', 'H2O', 'V100', 'U25', 'AG', 'TI', 'U6', 'U75', 'BE', 'U4', 'FSO4', 'FOXID', 'LI', 'CR', 'MO']\n",
            "\n",
            "SMOTEENN(random_state=42)\n",
            "XGBClassifier()\n",
            "<class 'sklearn.decomposition._pca.PCA'>\n",
            "PCA() 사용한 pipe line\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.92      0.92       279\n",
            "           1       0.94      0.93      0.93       327\n",
            "\n",
            "    accuracy                           0.93       606\n",
            "   macro avg       0.93      0.93      0.93       606\n",
            "weighted avg       0.93      0.93      0.93       606\n",
            "\n",
            "PCA() 사용한 pipe line\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.93      0.90       160\n",
            "           1       0.95      0.91      0.93       225\n",
            "\n",
            "    accuracy                           0.92       385\n",
            "   macro avg       0.91      0.92      0.92       385\n",
            "weighted avg       0.92      0.92      0.92       385\n",
            "\n",
            "PCA() 사용한 pipe line\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.88      0.85       473\n",
            "           1       0.91      0.87      0.89       668\n",
            "\n",
            "    accuracy                           0.87      1141\n",
            "   macro avg       0.87      0.87      0.87      1141\n",
            "weighted avg       0.87      0.87      0.87      1141\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "두 번째 반복문:   0%|          | 0/2 [00:27<?, ?it/s]\n",
            "\n",
            "첫 번째 반복문: 100%|██████████| 3/3 [00:37<00:00, 15.64s/it]\n",
            "첫 번째 반복문: 100%|██████████| 3/3 [00:37<00:00, 12.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PCA() 사용한 pipe line\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.92      0.96        65\n",
            "           1       0.88      1.00      0.94        37\n",
            "\n",
            "    accuracy                           0.95       102\n",
            "   macro avg       0.94      0.96      0.95       102\n",
            "weighted avg       0.96      0.95      0.95       102\n",
            "\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_target_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qkEIeJWuKxj",
        "outputId": "d976f9f6-7a16-4554-bc11-9fb5d1306be5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['U100',\n",
              " 'CD',\n",
              " 'FH2O',\n",
              " 'U20',\n",
              " 'U14',\n",
              " 'PB',\n",
              " 'U50',\n",
              " 'FUEL',\n",
              " 'FTBN',\n",
              " 'FOPTIMETHGLY',\n",
              " 'SOOTPERCENTAGE',\n",
              " 'CO',\n",
              " 'FNOX',\n",
              " 'V',\n",
              " 'H2O',\n",
              " 'V100',\n",
              " 'U25',\n",
              " 'AG',\n",
              " 'TI',\n",
              " 'U6',\n",
              " 'U75',\n",
              " 'BE',\n",
              " 'U4',\n",
              " 'FSO4',\n",
              " 'FOXID',\n",
              " 'LI',\n",
              " 'CR',\n",
              " 'MO']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set(drop_target_list) - set(test.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwHFEmp0tklW",
        "outputId": "2bdf6fae-07ff-4ea9-dbfa-c36c24419363"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'BE',\n",
              " 'CD',\n",
              " 'FH2O',\n",
              " 'FNOX',\n",
              " 'FOPTIMETHGLY',\n",
              " 'FOXID',\n",
              " 'FSO4',\n",
              " 'FTBN',\n",
              " 'FUEL',\n",
              " 'LI',\n",
              " 'PB',\n",
              " 'SOOTPERCENTAGE',\n",
              " 'U100',\n",
              " 'U14',\n",
              " 'U20',\n",
              " 'U25',\n",
              " 'U4',\n",
              " 'U50',\n",
              " 'U6',\n",
              " 'U75',\n",
              " 'V100'}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set(test.columns) - set(drop_target_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmRhVBeFtmQE",
        "outputId": "02702530-2f25-4fbe-edc6-4af333bdfb1c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ANONYMOUS_1',\n",
              " 'ANONYMOUS_2',\n",
              " 'COMPONENT_ARBITRARY',\n",
              " 'CU',\n",
              " 'FE',\n",
              " 'MN',\n",
              " 'NI',\n",
              " 'PQINDEX',\n",
              " 'V40',\n",
              " 'YEAR',\n",
              " 'ZN'}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(drop_target_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlufBUjduNo0",
        "outputId": "5caae6f4-bd0f-41bb-89de-6af5888366ac"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(drop_target_list) - set(test.columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mo8NwCWBLr1c",
        "outputId": "c36e1154-ac60-4190-f8dd-e868728253e9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(test.columns) - set(drop_target_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "El4UiB_Bt1dL",
        "outputId": "589ecbc6-a6ea-407b-a0c1-5bd0b2e1e62e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X2.columns), len(test.columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BqSrWP8Nuzg",
        "outputId": "e1a05a5c-e0ac-4b21-aa89-18833ec8c939"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_list_reg = list(set(drop_target_list) - set(test.columns))\n",
        "X3 = X2.drop(columns=drop_list_reg)\n",
        "X3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "RVKdlLQTN1R3",
        "outputId": "6f1a222e-f48c-434b-cf36-c0a1928d2e37"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       COMPONENT_ARBITRARY  ANONYMOUS_1      YEAR  SAMPLE_TRANSFER_DAY  \\\n",
              "0                        3    -0.393763 -0.669043            -0.051413   \n",
              "1                        2    -0.426022  1.853268             3.715319   \n",
              "2                        3    -0.410367  0.339881            -0.051413   \n",
              "3                        3     0.411276  0.087650            -0.051413   \n",
              "4                        3    -0.468243  1.096575            -0.222628   \n",
              "...                    ...          ...       ...                  ...   \n",
              "22309                    1    -0.189589 -1.662718            -0.142197   \n",
              "22310                    3    -0.209092  0.305027            -0.246288   \n",
              "22311                    3    -0.215672  1.801752            -0.495120   \n",
              "22312                    1    -0.106748 -1.496417            -0.147370   \n",
              "22313                    3     0.937084 -0.343892            -0.209239   \n",
              "\n",
              "       ANONYMOUS_2        AG        AL         B        BA        CA  ...  \\\n",
              "0        -0.340760 -0.150214 -0.111628  0.281646 -0.238453  1.141962  ...   \n",
              "1        -0.022576 -0.150214 -0.123127 -0.437686 -0.238453  1.087302  ...   \n",
              "2         0.415608 -0.150214 -0.146124 -0.418245 -0.238453 -0.834591  ...   \n",
              "3        -0.340760 -0.150214 -0.146124 -0.612659 -0.238453 -0.914895  ...   \n",
              "4        -0.022576 -0.150214 -0.111628 -0.602938  0.105735  0.646643  ...   \n",
              "...            ...       ...       ...       ...       ...       ...  ...   \n",
              "22309     0.646648 -0.150214  0.624704 -0.565231  0.429113 -0.717098  ...   \n",
              "22310    -0.340760 -0.150214 -0.123127 -0.572115  0.354800 -0.745044  ...   \n",
              "22311     2.740946 -0.150214  1.169934 -0.618409 -0.168156 -0.902890  ...   \n",
              "22312    -0.251598 -0.150214  0.101291 -0.077057  0.504764 -0.254774  ...   \n",
              "22313    -0.340760 -0.150214  0.357593 -0.561015  1.627665 -0.876328  ...   \n",
              "\n",
              "              P   PQINDEX         S        SB        SI        SN        TI  \\\n",
              "0      1.845136  5.293270  1.001652 -0.174727  2.006643  0.302478  0.622282   \n",
              "1     -0.598302 -0.259244 -1.170187 -0.174727 -0.179489 -0.252439 -0.102635   \n",
              "2     -1.027099 -0.254663  0.455823 -0.174727 -0.174370 -0.252439 -0.102635   \n",
              "3     -0.812700 -0.217362  0.421508 -0.174727 -0.169250 -0.252439 -0.102635   \n",
              "4     -1.089115 -0.180717  0.129828 -0.174727 -0.179489 -0.252439 -0.102635   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "22309 -0.015643 -0.262893 -0.825583  0.568990 -0.123017  0.571548 -0.102635   \n",
              "22310  0.283263 -0.213244 -0.733527 -0.174727 -0.144526 -0.013321 -0.102635   \n",
              "22311 -1.062114 -0.180376  0.571305  1.865800 -0.105939 -0.195770 -0.102635   \n",
              "22312  0.254767 -0.261836 -0.821648  0.088943 -0.134846  0.302478 -0.102635   \n",
              "22313  0.148236 -0.213101  0.729147 -0.174727 -0.175850 -0.252439 -0.102635   \n",
              "\n",
              "              V       V40        ZN  \n",
              "0     -0.106550  0.899892 -0.966002  \n",
              "1     -0.106550 -1.317376  0.119147  \n",
              "2     -0.106550  0.789028 -1.061916  \n",
              "3     -0.106550  0.631804 -0.939672  \n",
              "4     -0.106550  1.299000 -1.099530  \n",
              "...         ...       ...       ...  \n",
              "22309  1.996846  0.016880  1.019857  \n",
              "22310 -0.106550 -0.941650  1.230105  \n",
              "22311 -0.106550  0.371037 -1.072193  \n",
              "22312 -0.106550  0.019453  1.274882  \n",
              "22313 -0.106550  0.347075 -1.080268  \n",
              "\n",
              "[22314 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3d1c82ff-11e8-412e-9c6b-c954caac7eb3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COMPONENT_ARBITRARY</th>\n",
              "      <th>ANONYMOUS_1</th>\n",
              "      <th>YEAR</th>\n",
              "      <th>SAMPLE_TRANSFER_DAY</th>\n",
              "      <th>ANONYMOUS_2</th>\n",
              "      <th>AG</th>\n",
              "      <th>AL</th>\n",
              "      <th>B</th>\n",
              "      <th>BA</th>\n",
              "      <th>CA</th>\n",
              "      <th>...</th>\n",
              "      <th>P</th>\n",
              "      <th>PQINDEX</th>\n",
              "      <th>S</th>\n",
              "      <th>SB</th>\n",
              "      <th>SI</th>\n",
              "      <th>SN</th>\n",
              "      <th>TI</th>\n",
              "      <th>V</th>\n",
              "      <th>V40</th>\n",
              "      <th>ZN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.393763</td>\n",
              "      <td>-0.669043</td>\n",
              "      <td>-0.051413</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.111628</td>\n",
              "      <td>0.281646</td>\n",
              "      <td>-0.238453</td>\n",
              "      <td>1.141962</td>\n",
              "      <td>...</td>\n",
              "      <td>1.845136</td>\n",
              "      <td>5.293270</td>\n",
              "      <td>1.001652</td>\n",
              "      <td>-0.174727</td>\n",
              "      <td>2.006643</td>\n",
              "      <td>0.302478</td>\n",
              "      <td>0.622282</td>\n",
              "      <td>-0.106550</td>\n",
              "      <td>0.899892</td>\n",
              "      <td>-0.966002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.426022</td>\n",
              "      <td>1.853268</td>\n",
              "      <td>3.715319</td>\n",
              "      <td>-0.022576</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.123127</td>\n",
              "      <td>-0.437686</td>\n",
              "      <td>-0.238453</td>\n",
              "      <td>1.087302</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.598302</td>\n",
              "      <td>-0.259244</td>\n",
              "      <td>-1.170187</td>\n",
              "      <td>-0.174727</td>\n",
              "      <td>-0.179489</td>\n",
              "      <td>-0.252439</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.106550</td>\n",
              "      <td>-1.317376</td>\n",
              "      <td>0.119147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.410367</td>\n",
              "      <td>0.339881</td>\n",
              "      <td>-0.051413</td>\n",
              "      <td>0.415608</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.146124</td>\n",
              "      <td>-0.418245</td>\n",
              "      <td>-0.238453</td>\n",
              "      <td>-0.834591</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.027099</td>\n",
              "      <td>-0.254663</td>\n",
              "      <td>0.455823</td>\n",
              "      <td>-0.174727</td>\n",
              "      <td>-0.174370</td>\n",
              "      <td>-0.252439</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.106550</td>\n",
              "      <td>0.789028</td>\n",
              "      <td>-1.061916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.411276</td>\n",
              "      <td>0.087650</td>\n",
              "      <td>-0.051413</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.146124</td>\n",
              "      <td>-0.612659</td>\n",
              "      <td>-0.238453</td>\n",
              "      <td>-0.914895</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.812700</td>\n",
              "      <td>-0.217362</td>\n",
              "      <td>0.421508</td>\n",
              "      <td>-0.174727</td>\n",
              "      <td>-0.169250</td>\n",
              "      <td>-0.252439</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.106550</td>\n",
              "      <td>0.631804</td>\n",
              "      <td>-0.939672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.468243</td>\n",
              "      <td>1.096575</td>\n",
              "      <td>-0.222628</td>\n",
              "      <td>-0.022576</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.111628</td>\n",
              "      <td>-0.602938</td>\n",
              "      <td>0.105735</td>\n",
              "      <td>0.646643</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.089115</td>\n",
              "      <td>-0.180717</td>\n",
              "      <td>0.129828</td>\n",
              "      <td>-0.174727</td>\n",
              "      <td>-0.179489</td>\n",
              "      <td>-0.252439</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.106550</td>\n",
              "      <td>1.299000</td>\n",
              "      <td>-1.099530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22309</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.189589</td>\n",
              "      <td>-1.662718</td>\n",
              "      <td>-0.142197</td>\n",
              "      <td>0.646648</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>0.624704</td>\n",
              "      <td>-0.565231</td>\n",
              "      <td>0.429113</td>\n",
              "      <td>-0.717098</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.015643</td>\n",
              "      <td>-0.262893</td>\n",
              "      <td>-0.825583</td>\n",
              "      <td>0.568990</td>\n",
              "      <td>-0.123017</td>\n",
              "      <td>0.571548</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>1.996846</td>\n",
              "      <td>0.016880</td>\n",
              "      <td>1.019857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22310</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.209092</td>\n",
              "      <td>0.305027</td>\n",
              "      <td>-0.246288</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.123127</td>\n",
              "      <td>-0.572115</td>\n",
              "      <td>0.354800</td>\n",
              "      <td>-0.745044</td>\n",
              "      <td>...</td>\n",
              "      <td>0.283263</td>\n",
              "      <td>-0.213244</td>\n",
              "      <td>-0.733527</td>\n",
              "      <td>-0.174727</td>\n",
              "      <td>-0.144526</td>\n",
              "      <td>-0.013321</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.106550</td>\n",
              "      <td>-0.941650</td>\n",
              "      <td>1.230105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22311</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.215672</td>\n",
              "      <td>1.801752</td>\n",
              "      <td>-0.495120</td>\n",
              "      <td>2.740946</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>1.169934</td>\n",
              "      <td>-0.618409</td>\n",
              "      <td>-0.168156</td>\n",
              "      <td>-0.902890</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.062114</td>\n",
              "      <td>-0.180376</td>\n",
              "      <td>0.571305</td>\n",
              "      <td>1.865800</td>\n",
              "      <td>-0.105939</td>\n",
              "      <td>-0.195770</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.106550</td>\n",
              "      <td>0.371037</td>\n",
              "      <td>-1.072193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22312</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.106748</td>\n",
              "      <td>-1.496417</td>\n",
              "      <td>-0.147370</td>\n",
              "      <td>-0.251598</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>0.101291</td>\n",
              "      <td>-0.077057</td>\n",
              "      <td>0.504764</td>\n",
              "      <td>-0.254774</td>\n",
              "      <td>...</td>\n",
              "      <td>0.254767</td>\n",
              "      <td>-0.261836</td>\n",
              "      <td>-0.821648</td>\n",
              "      <td>0.088943</td>\n",
              "      <td>-0.134846</td>\n",
              "      <td>0.302478</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.106550</td>\n",
              "      <td>0.019453</td>\n",
              "      <td>1.274882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22313</th>\n",
              "      <td>3</td>\n",
              "      <td>0.937084</td>\n",
              "      <td>-0.343892</td>\n",
              "      <td>-0.209239</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>0.357593</td>\n",
              "      <td>-0.561015</td>\n",
              "      <td>1.627665</td>\n",
              "      <td>-0.876328</td>\n",
              "      <td>...</td>\n",
              "      <td>0.148236</td>\n",
              "      <td>-0.213101</td>\n",
              "      <td>0.729147</td>\n",
              "      <td>-0.174727</td>\n",
              "      <td>-0.175850</td>\n",
              "      <td>-0.252439</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.106550</td>\n",
              "      <td>0.347075</td>\n",
              "      <td>-1.080268</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22314 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d1c82ff-11e8-412e-9c6b-c954caac7eb3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3d1c82ff-11e8-412e-9c6b-c954caac7eb3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3d1c82ff-11e8-412e-9c6b-c954caac7eb3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resid_cols = list(set(X3.columns) - set(test.columns))\n",
        "print('length of residual columns is ', len(resid_cols))\n",
        "print('residual columns are ', resid_cols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZYaWC8CPh8U",
        "outputId": "e2a81289-32e1-4cad-a17c-f9ee7c9a4dc6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of residual columns is  13\n",
            "residual columns are  ['SN', 'AL', 'SI', 'BA', 'K', 'SB', 'MG', 'P', 'B', 'NA', 'SAMPLE_TRANSFER_DAY', 'CA', 'S']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('length of test columns is ', len(test.columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWNgGf9sP2uc",
        "outputId": "6ec65a16-d4d6-41b7-eef8-fb4be1d59837"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of test columns is  18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "ZTplN_MRSYBR",
        "outputId": "609c264e-a2ef-47a0-b923-eb7f07159d86"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      COMPONENT_ARBITRARY  ANONYMOUS_1      YEAR  ANONYMOUS_2        AG  \\\n",
              "0                       1    -0.226304  0.592112    -0.340760 -0.150214   \n",
              "1                       3    -0.083512 -0.669043    -0.340760 -0.150214   \n",
              "2                       2    -0.276115 -0.921274    -0.340760 -0.150214   \n",
              "3                       3    -0.413213 -1.173506    -0.340760 -0.150214   \n",
              "4                       2     1.204694 -0.164581    -0.340760 -0.150214   \n",
              "...                   ...          ...       ...          ...       ...   \n",
              "6036                    3    -0.339683  0.087650    -0.340760 -0.150214   \n",
              "6037                    3     0.233617  0.592112    -0.340760 -0.150214   \n",
              "6038                    3     0.279633  0.087650    -0.340760 -0.150214   \n",
              "6039                    2    -0.422701 -0.164581    -0.340760 -0.150214   \n",
              "6040                    1    -0.177679  0.592112     2.199256  5.666438   \n",
              "\n",
              "            CO        CR        CU        FE       H2O        MN        MO  \\\n",
              "0    -0.089633 -0.115388 -0.260252 -0.311651 -0.041588 -0.250456 -0.400998   \n",
              "1    -0.089633 -0.045445 -0.260252  0.187233 -0.041588  0.019051 -0.400998   \n",
              "2    -0.089633 -0.115388 -0.143932 -0.324780 -0.041588 -0.250456 -0.400998   \n",
              "3    -0.089633 -0.010473 -0.236988 -0.028450 -0.041588  0.108886 -0.350857   \n",
              "4    -0.089633 -0.115388 -0.221479 -0.309776 -0.041588 -0.250456 -0.400998   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "6036 -0.089633 -0.010473  0.740102  1.629495 -0.041588  5.588859 -0.317430   \n",
              "6037 -0.089633  0.059471 -0.252497  1.046214 -0.041588  0.198722 -0.400998   \n",
              "6038 -0.089633 -0.115388 -0.268007 -0.234755 -0.041588 -0.250456 -0.400998   \n",
              "6039 -0.089633 -0.115388  0.212784 -0.330406 -0.041588 -0.250456 -0.400998   \n",
              "6040 -0.089633 -0.115388 -0.268007 -0.326655 -0.041588 -0.250456 -0.367571   \n",
              "\n",
              "            NI   PQINDEX        TI        V       V40        ZN  \n",
              "0    -0.191804 -0.265133 -0.102635 -0.10655 -0.363951  0.944762  \n",
              "1    -0.191804  1.516121  0.042348 -0.10655  0.353638 -1.084484  \n",
              "2    -0.191804 -0.264479 -0.102635 -0.10655 -1.311328  0.235748  \n",
              "3    -0.191804  4.968037 -0.102635 -0.10655  0.674134 -0.930269  \n",
              "4    -0.191804 -0.261207 -0.102635 -0.10655 -0.926330 -0.225017  \n",
              "...        ...       ...       ...      ...       ...       ...  \n",
              "6036  0.333602  1.036452 -0.102635 -0.10655 -0.769106  1.080171  \n",
              "6037 -0.191804  0.181816 -0.102635 -0.10655  0.573349 -1.082603  \n",
              "6038 -0.191804 -0.226524 -0.102635 -0.10655  3.887155 -1.082603  \n",
              "6039 -0.191804 -0.268405 -0.102635 -0.10655 -1.174261 -0.208091  \n",
              "6040 -0.191804 -0.262516 -0.102635 -0.10655 -0.591724  0.717201  \n",
              "\n",
              "[6041 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b3ea810-98de-45b3-a268-8aec47aaff91\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COMPONENT_ARBITRARY</th>\n",
              "      <th>ANONYMOUS_1</th>\n",
              "      <th>YEAR</th>\n",
              "      <th>ANONYMOUS_2</th>\n",
              "      <th>AG</th>\n",
              "      <th>CO</th>\n",
              "      <th>CR</th>\n",
              "      <th>CU</th>\n",
              "      <th>FE</th>\n",
              "      <th>H2O</th>\n",
              "      <th>MN</th>\n",
              "      <th>MO</th>\n",
              "      <th>NI</th>\n",
              "      <th>PQINDEX</th>\n",
              "      <th>TI</th>\n",
              "      <th>V</th>\n",
              "      <th>V40</th>\n",
              "      <th>ZN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.226304</td>\n",
              "      <td>0.592112</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>-0.115388</td>\n",
              "      <td>-0.260252</td>\n",
              "      <td>-0.311651</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>-0.250456</td>\n",
              "      <td>-0.400998</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>-0.265133</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>-0.363951</td>\n",
              "      <td>0.944762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.083512</td>\n",
              "      <td>-0.669043</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>-0.045445</td>\n",
              "      <td>-0.260252</td>\n",
              "      <td>0.187233</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>0.019051</td>\n",
              "      <td>-0.400998</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>1.516121</td>\n",
              "      <td>0.042348</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>0.353638</td>\n",
              "      <td>-1.084484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.276115</td>\n",
              "      <td>-0.921274</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>-0.115388</td>\n",
              "      <td>-0.143932</td>\n",
              "      <td>-0.324780</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>-0.250456</td>\n",
              "      <td>-0.400998</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>-0.264479</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>-1.311328</td>\n",
              "      <td>0.235748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.413213</td>\n",
              "      <td>-1.173506</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>-0.010473</td>\n",
              "      <td>-0.236988</td>\n",
              "      <td>-0.028450</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>0.108886</td>\n",
              "      <td>-0.350857</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>4.968037</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>0.674134</td>\n",
              "      <td>-0.930269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>1.204694</td>\n",
              "      <td>-0.164581</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>-0.115388</td>\n",
              "      <td>-0.221479</td>\n",
              "      <td>-0.309776</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>-0.250456</td>\n",
              "      <td>-0.400998</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>-0.261207</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>-0.926330</td>\n",
              "      <td>-0.225017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6036</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.339683</td>\n",
              "      <td>0.087650</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>-0.010473</td>\n",
              "      <td>0.740102</td>\n",
              "      <td>1.629495</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>5.588859</td>\n",
              "      <td>-0.317430</td>\n",
              "      <td>0.333602</td>\n",
              "      <td>1.036452</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>-0.769106</td>\n",
              "      <td>1.080171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6037</th>\n",
              "      <td>3</td>\n",
              "      <td>0.233617</td>\n",
              "      <td>0.592112</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>0.059471</td>\n",
              "      <td>-0.252497</td>\n",
              "      <td>1.046214</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>0.198722</td>\n",
              "      <td>-0.400998</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>0.181816</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>0.573349</td>\n",
              "      <td>-1.082603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6038</th>\n",
              "      <td>3</td>\n",
              "      <td>0.279633</td>\n",
              "      <td>0.087650</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>-0.115388</td>\n",
              "      <td>-0.268007</td>\n",
              "      <td>-0.234755</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>-0.250456</td>\n",
              "      <td>-0.400998</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>-0.226524</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>3.887155</td>\n",
              "      <td>-1.082603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6039</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.422701</td>\n",
              "      <td>-0.164581</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>-0.115388</td>\n",
              "      <td>0.212784</td>\n",
              "      <td>-0.330406</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>-0.250456</td>\n",
              "      <td>-0.400998</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>-0.268405</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>-1.174261</td>\n",
              "      <td>-0.208091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6040</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.177679</td>\n",
              "      <td>0.592112</td>\n",
              "      <td>2.199256</td>\n",
              "      <td>5.666438</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>-0.115388</td>\n",
              "      <td>-0.268007</td>\n",
              "      <td>-0.326655</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>-0.250456</td>\n",
              "      <td>-0.367571</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>-0.262516</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>-0.591724</td>\n",
              "      <td>0.717201</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6041 rows × 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b3ea810-98de-45b3-a268-8aec47aaff91')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1b3ea810-98de-45b3-a268-8aec47aaff91 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1b3ea810-98de-45b3-a268-8aec47aaff91');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------------------- #\n",
        "#                 Make Model Pipeline for the multiple tests                   #\n",
        "# ---------------------------------------------------------------------------- #\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import copy\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "# classification models\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
        "from lightgbm.sklearn import LGBMClassifier\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "\n",
        "# classification metrics\n",
        "from sklearn.metrics import accuracy_score, f1_score, auc\n",
        "\n",
        "# regression models\n",
        "from sklearn.ensemble import RandomForestRegressor, VotingRegressor, StackingRegressor\n",
        "from lightgbm.sklearn import LGBMRegressor\n",
        "from xgboost.sklearn import XGBRegressor\n",
        "\n",
        "# regression metrics\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, mean_absolute_percentage_error, r2_score\n",
        "\n",
        "# KFold(CV), partial : optuna를 사용하기 위함\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "\n",
        "# optimize : hyper-parameter tuning\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "import optuna\n",
        "from optuna import Trial\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "class Ensemble:\n",
        "    \"\"\"\n",
        "    Ensemble & Optimize 3 models(RandomForest, XGBoost, LightGBM)\n",
        "    - (model_type : Classifier / Regressor) Ensemble with (ensemble : voting / stacking)\n",
        "    \"\"\"\n",
        "    def __init__(self, metric: str, learner: str='auto', ensemble: str='voting'):\n",
        "        \"\"\"\n",
        "        metric : sklearn.metrics 내장함수 활용\n",
        "        learner : 'auto' - rf, xgb, lgbm ensemble / 'rf' - RandomForest / 'xgb' - XGBoost / 'lgbm' - LightGBM\n",
        "        ensemble : 'voting', 'stacking'\n",
        "        \"\"\"\n",
        "        self.final_ensemble = None        # Final Ensemble model\n",
        "        self.models = {\n",
        "            'rf': None,\n",
        "            'xgb': None,\n",
        "            'lgbm': None\n",
        "        }\n",
        "        \n",
        "        # self.metric_dict[self.type_][self.metric_]\n",
        "        self.metric_dict = {\n",
        "            'classification': {\n",
        "                'accuracy_score': accuracy_score,\n",
        "                'f1_score': f1_score,\n",
        "                'auc': auc,\n",
        "            },\n",
        "            \n",
        "            'regression': {\n",
        "                'mae': mean_absolute_error,\n",
        "                'mse': mean_squared_error,\n",
        "                'rmse': mean_squared_error,\n",
        "                'msle': mean_squared_log_error,\n",
        "                'rmsle': mean_squared_log_error,\n",
        "                'mape': mean_absolute_percentage_error,\n",
        "                'r2_score': r2_score,\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # self.metric_direction_dict[self.type_][self.metric_]\n",
        "        self.metric_direction_dict = {\n",
        "            'classification': {\n",
        "                'accuracy_score': 'maximize',\n",
        "                'f1_score': 'maximize',\n",
        "                'auc': 'maximize'\n",
        "            },\n",
        "\n",
        "            'regression': {\n",
        "                'mae': 'minimize',\n",
        "                'mse': 'minimize',\n",
        "                'rmse': 'minimize',\n",
        "                'msle': 'minimize',\n",
        "                'rmsle': 'minimize',\n",
        "                'mape': 'minimize',\n",
        "                'r2_score': 'maximize'\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Initializing hyper-parameter for each model\n",
        "        # self.param[self.learner_]\n",
        "        self.param = {\n",
        "            'rf' : {'n_jobs': -1,\n",
        "                    'random_state': 42},\n",
        "            \n",
        "            'xgb' : {'learning_rate': 0.001,\n",
        "                     'nthread' : -1,\n",
        "                     'n_jobs': -1,\n",
        "                     'tree_method': 'gpu_hist',\n",
        "                     'predictor': 'gpu_predictor',\n",
        "                     'random_state': 42},\n",
        "            \n",
        "            'lgbm' : {'learning_rate': 0.001,\n",
        "                      'n_jobs': -1,\n",
        "                      'random_state': 42}\n",
        "        }\n",
        "\n",
        "        # self.learners[self.type_][self.learner_]\n",
        "        self.learners = {\n",
        "            'classification' : {\n",
        "                'rf': RandomForestClassifier,\n",
        "                'xgb': XGBClassifier,\n",
        "                'lgbm': LGBMClassifier\n",
        "            },\n",
        "            \n",
        "            'regression' : {\n",
        "                'rf': RandomForestRegressor,\n",
        "                'xgb': XGBRegressor,\n",
        "                'lgbm': LGBMRegressor\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # self.voters[self.type_][self.emsemble_]\n",
        "        self.voters = {\n",
        "            'classification' : {\n",
        "                'voting' : VotingClassifier,\n",
        "                'stacking' : StackingClassifier\n",
        "            },\n",
        "            \n",
        "            'regression' : {\n",
        "                'voting' : VotingRegressor,\n",
        "                'stacking' : StackingRegressor\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # 'classification' , 'regression'\n",
        "        self.type_ = ''\n",
        "        self.learner_ = ['rf', 'xgb', 'lgbm'] if learner == 'auto' else [learner]\n",
        "        self.ensemble_ = ensemble if ensemble in ['voting', 'stacking'] else 'voting'\n",
        "        self.metric_ = metric\n",
        "\n",
        "    def make_weights(self, N: int) -> list:\n",
        "        # x+y+z = 5인 음이 아닌 정수 (x, y, z) 순서쌍 만들기\n",
        "        weights = []\n",
        "        for i in range(N+1):\n",
        "            for j in range(N+1-i):\n",
        "                k = N-i-j\n",
        "                temp = [i/N, j/N, k/N]\n",
        "                weights.append(temp)\n",
        "        return weights\n",
        "        \n",
        "    def fit(self, X_train: pd.DataFrame, y_train: np.ndarray,\n",
        "            n_trials: int=20, cv: int=5, N: int=5) -> None:\n",
        "\n",
        "        self.X_cols = X_train.columns\n",
        "\n",
        "        for learner in self.learner_:\n",
        "            # RF, XGB, LGBM 순서대로 hyper-parameter tuning\n",
        "            param = self.optimizer(X_train, y_train, learner, n_trials, cv)\n",
        "            # Hyper-parameter fix + tuning\n",
        "            self.param[learner].update(param)\n",
        "            # Set up final models\n",
        "            self.models[learner] = self.learners[self.type_][learner](**self.param[learner])\n",
        "            self.models[learner].fit(X_train, y_train)\n",
        "\n",
        "        if len(self.learner_) < 2:\n",
        "            self.final_ensemble = self.models[self.learner_[0]]\n",
        "\n",
        "        else:\n",
        "            estimators = [(learner, self.models[learner]) for learner in self.learner_]\n",
        "            weights = self.make_weights(N)\n",
        "\n",
        "            # 'weights': weights,\n",
        "            ensemble_param = {\n",
        "                'estimators': estimators,\n",
        "                'n_jobs': -1\n",
        "            }\n",
        "\n",
        "            if self.ensemble_ == 'voting':\n",
        "                ensemble_param.update({'voting': 'soft'})\n",
        "            \n",
        "            self.final_ensemble = self.voters[self.type_][self.ensemle_](**ensemble_param)\n",
        "\n",
        "            grid_params = {'weights': weights}\n",
        "            grid_Search = GridSearchCV(param_grid = grid_params, estimator=self.final_ensemble, scoring=self.metric_dict[self.type_][self.metric_])\n",
        "            grid_Search.fit(X_train, y_train)\n",
        "            self.final_ensemble = grid_Search.best_estimator_\n",
        "\n",
        "    def predict(self, X_test: pd.DataFrame) -> np.ndarray:\n",
        "        return self.final_ensemble.predict(X_test)\n",
        "\n",
        "    def score(self, y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
        "        if self.metric_ in ['rmse', 'rmsle']:\n",
        "            return self.metric_dict[self.type_][self.metric_[1:]](y_true, y_pred, squared=False)\n",
        "        else:\n",
        "            return self.metric_dict[self.type_][self.metric_](y_true, y_pred)\n",
        "\n",
        "    def K_fold(self, model, X, y, cv) -> list:\n",
        "        scores = []\n",
        "        folds = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
        "\n",
        "        try:\n",
        "            for train_idx, val_idx in folds.split(X, y):\n",
        "                continue\n",
        "        except:\n",
        "            folds = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
        "        \n",
        "        if cv == 1:\n",
        "            X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "            model.fit(X_train, y_train)\n",
        "            score = self.score(y_val, model.predict(X_val))\n",
        "            scores.append(score)\n",
        "        else:\n",
        "            for train_idx, val_idx in folds.split(X, y):\n",
        "                X_train = X.iloc[train_idx, :]\n",
        "                y_train = y.iloc[train_idx]\n",
        "                \n",
        "                X_val = X.iloc[val_idx, :]\n",
        "                y_val = y.iloc[val_idx]\n",
        "                \n",
        "                model.fit(X_train, y_train)\n",
        "                score = self.score(y_val, model.predict(X_val))\n",
        "                scores.append(score)\n",
        "\n",
        "        return scores\n",
        "\n",
        "    def objective(self, trial: Trial, X, y, learner: str, cv: int) -> float:\n",
        "        temp = copy.deepcopy(self.param[learner])\n",
        "        \n",
        "        if learner == 'rf': # RandomForest\n",
        "            param = {\n",
        "                \"n_estimators\" : trial.suggest_int('n_estimators', 50, 1000),\n",
        "                'max_depth':trial.suggest_int('max_depth', 8, 16),\n",
        "                'min_samples_split': trial.suggest_int('min_samples_split', 1, 150),\n",
        "                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 60),\n",
        "            }\n",
        "\n",
        "        elif learner == 'xgb': # XGB\n",
        "            param = {\n",
        "                \"n_estimators\" : trial.suggest_int('n_estimators', 500, 4000),\n",
        "                'max_depth':trial.suggest_int('max_depth', 8, 16),\n",
        "                'min_child_weight':trial.suggest_int('min_child_weight', 1, 300),\n",
        "                'gamma':trial.suggest_int('gamma', 1, 3),\n",
        "                'learning_rate': 0.05,\n",
        "                'colsample_bytree':trial.suggest_discrete_uniform('colsample_bytree',0.5, 1, 0.1),\n",
        "                'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
        "                'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
        "                'subsample': trial.suggest_categorical('subsample', [0.6,0.7,0.8,1.0] ),\n",
        "            }\n",
        "\n",
        "        elif learner == 'lgbm': # LGBM\n",
        "            param = {\n",
        "                'num_leaves': trial.suggest_int('num_leaves', 2, 1024, step=1, log=True), \n",
        "                'max_depth': trial.suggest_int('max_depth', 1, 10, step=1, log=False), \n",
        "                'learning_rate': 0.05,\n",
        "                'n_estimators': trial.suggest_int('n_estimators', 8, 1024, step=1, log=True), \n",
        "                'class_weight': trial.suggest_categorical('class_weight', ['balanced', None]),\n",
        "                'min_child_samples': trial.suggest_int('min_child_samples', 10, 50, step=1, log=False), \n",
        "                'subsample': trial.suggest_uniform('subsample', 0.7, 1.0), \n",
        "                'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.7, 1.0),\n",
        "                'reg_alpha': trial.suggest_uniform('reg_alpha', 0.0, 1.0),\n",
        "                'reg_lambda': trial.suggest_uniform('reg_lambda', 0.0, 10.0),\n",
        "            }\n",
        "\n",
        "        else:\n",
        "            raise Exception(\"Not exist those model. Please choose the number in [0, 1, 2]\\nTry again.\")\n",
        "        \n",
        "        # Set up param\n",
        "        temp.update(param)\n",
        "        param = temp\n",
        "\n",
        "        # Set up the model by flag\n",
        "        model = self.learners[self.type_][learner](**param)\n",
        "        \n",
        "        # K-fold cross validation\n",
        "        scores = self.K_fold(model, X, y, cv)\n",
        "\n",
        "        return np.mean(scores)\n",
        "    \n",
        "    def optimizer(self, X: pd.DataFrame, y: np.ndarray,\n",
        "                  learner: str, n_trials: int, cv: int) -> dict:\n",
        "        \n",
        "        direction = self.metric_direction_dict[self.type_][self.metric_]\n",
        "        study = optuna.create_study(direction=direction, sampler=TPESampler())\n",
        "        study.optimize(lambda trial : self.objective(trial, X, y, learner, cv), n_trials=n_trials)\n",
        "        print('Best trial: score {},\\nparams: {}'.format(study.best_trial.value, study.best_trial.params))\n",
        "        return study.best_trial.params\n",
        "\n",
        "class BinaryCalssifier(Ensemble):\n",
        "    # Child Class\n",
        "    \"\"\"\n",
        "    metric : F1 score\n",
        "    \"\"\"\n",
        "    def __init__(self, metric: str='f1_score', learner: str='auto', ensemble: str='voting'):\n",
        "        super().__init__(metric, learner, ensemble)\n",
        "        # 'classification' Type\n",
        "        self.type_ = 'classification'\n",
        "        self.param['lgbm'] = {'objective': 'binary',\n",
        "                              'learning_rate': 0.05,\n",
        "                              'random_state': 42}   # LightGBM\n",
        "\n",
        "class Regressor(Ensemble):\n",
        "    # Child Class\n",
        "    \"\"\"\n",
        "    metric : R-squared score\n",
        "    \"\"\"\n",
        "    def __init__(self, metric: str='r2_score', learner: str='auto', ensemble: str='voting'):\n",
        "        super().__init__(metric, learner, ensemble)\n",
        "        # 'regression' Type\n",
        "        self.type_ = 'regression'\n"
      ],
      "metadata": {
        "id": "6xXourDeWOqs"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_reg = X3.loc[:, test.columns]\n",
        "reg_dict = {}\n",
        "for col in resid_cols:\n",
        "    print(f\"--------------- {col} ---------------\")\n",
        "    reg = Regressor(learner='lgbm')\n",
        "    y_reg = X3[col]\n",
        "    # train-validation split\n",
        "    X_reg_train, X_reg_val, y_reg_train, y_reg_val = train_test_split(X_reg, y_reg, test_size=0.2, random_state=69)\n",
        "\n",
        "    # model fitting\n",
        "    reg.fit(X_reg_train, y_reg_train, n_trials=20, cv=5)\n",
        "\n",
        "    # prediction\n",
        "    y_reg_train_pred = reg.predict(X_reg_train)\n",
        "    y_reg_pred = reg.predict(X_reg_val)\n",
        "    \n",
        "    # scoring\n",
        "    score_train = reg.score(y_reg_train, y_reg_train_pred)\n",
        "    score_val = reg.score(y_reg_val, y_reg_pred)\n",
        "    reg_dict[col] = reg\n",
        "    print(f\"--------------- {col} ---------------\")\n",
        "    print(\"Train R^2 score is %.4f\" % (score_train))\n",
        "    print(\"Validation R^2 score is %.4f\" % (score_val))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lXW9kBFQEy5",
        "outputId": "a5bfc385-9452-41d3-cd6d-3adac78b41ea"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:22:32,378]\u001b[0m A new study created in memory with name: no-name-00aa3d07-e892-42df-9187-e70751547935\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------- SN ---------------\n",
            "maximize\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:22:36,418]\u001b[0m Trial 0 finished with value: 0.5539447905936584 and parameters: {'num_leaves': 5, 'max_depth': 2, 'n_estimators': 777, 'class_weight': None, 'min_child_samples': 38, 'subsample': 0.7331382831722867, 'colsample_bytree': 0.9479189954274854, 'reg_alpha': 0.2728069360805898, 'reg_lambda': 0.9715070380707658}. Best is trial 0 with value: 0.5539447905936584.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:22:39,568]\u001b[0m Trial 1 finished with value: 0.708600783706115 and parameters: {'num_leaves': 274, 'max_depth': 9, 'n_estimators': 107, 'class_weight': None, 'min_child_samples': 23, 'subsample': 0.8196017250994299, 'colsample_bytree': 0.8889191203100093, 'reg_alpha': 0.09432136677054881, 'reg_lambda': 8.82449371171388}. Best is trial 1 with value: 0.708600783706115.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:22:39,861]\u001b[0m Trial 2 finished with value: 0.024556320301077017 and parameters: {'num_leaves': 5, 'max_depth': 5, 'n_estimators': 8, 'class_weight': 'balanced', 'min_child_samples': 29, 'subsample': 0.7286716128469533, 'colsample_bytree': 0.7137071886888134, 'reg_alpha': 0.9128030341966797, 'reg_lambda': 0.8923786632871256}. Best is trial 1 with value: 0.708600783706115.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:22:40,275]\u001b[0m Trial 3 finished with value: 0.2536007602463329 and parameters: {'num_leaves': 19, 'max_depth': 6, 'n_estimators': 14, 'class_weight': 'balanced', 'min_child_samples': 44, 'subsample': 0.7162440832083479, 'colsample_bytree': 0.9285295658553598, 'reg_alpha': 0.11605232941196553, 'reg_lambda': 3.7879314545478024}. Best is trial 1 with value: 0.708600783706115.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:22:40,553]\u001b[0m Trial 4 finished with value: 0.23476957324223702 and parameters: {'num_leaves': 66, 'max_depth': 2, 'n_estimators': 11, 'class_weight': None, 'min_child_samples': 37, 'subsample': 0.9520409173905284, 'colsample_bytree': 0.902991608442745, 'reg_alpha': 0.7370481642708434, 'reg_lambda': 9.774741786537833}. Best is trial 1 with value: 0.708600783706115.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:22:41,178]\u001b[0m Trial 5 finished with value: 0.3788803532753252 and parameters: {'num_leaves': 528, 'max_depth': 3, 'n_estimators': 16, 'class_weight': None, 'min_child_samples': 34, 'subsample': 0.9536487392512545, 'colsample_bytree': 0.9261035497074444, 'reg_alpha': 0.1976691675331823, 'reg_lambda': 3.48212671893662}. Best is trial 1 with value: 0.708600783706115.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:22:41,561]\u001b[0m Trial 6 finished with value: 0.019272266741177435 and parameters: {'num_leaves': 8, 'max_depth': 1, 'n_estimators': 29, 'class_weight': 'balanced', 'min_child_samples': 50, 'subsample': 0.8554893397161825, 'colsample_bytree': 0.7264749541379887, 'reg_alpha': 0.15634698723789464, 'reg_lambda': 9.018887131590855}. Best is trial 1 with value: 0.708600783706115.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:22:42,508]\u001b[0m Trial 7 finished with value: 0.3201621977341099 and parameters: {'num_leaves': 638, 'max_depth': 2, 'n_estimators': 100, 'class_weight': 'balanced', 'min_child_samples': 13, 'subsample': 0.703335493737809, 'colsample_bytree': 0.9783948058988444, 'reg_alpha': 0.2997868446394105, 'reg_lambda': 8.50420440968099}. Best is trial 1 with value: 0.708600783706115.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:22:45,819]\u001b[0m Trial 8 finished with value: 0.3823736454118113 and parameters: {'num_leaves': 82, 'max_depth': 8, 'n_estimators': 160, 'class_weight': 'balanced', 'min_child_samples': 23, 'subsample': 0.754272046923126, 'colsample_bytree': 0.7293550555319009, 'reg_alpha': 0.9914142239114696, 'reg_lambda': 1.3275593884465575}. Best is trial 1 with value: 0.708600783706115.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:22:46,782]\u001b[0m Trial 9 finished with value: 0.4642547153218996 and parameters: {'num_leaves': 106, 'max_depth': 5, 'n_estimators': 54, 'class_weight': 'balanced', 'min_child_samples': 27, 'subsample': 0.9903019352751524, 'colsample_bytree': 0.8417955276537926, 'reg_alpha': 0.6464547161898567, 'reg_lambda': 6.228468307800634}. Best is trial 1 with value: 0.708600783706115.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:22:54,669]\u001b[0m Trial 10 finished with value: 0.7397947627999527 and parameters: {'num_leaves': 246, 'max_depth': 10, 'n_estimators': 303, 'class_weight': None, 'min_child_samples': 17, 'subsample': 0.821178283046395, 'colsample_bytree': 0.8294376480059616, 'reg_alpha': 0.4370085837127924, 'reg_lambda': 6.8165754885980885}. Best is trial 10 with value: 0.7397947627999527.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:23:03,348]\u001b[0m Trial 11 finished with value: 0.7402208481948185 and parameters: {'num_leaves': 290, 'max_depth': 10, 'n_estimators': 332, 'class_weight': None, 'min_child_samples': 16, 'subsample': 0.8262098596117203, 'colsample_bytree': 0.8239213125588328, 'reg_alpha': 0.020654130220384162, 'reg_lambda': 7.102689275854937}. Best is trial 11 with value: 0.7402208481948185.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:23:15,549]\u001b[0m Trial 12 finished with value: 0.7479413672205759 and parameters: {'num_leaves': 248, 'max_depth': 10, 'n_estimators': 395, 'class_weight': None, 'min_child_samples': 10, 'subsample': 0.8491153205842634, 'colsample_bytree': 0.805013620917769, 'reg_alpha': 0.43242855582283246, 'reg_lambda': 6.825770623428039}. Best is trial 12 with value: 0.7479413672205759.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:23:31,012]\u001b[0m Trial 13 finished with value: 0.749577705430932 and parameters: {'num_leaves': 935, 'max_depth': 8, 'n_estimators': 624, 'class_weight': None, 'min_child_samples': 10, 'subsample': 0.8784572116388221, 'colsample_bytree': 0.7859712474012454, 'reg_alpha': 0.41236475742452655, 'reg_lambda': 7.061940007652583}. Best is trial 13 with value: 0.749577705430932.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:23:52,352]\u001b[0m Trial 14 finished with value: 0.749564148546843 and parameters: {'num_leaves': 979, 'max_depth': 7, 'n_estimators': 924, 'class_weight': None, 'min_child_samples': 10, 'subsample': 0.8841024784101761, 'colsample_bytree': 0.7865065483092107, 'reg_alpha': 0.4526575150182552, 'reg_lambda': 5.114486350739639}. Best is trial 13 with value: 0.749577705430932.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:24:07,281]\u001b[0m Trial 15 finished with value: 0.7405591210543795 and parameters: {'num_leaves': 994, 'max_depth': 7, 'n_estimators': 943, 'class_weight': None, 'min_child_samples': 20, 'subsample': 0.9001305414583528, 'colsample_bytree': 0.7752231290325164, 'reg_alpha': 0.5891589726479475, 'reg_lambda': 4.688514843371557}. Best is trial 13 with value: 0.749577705430932.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:24:09,157]\u001b[0m Trial 16 finished with value: 0.3230971126409271 and parameters: {'num_leaves': 2, 'max_depth': 7, 'n_estimators': 545, 'class_weight': None, 'min_child_samples': 10, 'subsample': 0.8987639609738711, 'colsample_bytree': 0.774422365847333, 'reg_alpha': 0.36448149721856193, 'reg_lambda': 5.1840442574783365}. Best is trial 13 with value: 0.749577705430932.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:24:30,888]\u001b[0m Trial 17 finished with value: 0.7516803085331627 and parameters: {'num_leaves': 934, 'max_depth': 8, 'n_estimators': 995, 'class_weight': None, 'min_child_samples': 16, 'subsample': 0.8967433259000622, 'colsample_bytree': 0.7867258584797738, 'reg_alpha': 0.5504249815852598, 'reg_lambda': 2.4052294831173415}. Best is trial 17 with value: 0.7516803085331627.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:24:33,404]\u001b[0m Trial 18 finished with value: 0.7091380748481828 and parameters: {'num_leaves': 34, 'max_depth': 8, 'n_estimators': 162, 'class_weight': None, 'min_child_samples': 18, 'subsample': 0.9310299226103778, 'colsample_bytree': 0.7511770292337835, 'reg_alpha': 0.5620278325938125, 'reg_lambda': 2.206947836141368}. Best is trial 17 with value: 0.7516803085331627.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:24:35,379]\u001b[0m Trial 19 finished with value: 0.6459459564872294 and parameters: {'num_leaves': 132, 'max_depth': 4, 'n_estimators': 210, 'class_weight': None, 'min_child_samples': 23, 'subsample': 0.7861336562576197, 'colsample_bytree': 0.8729989732798873, 'reg_alpha': 0.7743798867639031, 'reg_lambda': 2.5211656340717816}. Best is trial 17 with value: 0.7516803085331627.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: score 0.7516803085331627,\n",
            "params: {'num_leaves': 934, 'max_depth': 8, 'n_estimators': 995, 'class_weight': None, 'min_child_samples': 16, 'subsample': 0.8967433259000622, 'colsample_bytree': 0.7867258584797738, 'reg_alpha': 0.5504249815852598, 'reg_lambda': 2.4052294831173415}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:24:45,188]\u001b[0m A new study created in memory with name: no-name-4f08f92c-a607-48fa-bb8e-257841d60718\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------- SN ---------------\n",
            "Train R^2 score is 0.6112\n",
            "Validation R^2 score is 0.5426\n",
            "\n",
            "--------------- AL ---------------\n",
            "maximize\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:24:47,060]\u001b[0m Trial 0 finished with value: 0.20965133608024714 and parameters: {'num_leaves': 18, 'max_depth': 7, 'n_estimators': 125, 'class_weight': 'balanced', 'min_child_samples': 34, 'subsample': 0.9150174739714787, 'colsample_bytree': 0.8365872607222085, 'reg_alpha': 0.6763583595555764, 'reg_lambda': 5.987693794440973}. Best is trial 0 with value: 0.20965133608024714.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:24:47,903]\u001b[0m Trial 1 finished with value: 0.16660621129359468 and parameters: {'num_leaves': 154, 'max_depth': 8, 'n_estimators': 24, 'class_weight': 'balanced', 'min_child_samples': 19, 'subsample': 0.8128409904685735, 'colsample_bytree': 0.7039620199004907, 'reg_alpha': 0.3276806932392674, 'reg_lambda': 6.398871101958189}. Best is trial 0 with value: 0.20965133608024714.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:24:49,718]\u001b[0m Trial 2 finished with value: 0.06721783541972455 and parameters: {'num_leaves': 3, 'max_depth': 2, 'n_estimators': 351, 'class_weight': 'balanced', 'min_child_samples': 23, 'subsample': 0.9565547807201502, 'colsample_bytree': 0.7507974970799897, 'reg_alpha': 0.1484709461169309, 'reg_lambda': 9.037765390632341}. Best is trial 0 with value: 0.20965133608024714.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:24:53,088]\u001b[0m Trial 3 finished with value: 0.038170101398874355 and parameters: {'num_leaves': 603, 'max_depth': 1, 'n_estimators': 761, 'class_weight': 'balanced', 'min_child_samples': 26, 'subsample': 0.8163493894387165, 'colsample_bytree': 0.899723448191784, 'reg_alpha': 0.07544871267239006, 'reg_lambda': 9.486702760775714}. Best is trial 0 with value: 0.20965133608024714.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:24:53,383]\u001b[0m Trial 4 finished with value: 0.04378435754479999 and parameters: {'num_leaves': 148, 'max_depth': 1, 'n_estimators': 26, 'class_weight': None, 'min_child_samples': 24, 'subsample': 0.726915063755842, 'colsample_bytree': 0.7071738417884174, 'reg_alpha': 0.06126302127182848, 'reg_lambda': 6.4856323078169575}. Best is trial 0 with value: 0.20965133608024714.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:24:53,967]\u001b[0m Trial 5 finished with value: -0.02083220728148385 and parameters: {'num_leaves': 4, 'max_depth': 1, 'n_estimators': 85, 'class_weight': 'balanced', 'min_child_samples': 45, 'subsample': 0.8082210704875871, 'colsample_bytree': 0.9374960682559588, 'reg_alpha': 0.44998897829507, 'reg_lambda': 6.48009261460166}. Best is trial 0 with value: 0.20965133608024714.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:24:55,528]\u001b[0m Trial 6 finished with value: 0.28852208369111965 and parameters: {'num_leaves': 8, 'max_depth': 5, 'n_estimators': 199, 'class_weight': None, 'min_child_samples': 12, 'subsample': 0.960211003623179, 'colsample_bytree': 0.7600560212504773, 'reg_alpha': 0.8101447864152458, 'reg_lambda': 6.7276737325577045}. Best is trial 6 with value: 0.28852208369111965.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:24:58,127]\u001b[0m Trial 7 finished with value: 0.2670391711425409 and parameters: {'num_leaves': 636, 'max_depth': 7, 'n_estimators': 123, 'class_weight': 'balanced', 'min_child_samples': 19, 'subsample': 0.9085301597093514, 'colsample_bytree': 0.7726255202894727, 'reg_alpha': 0.22901986300423927, 'reg_lambda': 7.4486173425803965}. Best is trial 6 with value: 0.28852208369111965.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:24:58,934]\u001b[0m Trial 8 finished with value: 0.06286473629404252 and parameters: {'num_leaves': 96, 'max_depth': 3, 'n_estimators': 74, 'class_weight': 'balanced', 'min_child_samples': 42, 'subsample': 0.8210763131533892, 'colsample_bytree': 0.9191010289022812, 'reg_alpha': 0.19876485826557633, 'reg_lambda': 3.4049322425749127}. Best is trial 6 with value: 0.28852208369111965.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:25:04,396]\u001b[0m Trial 9 finished with value: 0.49628607098085376 and parameters: {'num_leaves': 122, 'max_depth': 9, 'n_estimators': 195, 'class_weight': None, 'min_child_samples': 29, 'subsample': 0.817211063048795, 'colsample_bytree': 0.8396126047886545, 'reg_alpha': 0.7816763320343457, 'reg_lambda': 9.27778930834798}. Best is trial 9 with value: 0.49628607098085376.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:25:04,815]\u001b[0m Trial 10 finished with value: 0.11401684093079863 and parameters: {'num_leaves': 39, 'max_depth': 10, 'n_estimators': 8, 'class_weight': None, 'min_child_samples': 35, 'subsample': 0.7137101388973531, 'colsample_bytree': 0.9983677161008675, 'reg_alpha': 0.895244934051176, 'reg_lambda': 0.047622213132616054}. Best is trial 9 with value: 0.49628607098085376.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:25:09,017]\u001b[0m Trial 11 finished with value: 0.32968213656732237 and parameters: {'num_leaves': 10, 'max_depth': 4, 'n_estimators': 320, 'class_weight': None, 'min_child_samples': 11, 'subsample': 0.9968135621162971, 'colsample_bytree': 0.8231195062795806, 'reg_alpha': 0.9480742440732464, 'reg_lambda': 3.8833686278688027}. Best is trial 9 with value: 0.49628607098085376.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:25:15,359]\u001b[0m Trial 12 finished with value: 0.3949864657202688 and parameters: {'num_leaves': 17, 'max_depth': 4, 'n_estimators': 532, 'class_weight': None, 'min_child_samples': 11, 'subsample': 0.8946192282333513, 'colsample_bytree': 0.837330234005736, 'reg_alpha': 0.9874605999639879, 'reg_lambda': 3.254278492125517}. Best is trial 9 with value: 0.49628607098085376.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:25:32,239]\u001b[0m Trial 13 finished with value: 0.5925518530703362 and parameters: {'num_leaves': 45, 'max_depth': 10, 'n_estimators': 857, 'class_weight': None, 'min_child_samples': 50, 'subsample': 0.8711164448869485, 'colsample_bytree': 0.8696804529030402, 'reg_alpha': 0.6743677742041738, 'reg_lambda': 1.1722784293053512}. Best is trial 13 with value: 0.5925518530703362.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:25:52,879]\u001b[0m Trial 14 finished with value: 0.6081871131790887 and parameters: {'num_leaves': 70, 'max_depth': 10, 'n_estimators': 848, 'class_weight': None, 'min_child_samples': 50, 'subsample': 0.7640468378884816, 'colsample_bytree': 0.8712131933560165, 'reg_alpha': 0.6414285677063635, 'reg_lambda': 0.7908596112798829}. Best is trial 14 with value: 0.6081871131790887.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:26:11,877]\u001b[0m Trial 15 finished with value: 0.5982445090482978 and parameters: {'num_leaves': 49, 'max_depth': 10, 'n_estimators': 909, 'class_weight': None, 'min_child_samples': 50, 'subsample': 0.762797751963601, 'colsample_bytree': 0.8780803166687843, 'reg_alpha': 0.5733687375084815, 'reg_lambda': 0.2743281175810539}. Best is trial 14 with value: 0.6081871131790887.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:26:32,337]\u001b[0m Trial 16 finished with value: 0.5848756527547299 and parameters: {'num_leaves': 342, 'max_depth': 8, 'n_estimators': 902, 'class_weight': None, 'min_child_samples': 50, 'subsample': 0.7630178590654536, 'colsample_bytree': 0.9508566829081853, 'reg_alpha': 0.5395124716958695, 'reg_lambda': 1.6863084810335915}. Best is trial 14 with value: 0.6081871131790887.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:26:41,832]\u001b[0m Trial 17 finished with value: 0.5535444342146286 and parameters: {'num_leaves': 46, 'max_depth': 10, 'n_estimators': 453, 'class_weight': None, 'min_child_samples': 42, 'subsample': 0.7604893575450252, 'colsample_bytree': 0.8854385251097042, 'reg_alpha': 0.5156114322398435, 'reg_lambda': 1.8908519182184789}. Best is trial 14 with value: 0.6081871131790887.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:26:55,635]\u001b[0m Trial 18 finished with value: 0.5431421132599825 and parameters: {'num_leaves': 305, 'max_depth': 6, 'n_estimators': 1007, 'class_weight': None, 'min_child_samples': 37, 'subsample': 0.7643098819876122, 'colsample_bytree': 0.7915417861706047, 'reg_alpha': 0.6182405676680487, 'reg_lambda': 0.04625751077198498}. Best is trial 14 with value: 0.6081871131790887.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:26:56,788]\u001b[0m Trial 19 finished with value: 0.29339989700046226 and parameters: {'num_leaves': 27, 'max_depth': 9, 'n_estimators': 53, 'class_weight': None, 'min_child_samples': 46, 'subsample': 0.7398222238622132, 'colsample_bytree': 0.9739373588416016, 'reg_alpha': 0.41597367093408055, 'reg_lambda': 2.489838579905267}. Best is trial 14 with value: 0.6081871131790887.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: score 0.6081871131790887,\n",
            "params: {'num_leaves': 70, 'max_depth': 10, 'n_estimators': 848, 'class_weight': None, 'min_child_samples': 50, 'subsample': 0.7640468378884816, 'colsample_bytree': 0.8712131933560165, 'reg_alpha': 0.6414285677063635, 'reg_lambda': 0.7908596112798829}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:27:05,257]\u001b[0m A new study created in memory with name: no-name-f3a8b9c5-7504-4419-b5e0-f093a288e57f\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------- AL ---------------\n",
            "Train R^2 score is 0.2628\n",
            "Validation R^2 score is 0.1882\n",
            "\n",
            "--------------- SI ---------------\n",
            "maximize\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:27:05,950]\u001b[0m Trial 0 finished with value: 0.8257251895627205 and parameters: {'num_leaves': 143, 'max_depth': 1, 'n_estimators': 136, 'class_weight': 'balanced', 'min_child_samples': 13, 'subsample': 0.9799938913760752, 'colsample_bytree': 0.767743906850746, 'reg_alpha': 0.9962835907476746, 'reg_lambda': 9.183105567499075}. Best is trial 0 with value: 0.8257251895627205.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:27:06,754]\u001b[0m Trial 1 finished with value: 0.9352860619755632 and parameters: {'num_leaves': 54, 'max_depth': 5, 'n_estimators': 70, 'class_weight': None, 'min_child_samples': 12, 'subsample': 0.8480368074147762, 'colsample_bytree': 0.7636009796832597, 'reg_alpha': 0.8426963403931583, 'reg_lambda': 7.392657965157499}. Best is trial 1 with value: 0.9352860619755632.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:27:07,176]\u001b[0m Trial 2 finished with value: 0.6075072428936601 and parameters: {'num_leaves': 328, 'max_depth': 10, 'n_estimators': 12, 'class_weight': None, 'min_child_samples': 37, 'subsample': 0.9093007718001115, 'colsample_bytree': 0.8595503274181867, 'reg_alpha': 0.7905560760427327, 'reg_lambda': 0.31562653789947603}. Best is trial 1 with value: 0.9352860619755632.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:27:07,546]\u001b[0m Trial 3 finished with value: 0.7706177263064915 and parameters: {'num_leaves': 4, 'max_depth': 3, 'n_estimators': 26, 'class_weight': 'balanced', 'min_child_samples': 43, 'subsample': 0.8590267083029292, 'colsample_bytree': 0.8076732052111129, 'reg_alpha': 0.6882693725211915, 'reg_lambda': 0.9814080625004451}. Best is trial 1 with value: 0.9352860619755632.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:27:11,828]\u001b[0m Trial 4 finished with value: 0.9377419223619146 and parameters: {'num_leaves': 3, 'max_depth': 4, 'n_estimators': 977, 'class_weight': None, 'min_child_samples': 12, 'subsample': 0.8851903599487574, 'colsample_bytree': 0.907772458721577, 'reg_alpha': 0.0876301313899781, 'reg_lambda': 4.631948548494076}. Best is trial 4 with value: 0.9377419223619146.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:27:14,532]\u001b[0m Trial 5 finished with value: 0.846316859013605 and parameters: {'num_leaves': 848, 'max_depth': 1, 'n_estimators': 633, 'class_weight': 'balanced', 'min_child_samples': 13, 'subsample': 0.9691660489763501, 'colsample_bytree': 0.8252427698027099, 'reg_alpha': 0.8738476485178298, 'reg_lambda': 7.3344595790408516}. Best is trial 4 with value: 0.9377419223619146.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:27:16,229]\u001b[0m Trial 6 finished with value: 0.9470505221252239 and parameters: {'num_leaves': 32, 'max_depth': 8, 'n_estimators': 128, 'class_weight': 'balanced', 'min_child_samples': 17, 'subsample': 0.8360058004106895, 'colsample_bytree': 0.7033497596579811, 'reg_alpha': 0.701603824460367, 'reg_lambda': 5.581986522140423}. Best is trial 6 with value: 0.9470505221252239.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:27:16,655]\u001b[0m Trial 7 finished with value: 0.820693975345159 and parameters: {'num_leaves': 3, 'max_depth': 6, 'n_estimators': 43, 'class_weight': None, 'min_child_samples': 16, 'subsample': 0.7142740916300729, 'colsample_bytree': 0.9516736611119074, 'reg_alpha': 0.7983028684390908, 'reg_lambda': 9.002110168355667}. Best is trial 6 with value: 0.9470505221252239.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:27:18,046]\u001b[0m Trial 8 finished with value: 0.9474044610161172 and parameters: {'num_leaves': 520, 'max_depth': 4, 'n_estimators': 129, 'class_weight': None, 'min_child_samples': 10, 'subsample': 0.8688407882628019, 'colsample_bytree': 0.9905252179924785, 'reg_alpha': 0.1599751828999859, 'reg_lambda': 4.595976791204036}. Best is trial 8 with value: 0.9474044610161172.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:27:24,241]\u001b[0m Trial 9 finished with value: 0.9441215391627171 and parameters: {'num_leaves': 5, 'max_depth': 9, 'n_estimators': 705, 'class_weight': 'balanced', 'min_child_samples': 30, 'subsample': 0.9009861579779896, 'colsample_bytree': 0.887053007790741, 'reg_alpha': 0.17540436309254726, 'reg_lambda': 6.032962633767436}. Best is trial 8 with value: 0.9474044610161172.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:27:28,214]\u001b[0m Trial 10 finished with value: 0.9496204599921347 and parameters: {'num_leaves': 21, 'max_depth': 7, 'n_estimators': 342, 'class_weight': None, 'min_child_samples': 26, 'subsample': 0.7717243954894576, 'colsample_bytree': 0.9959698183310384, 'reg_alpha': 0.3362854792158663, 'reg_lambda': 2.655620025689621}. Best is trial 10 with value: 0.9496204599921347.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:27:31,478]\u001b[0m Trial 11 finished with value: 0.9497070844836166 and parameters: {'num_leaves': 19, 'max_depth': 7, 'n_estimators': 282, 'class_weight': None, 'min_child_samples': 24, 'subsample': 0.7560913630836743, 'colsample_bytree': 0.9986800495271416, 'reg_alpha': 0.2834822633693781, 'reg_lambda': 3.036692662204046}. Best is trial 11 with value: 0.9497070844836166.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:27:35,319]\u001b[0m Trial 12 finished with value: 0.9513327007035828 and parameters: {'num_leaves': 16, 'max_depth': 7, 'n_estimators': 318, 'class_weight': None, 'min_child_samples': 24, 'subsample': 0.7473890980384795, 'colsample_bytree': 0.9973524279537528, 'reg_alpha': 0.3764324688902722, 'reg_lambda': 2.4839345407155387}. Best is trial 12 with value: 0.9513327007035828.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:27:37,957]\u001b[0m Trial 13 finished with value: 0.9483716968683902 and parameters: {'num_leaves': 11, 'max_depth': 7, 'n_estimators': 280, 'class_weight': None, 'min_child_samples': 23, 'subsample': 0.7045415193304947, 'colsample_bytree': 0.9567539398693385, 'reg_alpha': 0.442289158203636, 'reg_lambda': 2.7581897588961457}. Best is trial 12 with value: 0.9513327007035828.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:27:41,088]\u001b[0m Trial 14 finished with value: 0.9519475203539466 and parameters: {'num_leaves': 81, 'max_depth': 7, 'n_estimators': 271, 'class_weight': None, 'min_child_samples': 22, 'subsample': 0.7662545956479517, 'colsample_bytree': 0.9266408923883084, 'reg_alpha': 0.31551458040922087, 'reg_lambda': 2.3734690263127862}. Best is trial 14 with value: 0.9519475203539466.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:27:45,871]\u001b[0m Trial 15 finished with value: 0.9515186498309192 and parameters: {'num_leaves': 78, 'max_depth': 9, 'n_estimators': 405, 'class_weight': None, 'min_child_samples': 37, 'subsample': 0.7971534289820623, 'colsample_bytree': 0.9286734557788046, 'reg_alpha': 0.5227063995993451, 'reg_lambda': 1.6114909751297035}. Best is trial 14 with value: 0.9519475203539466.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:27:52,908]\u001b[0m Trial 16 finished with value: 0.9531764646267329 and parameters: {'num_leaves': 91, 'max_depth': 10, 'n_estimators': 502, 'class_weight': None, 'min_child_samples': 37, 'subsample': 0.7949213186352858, 'colsample_bytree': 0.9204650297336473, 'reg_alpha': 0.5574546496995417, 'reg_lambda': 1.5112104629989398}. Best is trial 16 with value: 0.9531764646267329.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:27:55,704]\u001b[0m Trial 17 finished with value: 0.9440787559392915 and parameters: {'num_leaves': 167, 'max_depth': 10, 'n_estimators': 178, 'class_weight': None, 'min_child_samples': 49, 'subsample': 0.7978079812757475, 'colsample_bytree': 0.8832700198018602, 'reg_alpha': 0.5681230693761901, 'reg_lambda': 0.1504554081682128}. Best is trial 16 with value: 0.9531764646267329.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:28:03,623]\u001b[0m Trial 18 finished with value: 0.9541353726131583 and parameters: {'num_leaves': 109, 'max_depth': 9, 'n_estimators': 570, 'class_weight': None, 'min_child_samples': 35, 'subsample': 0.8040309932213939, 'colsample_bytree': 0.9217867670248551, 'reg_alpha': 0.6130328946100312, 'reg_lambda': 3.9126732376444413}. Best is trial 18 with value: 0.9541353726131583.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:28:10,582]\u001b[0m Trial 19 finished with value: 0.9542840758851808 and parameters: {'num_leaves': 243, 'max_depth': 9, 'n_estimators': 583, 'class_weight': None, 'min_child_samples': 36, 'subsample': 0.8103562064832186, 'colsample_bytree': 0.8538149342544242, 'reg_alpha': 0.6170348755703685, 'reg_lambda': 3.7786866639736303}. Best is trial 19 with value: 0.9542840758851808.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: score 0.9542840758851808,\n",
            "params: {'num_leaves': 243, 'max_depth': 9, 'n_estimators': 583, 'class_weight': None, 'min_child_samples': 36, 'subsample': 0.8103562064832186, 'colsample_bytree': 0.8538149342544242, 'reg_alpha': 0.6170348755703685, 'reg_lambda': 3.7786866639736303}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:28:13,535]\u001b[0m A new study created in memory with name: no-name-a0a85802-74b2-45f4-a17d-6d744426dbf3\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------- SI ---------------\n",
            "Train R^2 score is 0.5987\n",
            "Validation R^2 score is 0.4938\n",
            "\n",
            "--------------- BA ---------------\n",
            "maximize\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:28:14,038]\u001b[0m Trial 0 finished with value: 0.08220810500933821 and parameters: {'num_leaves': 25, 'max_depth': 6, 'n_estimators': 16, 'class_weight': None, 'min_child_samples': 32, 'subsample': 0.8012580415588464, 'colsample_bytree': 0.8635511024519111, 'reg_alpha': 0.11953806553199997, 'reg_lambda': 5.202899356526082}. Best is trial 0 with value: 0.08220810500933821.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:28:14,530]\u001b[0m Trial 1 finished with value: 0.07162446155326865 and parameters: {'num_leaves': 104, 'max_depth': 6, 'n_estimators': 11, 'class_weight': None, 'min_child_samples': 29, 'subsample': 0.9295242261732659, 'colsample_bytree': 0.976694055011272, 'reg_alpha': 0.5446639359382924, 'reg_lambda': 5.4835825169693395}. Best is trial 0 with value: 0.08220810500933821.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:28:15,086]\u001b[0m Trial 2 finished with value: 0.03379156075326641 and parameters: {'num_leaves': 2, 'max_depth': 8, 'n_estimators': 41, 'class_weight': None, 'min_child_samples': 41, 'subsample': 0.7963334607654151, 'colsample_bytree': 0.9875232253448294, 'reg_alpha': 0.6410641859455986, 'reg_lambda': 1.353261066841176}. Best is trial 0 with value: 0.08220810500933821.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:28:15,854]\u001b[0m Trial 3 finished with value: 0.03815345154530168 and parameters: {'num_leaves': 2, 'max_depth': 6, 'n_estimators': 52, 'class_weight': None, 'min_child_samples': 37, 'subsample': 0.8742294847605451, 'colsample_bytree': 0.9425433451220668, 'reg_alpha': 0.09431836701718632, 'reg_lambda': 5.496260379282756}. Best is trial 0 with value: 0.08220810500933821.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:28:16,503]\u001b[0m Trial 4 finished with value: -0.5411661980498321 and parameters: {'num_leaves': 12, 'max_depth': 5, 'n_estimators': 19, 'class_weight': 'balanced', 'min_child_samples': 46, 'subsample': 0.7986248923147907, 'colsample_bytree': 0.768500453592124, 'reg_alpha': 0.5564319794363585, 'reg_lambda': 1.467846255830959}. Best is trial 0 with value: 0.08220810500933821.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:28:19,081]\u001b[0m Trial 5 finished with value: 0.14966658299539762 and parameters: {'num_leaves': 426, 'max_depth': 3, 'n_estimators': 257, 'class_weight': None, 'min_child_samples': 30, 'subsample': 0.9165686896337046, 'colsample_bytree': 0.9153094410538393, 'reg_alpha': 0.3194211550746142, 'reg_lambda': 6.925945008624982}. Best is trial 5 with value: 0.14966658299539762.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:28:19,710]\u001b[0m Trial 6 finished with value: 0.02500486286999304 and parameters: {'num_leaves': 3, 'max_depth': 9, 'n_estimators': 12, 'class_weight': None, 'min_child_samples': 18, 'subsample': 0.757865888636225, 'colsample_bytree': 0.9469767333758203, 'reg_alpha': 0.1913047218729642, 'reg_lambda': 5.146946053381821}. Best is trial 5 with value: 0.14966658299539762.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:28:20,493]\u001b[0m Trial 7 finished with value: 0.04011167126654991 and parameters: {'num_leaves': 704, 'max_depth': 3, 'n_estimators': 11, 'class_weight': None, 'min_child_samples': 39, 'subsample': 0.9716715573239582, 'colsample_bytree': 0.7197000980608586, 'reg_alpha': 0.6555727768748467, 'reg_lambda': 3.023259109948188}. Best is trial 5 with value: 0.14966658299539762.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:28:20,909]\u001b[0m Trial 8 finished with value: -0.361754664429048 and parameters: {'num_leaves': 113, 'max_depth': 4, 'n_estimators': 12, 'class_weight': 'balanced', 'min_child_samples': 38, 'subsample': 0.9282746685223451, 'colsample_bytree': 0.9398970913260527, 'reg_alpha': 0.1899289756140311, 'reg_lambda': 4.816285551389488}. Best is trial 5 with value: 0.14966658299539762.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:28:22,475]\u001b[0m Trial 9 finished with value: 0.1681389643144551 and parameters: {'num_leaves': 437, 'max_depth': 5, 'n_estimators': 111, 'class_weight': None, 'min_child_samples': 29, 'subsample': 0.920591785805388, 'colsample_bytree': 0.7332502467488946, 'reg_alpha': 0.9335331111093795, 'reg_lambda': 2.1396661110511275}. Best is trial 9 with value: 0.1681389643144551.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:28:27,925]\u001b[0m Trial 10 finished with value: -0.5724088812503727 and parameters: {'num_leaves': 217, 'max_depth': 1, 'n_estimators': 704, 'class_weight': 'balanced', 'min_child_samples': 10, 'subsample': 0.8625676163846904, 'colsample_bytree': 0.7741202076047151, 'reg_alpha': 0.9968947333841189, 'reg_lambda': 9.633358692317648}. Best is trial 9 with value: 0.1681389643144551.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:28:31,220]\u001b[0m Trial 11 finished with value: 0.10746576370623336 and parameters: {'num_leaves': 1020, 'max_depth': 2, 'n_estimators': 243, 'class_weight': None, 'min_child_samples': 26, 'subsample': 0.9904002966109074, 'colsample_bytree': 0.8634928529902751, 'reg_alpha': 0.9429355037783077, 'reg_lambda': 8.806443093941931}. Best is trial 9 with value: 0.1681389643144551.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:28:34,097]\u001b[0m Trial 12 finished with value: 0.16910903445347547 and parameters: {'num_leaves': 268, 'max_depth': 4, 'n_estimators': 190, 'class_weight': None, 'min_child_samples': 22, 'subsample': 0.9054995784514466, 'colsample_bytree': 0.8200294787177866, 'reg_alpha': 0.3687649385634527, 'reg_lambda': 7.716081302692844}. Best is trial 12 with value: 0.16910903445347547.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:28:37,980]\u001b[0m Trial 13 finished with value: 0.27093172333351767 and parameters: {'num_leaves': 221, 'max_depth': 8, 'n_estimators': 160, 'class_weight': None, 'min_child_samples': 21, 'subsample': 0.8907364102131425, 'colsample_bytree': 0.8022703583942661, 'reg_alpha': 0.8220001135105761, 'reg_lambda': 0.13485035331627193}. Best is trial 13 with value: 0.27093172333351767.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:28:44,134]\u001b[0m Trial 14 finished with value: 0.29671454658316526 and parameters: {'num_leaves': 57, 'max_depth': 10, 'n_estimators': 185, 'class_weight': None, 'min_child_samples': 21, 'subsample': 0.7141011521363032, 'colsample_bytree': 0.8143922279541808, 'reg_alpha': 0.3804177292161908, 'reg_lambda': 7.818525776276584}. Best is trial 14 with value: 0.29671454658316526.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:28:56,163]\u001b[0m Trial 15 finished with value: -1.1870434273080828 and parameters: {'num_leaves': 50, 'max_depth': 10, 'n_estimators': 431, 'class_weight': 'balanced', 'min_child_samples': 16, 'subsample': 0.7017319885542846, 'colsample_bytree': 0.8165878660056494, 'reg_alpha': 0.7842128636255344, 'reg_lambda': 0.08596572563539531}. Best is trial 14 with value: 0.29671454658316526.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:28:57,943]\u001b[0m Trial 16 finished with value: 0.17097088537488292 and parameters: {'num_leaves': 11, 'max_depth': 8, 'n_estimators': 124, 'class_weight': None, 'min_child_samples': 13, 'subsample': 0.7012905947011239, 'colsample_bytree': 0.8146614591749063, 'reg_alpha': 0.4296626849601402, 'reg_lambda': 3.6478106581347385}. Best is trial 14 with value: 0.29671454658316526.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:28:59,965]\u001b[0m Trial 17 finished with value: 0.21447573550677115 and parameters: {'num_leaves': 60, 'max_depth': 10, 'n_estimators': 55, 'class_weight': None, 'min_child_samples': 22, 'subsample': 0.8325728093969503, 'colsample_bytree': 0.7720061987503508, 'reg_alpha': 0.8159620147101325, 'reg_lambda': 7.069305219185983}. Best is trial 14 with value: 0.29671454658316526.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:29:06,367]\u001b[0m Trial 18 finished with value: -1.3803697246661655 and parameters: {'num_leaves': 22, 'max_depth': 8, 'n_estimators': 459, 'class_weight': 'balanced', 'min_child_samples': 22, 'subsample': 0.7454446662055698, 'colsample_bytree': 0.8886537856741356, 'reg_alpha': 0.7485230044426164, 'reg_lambda': 8.290515389803332}. Best is trial 14 with value: 0.29671454658316526.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:29:41,787]\u001b[0m Trial 19 finished with value: 0.3576757163920209 and parameters: {'num_leaves': 139, 'max_depth': 9, 'n_estimators': 1003, 'class_weight': None, 'min_child_samples': 17, 'subsample': 0.8310620792011476, 'colsample_bytree': 0.8351437045118777, 'reg_alpha': 0.45823637967741804, 'reg_lambda': 6.524889983127004}. Best is trial 19 with value: 0.3576757163920209.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: score 0.3576757163920209,\n",
            "params: {'num_leaves': 139, 'max_depth': 9, 'n_estimators': 1003, 'class_weight': None, 'min_child_samples': 17, 'subsample': 0.8310620792011476, 'colsample_bytree': 0.8351437045118777, 'reg_alpha': 0.45823637967741804, 'reg_lambda': 6.524889983127004}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:29:55,017]\u001b[0m A new study created in memory with name: no-name-6ffc0ca1-c611-4550-9d8b-ab9b13722aa4\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------- BA ---------------\n",
            "Train R^2 score is 0.2321\n",
            "Validation R^2 score is 0.0588\n",
            "\n",
            "--------------- K ---------------\n",
            "maximize\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:29:58,059]\u001b[0m Trial 0 finished with value: 0.5859568145297361 and parameters: {'num_leaves': 40, 'max_depth': 8, 'n_estimators': 269, 'class_weight': None, 'min_child_samples': 38, 'subsample': 0.7540810832803921, 'colsample_bytree': 0.7578198639492527, 'reg_alpha': 0.605771316772862, 'reg_lambda': 2.290299598166712}. Best is trial 0 with value: 0.5859568145297361.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:29:58,617]\u001b[0m Trial 1 finished with value: 0.3476657997947306 and parameters: {'num_leaves': 14, 'max_depth': 3, 'n_estimators': 68, 'class_weight': None, 'min_child_samples': 40, 'subsample': 0.8532113180486331, 'colsample_bytree': 0.8645871192860982, 'reg_alpha': 0.35444732416553726, 'reg_lambda': 5.794727684843508}. Best is trial 0 with value: 0.5859568145297361.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:29:59,025]\u001b[0m Trial 2 finished with value: 0.23310823221199542 and parameters: {'num_leaves': 430, 'max_depth': 6, 'n_estimators': 8, 'class_weight': 'balanced', 'min_child_samples': 14, 'subsample': 0.7026514776865325, 'colsample_bytree': 0.7013808009686422, 'reg_alpha': 0.8180094460445674, 'reg_lambda': 0.6560381750571642}. Best is trial 0 with value: 0.5859568145297361.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:30:00,326]\u001b[0m Trial 3 finished with value: 0.41453299961869916 and parameters: {'num_leaves': 281, 'max_depth': 9, 'n_estimators': 51, 'class_weight': None, 'min_child_samples': 45, 'subsample': 0.9599988791917518, 'colsample_bytree': 0.8862497283661188, 'reg_alpha': 0.11668080108652623, 'reg_lambda': 1.6859568080138032}. Best is trial 0 with value: 0.5859568145297361.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:30:03,620]\u001b[0m Trial 4 finished with value: 0.2490464243534439 and parameters: {'num_leaves': 32, 'max_depth': 7, 'n_estimators': 286, 'class_weight': 'balanced', 'min_child_samples': 37, 'subsample': 0.9963733821326585, 'colsample_bytree': 0.8898044675934424, 'reg_alpha': 0.5788197861015549, 'reg_lambda': 0.7794103212705494}. Best is trial 0 with value: 0.5859568145297361.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:30:05,522]\u001b[0m Trial 5 finished with value: 0.3484666819507755 and parameters: {'num_leaves': 565, 'max_depth': 9, 'n_estimators': 52, 'class_weight': 'balanced', 'min_child_samples': 12, 'subsample': 0.9161778407138398, 'colsample_bytree': 0.9643937270079277, 'reg_alpha': 0.04370181640498927, 'reg_lambda': 0.5121858865393047}. Best is trial 0 with value: 0.5859568145297361.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:30:06,278]\u001b[0m Trial 6 finished with value: 0.19191192602116805 and parameters: {'num_leaves': 7, 'max_depth': 1, 'n_estimators': 170, 'class_weight': 'balanced', 'min_child_samples': 44, 'subsample': 0.8970882645331096, 'colsample_bytree': 0.7085282855562541, 'reg_alpha': 0.1387400785413342, 'reg_lambda': 7.008341106849616}. Best is trial 0 with value: 0.5859568145297361.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:30:06,644]\u001b[0m Trial 7 finished with value: 0.21435820053319973 and parameters: {'num_leaves': 36, 'max_depth': 10, 'n_estimators': 8, 'class_weight': None, 'min_child_samples': 10, 'subsample': 0.8022655245776522, 'colsample_bytree': 0.8683713950024308, 'reg_alpha': 0.5340331833724877, 'reg_lambda': 7.592961936147969}. Best is trial 0 with value: 0.5859568145297361.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:30:07,611]\u001b[0m Trial 8 finished with value: 0.41915162683893853 and parameters: {'num_leaves': 26, 'max_depth': 5, 'n_estimators': 103, 'class_weight': None, 'min_child_samples': 40, 'subsample': 0.8738374276058352, 'colsample_bytree': 0.7818138956315939, 'reg_alpha': 0.7838085939635285, 'reg_lambda': 5.5686079206632595}. Best is trial 0 with value: 0.5859568145297361.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:30:08,669]\u001b[0m Trial 9 finished with value: 0.2029253590392864 and parameters: {'num_leaves': 792, 'max_depth': 9, 'n_estimators': 30, 'class_weight': 'balanced', 'min_child_samples': 39, 'subsample': 0.941579281668896, 'colsample_bytree': 0.9981855222590685, 'reg_alpha': 0.1302957073459181, 'reg_lambda': 4.206430930051263}. Best is trial 0 with value: 0.5859568145297361.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:30:11,551]\u001b[0m Trial 10 finished with value: 0.33008144106402854 and parameters: {'num_leaves': 2, 'max_depth': 7, 'n_estimators': 922, 'class_weight': None, 'min_child_samples': 23, 'subsample': 0.7452250305417791, 'colsample_bytree': 0.7865263145594277, 'reg_alpha': 0.9778611623259837, 'reg_lambda': 3.2404559271637727}. Best is trial 0 with value: 0.5859568145297361.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:30:14,216]\u001b[0m Trial 11 finished with value: 0.5027384264437237 and parameters: {'num_leaves': 122, 'max_depth': 4, 'n_estimators': 326, 'class_weight': None, 'min_child_samples': 30, 'subsample': 0.8075642618829679, 'colsample_bytree': 0.7808728968912727, 'reg_alpha': 0.721942238358224, 'reg_lambda': 9.826715419396276}. Best is trial 0 with value: 0.5859568145297361.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:30:17,629]\u001b[0m Trial 12 finished with value: 0.5879804118132386 and parameters: {'num_leaves': 117, 'max_depth': 4, 'n_estimators': 553, 'class_weight': None, 'min_child_samples': 30, 'subsample': 0.7948014336233626, 'colsample_bytree': 0.7844874746182652, 'reg_alpha': 0.6867741620036641, 'reg_lambda': 8.369232931644213}. Best is trial 12 with value: 0.5879804118132386.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:30:21,263]\u001b[0m Trial 13 finished with value: 0.5122447512793714 and parameters: {'num_leaves': 127, 'max_depth': 2, 'n_estimators': 852, 'class_weight': None, 'min_child_samples': 29, 'subsample': 0.7860830906399592, 'colsample_bytree': 0.7477302733857688, 'reg_alpha': 0.38157000443191624, 'reg_lambda': 9.94933316947365}. Best is trial 12 with value: 0.5879804118132386.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:30:25,726]\u001b[0m Trial 14 finished with value: 0.6796027315493331 and parameters: {'num_leaves': 137, 'max_depth': 7, 'n_estimators': 436, 'class_weight': None, 'min_child_samples': 22, 'subsample': 0.7406520652733036, 'colsample_bytree': 0.8158734057254416, 'reg_alpha': 0.6521654777219238, 'reg_lambda': 2.767425293201822}. Best is trial 14 with value: 0.6796027315493331.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:30:28,662]\u001b[0m Trial 15 finished with value: 0.592422011286003 and parameters: {'num_leaves': 113, 'max_depth': 4, 'n_estimators': 475, 'class_weight': None, 'min_child_samples': 21, 'subsample': 0.7142844926764035, 'colsample_bytree': 0.8283695435732441, 'reg_alpha': 0.9803327065154694, 'reg_lambda': 8.221826554654475}. Best is trial 14 with value: 0.6796027315493331.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:30:32,703]\u001b[0m Trial 16 finished with value: 0.6583237448201655 and parameters: {'num_leaves': 215, 'max_depth': 5, 'n_estimators': 492, 'class_weight': None, 'min_child_samples': 19, 'subsample': 0.7014731874649732, 'colsample_bytree': 0.830486753986872, 'reg_alpha': 0.9152205218176935, 'reg_lambda': 4.0998120543586785}. Best is trial 14 with value: 0.6796027315493331.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:30:34,295]\u001b[0m Trial 17 finished with value: 0.551213831768113 and parameters: {'num_leaves': 248, 'max_depth': 6, 'n_estimators': 139, 'class_weight': None, 'min_child_samples': 19, 'subsample': 0.7438512498285874, 'colsample_bytree': 0.8284403486446218, 'reg_alpha': 0.8762839913369181, 'reg_lambda': 4.2409263459400615}. Best is trial 14 with value: 0.6796027315493331.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:30:43,094]\u001b[0m Trial 18 finished with value: 0.7367011034262451 and parameters: {'num_leaves': 1024, 'max_depth': 7, 'n_estimators': 579, 'class_weight': None, 'min_child_samples': 17, 'subsample': 0.7261201367215474, 'colsample_bytree': 0.9211360676975364, 'reg_alpha': 0.422254437708353, 'reg_lambda': 2.9046877881393245}. Best is trial 18 with value: 0.7367011034262451.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:30:43,820]\u001b[0m Trial 19 finished with value: 0.34485810415042756 and parameters: {'num_leaves': 941, 'max_depth': 7, 'n_estimators': 19, 'class_weight': None, 'min_child_samples': 26, 'subsample': 0.830105470895951, 'colsample_bytree': 0.9195186425608909, 'reg_alpha': 0.3717044065653975, 'reg_lambda': 2.6032867843107557}. Best is trial 18 with value: 0.7367011034262451.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: score 0.7367011034262451,\n",
            "params: {'num_leaves': 1024, 'max_depth': 7, 'n_estimators': 579, 'class_weight': None, 'min_child_samples': 17, 'subsample': 0.7261201367215474, 'colsample_bytree': 0.9211360676975364, 'reg_alpha': 0.422254437708353, 'reg_lambda': 2.9046877881393245}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:30:47,231]\u001b[0m A new study created in memory with name: no-name-60d3227a-2406-4b4b-89ba-ea9821c80ce2\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------- K ---------------\n",
            "Train R^2 score is 0.3414\n",
            "Validation R^2 score is 0.1452\n",
            "\n",
            "--------------- SB ---------------\n",
            "maximize\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:30:49,077]\u001b[0m Trial 0 finished with value: 0.6037813070089918 and parameters: {'num_leaves': 142, 'max_depth': 5, 'n_estimators': 216, 'class_weight': None, 'min_child_samples': 50, 'subsample': 0.7876389410763971, 'colsample_bytree': 0.7127238751804208, 'reg_alpha': 0.026626405203219128, 'reg_lambda': 5.200710225410572}. Best is trial 0 with value: 0.6037813070089918.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:30:54,019]\u001b[0m Trial 1 finished with value: 0.2785975208202297 and parameters: {'num_leaves': 111, 'max_depth': 10, 'n_estimators': 156, 'class_weight': 'balanced', 'min_child_samples': 13, 'subsample': 0.9927292358157898, 'colsample_bytree': 0.9119203019142077, 'reg_alpha': 0.8392252338961712, 'reg_lambda': 4.596475070041671}. Best is trial 0 with value: 0.6037813070089918.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:30:54,370]\u001b[0m Trial 2 finished with value: 0.04251783189760887 and parameters: {'num_leaves': 159, 'max_depth': 1, 'n_estimators': 49, 'class_weight': None, 'min_child_samples': 13, 'subsample': 0.7460065834712383, 'colsample_bytree': 0.7118181852076425, 'reg_alpha': 0.20947773250648483, 'reg_lambda': 3.6640547625971296}. Best is trial 0 with value: 0.6037813070089918.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:30:55,362]\u001b[0m Trial 3 finished with value: 0.43302835266156814 and parameters: {'num_leaves': 750, 'max_depth': 9, 'n_estimators': 20, 'class_weight': None, 'min_child_samples': 12, 'subsample': 0.7043445153446977, 'colsample_bytree': 0.8900964158844027, 'reg_alpha': 0.38614508709915796, 'reg_lambda': 1.1365272574819418}. Best is trial 0 with value: 0.6037813070089918.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:30:55,926]\u001b[0m Trial 4 finished with value: 0.05802412777806705 and parameters: {'num_leaves': 56, 'max_depth': 1, 'n_estimators': 104, 'class_weight': None, 'min_child_samples': 32, 'subsample': 0.9288375136778892, 'colsample_bytree': 0.9898448806785696, 'reg_alpha': 0.8474049456769502, 'reg_lambda': 4.045201716729596}. Best is trial 0 with value: 0.6037813070089918.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:30:56,315]\u001b[0m Trial 5 finished with value: 0.2248631110891019 and parameters: {'num_leaves': 506, 'max_depth': 2, 'n_estimators': 23, 'class_weight': 'balanced', 'min_child_samples': 11, 'subsample': 0.8478853828058222, 'colsample_bytree': 0.7587114571056998, 'reg_alpha': 0.3307285512788244, 'reg_lambda': 2.064039929622573}. Best is trial 0 with value: 0.6037813070089918.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:30:56,634]\u001b[0m Trial 6 finished with value: 0.16807606661569446 and parameters: {'num_leaves': 58, 'max_depth': 6, 'n_estimators': 8, 'class_weight': None, 'min_child_samples': 25, 'subsample': 0.9586585739460538, 'colsample_bytree': 0.7397277554214745, 'reg_alpha': 0.4114385728206972, 'reg_lambda': 5.159253734414593}. Best is trial 0 with value: 0.6037813070089918.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:30:57,789]\u001b[0m Trial 7 finished with value: -0.3253793589969982 and parameters: {'num_leaves': 21, 'max_depth': 3, 'n_estimators': 154, 'class_weight': 'balanced', 'min_child_samples': 36, 'subsample': 0.8552191001046731, 'colsample_bytree': 0.8513426465471395, 'reg_alpha': 0.14693609028144128, 'reg_lambda': 9.65901278717539}. Best is trial 0 with value: 0.6037813070089918.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:31:04,149]\u001b[0m Trial 8 finished with value: 0.19606937012633457 and parameters: {'num_leaves': 7, 'max_depth': 7, 'n_estimators': 653, 'class_weight': 'balanced', 'min_child_samples': 13, 'subsample': 0.7835064940504047, 'colsample_bytree': 0.9941846109522745, 'reg_alpha': 0.7851042207149131, 'reg_lambda': 4.170870575223119}. Best is trial 0 with value: 0.6037813070089918.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:31:04,456]\u001b[0m Trial 9 finished with value: 0.10509736492647284 and parameters: {'num_leaves': 5, 'max_depth': 3, 'n_estimators': 13, 'class_weight': 'balanced', 'min_child_samples': 48, 'subsample': 0.7103731838012785, 'colsample_bytree': 0.7668231010980073, 'reg_alpha': 0.5955519053783255, 'reg_lambda': 9.079064013543677}. Best is trial 0 with value: 0.6037813070089918.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:31:06,311]\u001b[0m Trial 10 finished with value: 0.10646676974518196 and parameters: {'num_leaves': 2, 'max_depth': 5, 'n_estimators': 555, 'class_weight': None, 'min_child_samples': 50, 'subsample': 0.8217677024245224, 'colsample_bytree': 0.8084982946930918, 'reg_alpha': 0.006427955438898791, 'reg_lambda': 6.939636088522775}. Best is trial 0 with value: 0.6037813070089918.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:31:07,684]\u001b[0m Trial 11 finished with value: 0.47850520707846345 and parameters: {'num_leaves': 791, 'max_depth': 9, 'n_estimators': 48, 'class_weight': None, 'min_child_samples': 40, 'subsample': 0.7077788553434397, 'colsample_bytree': 0.8829739357713086, 'reg_alpha': 0.6061367466185182, 'reg_lambda': 0.32146014657082145}. Best is trial 0 with value: 0.6037813070089918.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:31:12,481]\u001b[0m Trial 12 finished with value: 0.6738572176615668 and parameters: {'num_leaves': 313, 'max_depth': 8, 'n_estimators': 277, 'class_weight': None, 'min_child_samples': 41, 'subsample': 0.7826960029982292, 'colsample_bytree': 0.9304954963476965, 'reg_alpha': 0.608123727130876, 'reg_lambda': 0.024856408941155095}. Best is trial 12 with value: 0.6738572176615668.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:31:16,914]\u001b[0m Trial 13 finished with value: 0.6638231123399253 and parameters: {'num_leaves': 238, 'max_depth': 7, 'n_estimators': 327, 'class_weight': None, 'min_child_samples': 44, 'subsample': 0.7858805853823172, 'colsample_bytree': 0.9374577519804927, 'reg_alpha': 0.99028227473378, 'reg_lambda': 7.743620715376876}. Best is trial 12 with value: 0.6738572176615668.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:31:22,586]\u001b[0m Trial 14 finished with value: 0.6590802516513106 and parameters: {'num_leaves': 300, 'max_depth': 7, 'n_estimators': 303, 'class_weight': None, 'min_child_samples': 42, 'subsample': 0.8766089036346478, 'colsample_bytree': 0.9521520977760581, 'reg_alpha': 0.9920210903828399, 'reg_lambda': 7.54400857160614}. Best is trial 12 with value: 0.6738572176615668.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:31:42,371]\u001b[0m Trial 15 finished with value: 0.7137459826889792 and parameters: {'num_leaves': 287, 'max_depth': 8, 'n_estimators': 989, 'class_weight': None, 'min_child_samples': 43, 'subsample': 0.7749413984278843, 'colsample_bytree': 0.9472053259546441, 'reg_alpha': 0.6691258129000416, 'reg_lambda': 6.69201686026645}. Best is trial 15 with value: 0.7137459826889792.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:31:58,548]\u001b[0m Trial 16 finished with value: 0.7225850169227097 and parameters: {'num_leaves': 16, 'max_depth': 8, 'n_estimators': 946, 'class_weight': None, 'min_child_samples': 27, 'subsample': 0.7511111019753454, 'colsample_bytree': 0.947451556886148, 'reg_alpha': 0.6496987332540506, 'reg_lambda': 6.432728968725736}. Best is trial 16 with value: 0.7225850169227097.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:32:17,137]\u001b[0m Trial 17 finished with value: 0.7156154535152773 and parameters: {'num_leaves': 21, 'max_depth': 10, 'n_estimators': 950, 'class_weight': None, 'min_child_samples': 24, 'subsample': 0.7467063812923055, 'colsample_bytree': 0.842641131215377, 'reg_alpha': 0.6877471658528842, 'reg_lambda': 6.572991789808686}. Best is trial 16 with value: 0.7225850169227097.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:32:26,451]\u001b[0m Trial 18 finished with value: 0.7213063822130457 and parameters: {'num_leaves': 16, 'max_depth': 10, 'n_estimators': 923, 'class_weight': None, 'min_child_samples': 24, 'subsample': 0.7489624257466649, 'colsample_bytree': 0.810330385499488, 'reg_alpha': 0.5026344198985696, 'reg_lambda': 6.067603790072588}. Best is trial 16 with value: 0.7225850169227097.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:32:30,743]\u001b[0m Trial 19 finished with value: 0.7248406893733225 and parameters: {'num_leaves': 11, 'max_depth': 9, 'n_estimators': 509, 'class_weight': None, 'min_child_samples': 20, 'subsample': 0.8204570274684536, 'colsample_bytree': 0.8034045713953912, 'reg_alpha': 0.5075057407907669, 'reg_lambda': 2.6852986962989673}. Best is trial 19 with value: 0.7248406893733225.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: score 0.7248406893733225,\n",
            "params: {'num_leaves': 11, 'max_depth': 9, 'n_estimators': 509, 'class_weight': None, 'min_child_samples': 20, 'subsample': 0.8204570274684536, 'colsample_bytree': 0.8034045713953912, 'reg_alpha': 0.5075057407907669, 'reg_lambda': 2.6852986962989673}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:32:32,559]\u001b[0m A new study created in memory with name: no-name-fac4fd5d-1a0f-428e-a1fa-90545ffd46a8\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------- SB ---------------\n",
            "Train R^2 score is 0.3131\n",
            "Validation R^2 score is 0.1215\n",
            "\n",
            "--------------- MG ---------------\n",
            "maximize\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:32:33,633]\u001b[0m Trial 0 finished with value: 0.1927990388475192 and parameters: {'num_leaves': 2, 'max_depth': 2, 'n_estimators': 182, 'class_weight': None, 'min_child_samples': 18, 'subsample': 0.7391635078824773, 'colsample_bytree': 0.9218088242398209, 'reg_alpha': 0.8815346675975864, 'reg_lambda': 3.468130628528918}. Best is trial 0 with value: 0.1927990388475192.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:32:36,436]\u001b[0m Trial 1 finished with value: 0.09085927164326164 and parameters: {'num_leaves': 2, 'max_depth': 10, 'n_estimators': 756, 'class_weight': 'balanced', 'min_child_samples': 31, 'subsample': 0.8708580050326465, 'colsample_bytree': 0.704825214770281, 'reg_alpha': 0.1394888317895927, 'reg_lambda': 8.433226560345854}. Best is trial 0 with value: 0.1927990388475192.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:32:37,286]\u001b[0m Trial 2 finished with value: 0.3187573797756896 and parameters: {'num_leaves': 734, 'max_depth': 2, 'n_estimators': 106, 'class_weight': None, 'min_child_samples': 16, 'subsample': 0.740350121495525, 'colsample_bytree': 0.9872026798255711, 'reg_alpha': 0.020698655016653467, 'reg_lambda': 8.397068660512105}. Best is trial 2 with value: 0.3187573797756896.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:32:37,745]\u001b[0m Trial 3 finished with value: 0.2101740284071588 and parameters: {'num_leaves': 828, 'max_depth': 2, 'n_estimators': 29, 'class_weight': None, 'min_child_samples': 49, 'subsample': 0.8013553633325332, 'colsample_bytree': 0.9690567582893885, 'reg_alpha': 0.7868801246203947, 'reg_lambda': 1.6619391353997193}. Best is trial 2 with value: 0.3187573797756896.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:32:42,895]\u001b[0m Trial 4 finished with value: 0.5524244732891946 and parameters: {'num_leaves': 5, 'max_depth': 5, 'n_estimators': 763, 'class_weight': None, 'min_child_samples': 30, 'subsample': 0.8776284977673332, 'colsample_bytree': 0.919176091181878, 'reg_alpha': 0.05048887725436746, 'reg_lambda': 8.227629646001244}. Best is trial 4 with value: 0.5524244732891946.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:32:43,564]\u001b[0m Trial 5 finished with value: 0.2554800756050553 and parameters: {'num_leaves': 42, 'max_depth': 3, 'n_estimators': 33, 'class_weight': 'balanced', 'min_child_samples': 41, 'subsample': 0.7384410742139995, 'colsample_bytree': 0.954354792234275, 'reg_alpha': 0.5461013642744071, 'reg_lambda': 4.157411112653186}. Best is trial 4 with value: 0.5524244732891946.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:32:45,875]\u001b[0m Trial 6 finished with value: 0.26493125121203165 and parameters: {'num_leaves': 378, 'max_depth': 4, 'n_estimators': 187, 'class_weight': 'balanced', 'min_child_samples': 35, 'subsample': 0.986316328773191, 'colsample_bytree': 0.9555978277039412, 'reg_alpha': 0.38899439034010186, 'reg_lambda': 6.4784918829974805}. Best is trial 4 with value: 0.5524244732891946.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:32:46,875]\u001b[0m Trial 7 finished with value: 0.507605582645364 and parameters: {'num_leaves': 34, 'max_depth': 4, 'n_estimators': 97, 'class_weight': None, 'min_child_samples': 21, 'subsample': 0.8934487362373625, 'colsample_bytree': 0.7875191259665403, 'reg_alpha': 0.08368599593779102, 'reg_lambda': 7.597772463089295}. Best is trial 4 with value: 0.5524244732891946.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:32:47,208]\u001b[0m Trial 8 finished with value: 0.1088165314844304 and parameters: {'num_leaves': 371, 'max_depth': 3, 'n_estimators': 8, 'class_weight': 'balanced', 'min_child_samples': 28, 'subsample': 0.754072581864881, 'colsample_bytree': 0.7174845716558903, 'reg_alpha': 0.5838154690654517, 'reg_lambda': 4.299204759649972}. Best is trial 4 with value: 0.5524244732891946.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:32:47,665]\u001b[0m Trial 9 finished with value: 0.2754844096892556 and parameters: {'num_leaves': 6, 'max_depth': 6, 'n_estimators': 27, 'class_weight': 'balanced', 'min_child_samples': 43, 'subsample': 0.7097814761419444, 'colsample_bytree': 0.9502276586879499, 'reg_alpha': 0.6569615692336608, 'reg_lambda': 6.411173058762878}. Best is trial 4 with value: 0.5524244732891946.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:32:56,928]\u001b[0m Trial 10 finished with value: 0.6400919775221342 and parameters: {'num_leaves': 14, 'max_depth': 7, 'n_estimators': 1012, 'class_weight': None, 'min_child_samples': 10, 'subsample': 0.9426938469591142, 'colsample_bytree': 0.875254700068784, 'reg_alpha': 0.30107863487041586, 'reg_lambda': 9.970915393571941}. Best is trial 10 with value: 0.6400919775221342.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:33:06,063]\u001b[0m Trial 11 finished with value: 0.6415201254275414 and parameters: {'num_leaves': 14, 'max_depth': 7, 'n_estimators': 1008, 'class_weight': None, 'min_child_samples': 10, 'subsample': 0.9414799122551062, 'colsample_bytree': 0.8627042398787595, 'reg_alpha': 0.30884587700839294, 'reg_lambda': 9.965028725847104}. Best is trial 11 with value: 0.6415201254275414.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:33:21,287]\u001b[0m Trial 12 finished with value: 0.6559098674976582 and parameters: {'num_leaves': 34, 'max_depth': 8, 'n_estimators': 961, 'class_weight': None, 'min_child_samples': 12, 'subsample': 0.9629604106476254, 'colsample_bytree': 0.8555907129095958, 'reg_alpha': 0.35929644694654167, 'reg_lambda': 9.860786669269574}. Best is trial 12 with value: 0.6559098674976582.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:33:30,736]\u001b[0m Trial 13 finished with value: 0.653338680432061 and parameters: {'num_leaves': 68, 'max_depth': 8, 'n_estimators': 389, 'class_weight': None, 'min_child_samples': 11, 'subsample': 0.9974183834550429, 'colsample_bytree': 0.8321284597646001, 'reg_alpha': 0.301811269555277, 'reg_lambda': 9.904355367191599}. Best is trial 12 with value: 0.6559098674976582.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:33:39,776]\u001b[0m Trial 14 finished with value: 0.6419011920252208 and parameters: {'num_leaves': 125, 'max_depth': 10, 'n_estimators': 354, 'class_weight': None, 'min_child_samples': 23, 'subsample': 0.9968042957376287, 'colsample_bytree': 0.8057165635041689, 'reg_alpha': 0.4088346373739281, 'reg_lambda': 0.1917808567778998}. Best is trial 12 with value: 0.6559098674976582.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:33:48,241]\u001b[0m Trial 15 finished with value: 0.6528741519054966 and parameters: {'num_leaves': 91, 'max_depth': 8, 'n_estimators': 402, 'class_weight': None, 'min_child_samples': 14, 'subsample': 0.9509043450932416, 'colsample_bytree': 0.8160456066708981, 'reg_alpha': 0.23431962013234955, 'reg_lambda': 6.1377216287261955}. Best is trial 12 with value: 0.6559098674976582.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:33:57,514]\u001b[0m Trial 16 finished with value: 0.649807156319417 and parameters: {'num_leaves': 88, 'max_depth': 9, 'n_estimators': 402, 'class_weight': None, 'min_child_samples': 21, 'subsample': 0.91271061917722, 'colsample_bytree': 0.7478491926683271, 'reg_alpha': 0.4742003389222805, 'reg_lambda': 9.289884186401988}. Best is trial 12 with value: 0.6559098674976582.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:34:01,426]\u001b[0m Trial 17 finished with value: 0.6319580037579279 and parameters: {'num_leaves': 38, 'max_depth': 8, 'n_estimators': 205, 'class_weight': None, 'min_child_samples': 14, 'subsample': 0.8099989051282457, 'colsample_bytree': 0.8353122414996701, 'reg_alpha': 0.19676974378306727, 'reg_lambda': 7.753262681210569}. Best is trial 12 with value: 0.6559098674976582.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:34:12,237]\u001b[0m Trial 18 finished with value: 0.6392754354263138 and parameters: {'num_leaves': 209, 'max_depth': 8, 'n_estimators': 520, 'class_weight': None, 'min_child_samples': 26, 'subsample': 0.9727477645310242, 'colsample_bytree': 0.8884225180061031, 'reg_alpha': 0.674520807541477, 'reg_lambda': 5.441391382849353}. Best is trial 12 with value: 0.6559098674976582.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:34:13,321]\u001b[0m Trial 19 finished with value: 0.4971893053246784 and parameters: {'num_leaves': 14, 'max_depth': 6, 'n_estimators': 58, 'class_weight': None, 'min_child_samples': 11, 'subsample': 0.8435330898463068, 'colsample_bytree': 0.7707260120663405, 'reg_alpha': 0.3608931977180449, 'reg_lambda': 2.638587342890851}. Best is trial 12 with value: 0.6559098674976582.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: score 0.6559098674976582,\n",
            "params: {'num_leaves': 34, 'max_depth': 8, 'n_estimators': 961, 'class_weight': None, 'min_child_samples': 12, 'subsample': 0.9629604106476254, 'colsample_bytree': 0.8555907129095958, 'reg_alpha': 0.35929644694654167, 'reg_lambda': 9.860786669269574}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:34:24,629]\u001b[0m A new study created in memory with name: no-name-134296e5-335b-4795-abd6-965591df62fe\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------- MG ---------------\n",
            "Train R^2 score is 0.4568\n",
            "Validation R^2 score is 0.4659\n",
            "\n",
            "--------------- P ---------------\n",
            "maximize\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:34:29,373]\u001b[0m Trial 0 finished with value: 0.5428309641412051 and parameters: {'num_leaves': 1022, 'max_depth': 2, 'n_estimators': 731, 'class_weight': 'balanced', 'min_child_samples': 14, 'subsample': 0.9593345780010969, 'colsample_bytree': 0.9050491101094127, 'reg_alpha': 0.9013903188930551, 'reg_lambda': 6.986993561292948}. Best is trial 0 with value: 0.5428309641412051.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:34:55,265]\u001b[0m Trial 1 finished with value: 0.7666982178583996 and parameters: {'num_leaves': 435, 'max_depth': 10, 'n_estimators': 749, 'class_weight': 'balanced', 'min_child_samples': 31, 'subsample': 0.765227005422617, 'colsample_bytree': 0.9086383469732098, 'reg_alpha': 0.23018299031980238, 'reg_lambda': 7.343370881759725}. Best is trial 1 with value: 0.7666982178583996.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:34:57,294]\u001b[0m Trial 2 finished with value: 0.5021388205702255 and parameters: {'num_leaves': 191, 'max_depth': 2, 'n_estimators': 345, 'class_weight': 'balanced', 'min_child_samples': 26, 'subsample': 0.8089066355287067, 'colsample_bytree': 0.7347152233297832, 'reg_alpha': 0.5217393408275086, 'reg_lambda': 2.750073064475711}. Best is trial 1 with value: 0.7666982178583996.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:34:57,964]\u001b[0m Trial 3 finished with value: 0.4419143195691609 and parameters: {'num_leaves': 154, 'max_depth': 6, 'n_estimators': 20, 'class_weight': None, 'min_child_samples': 11, 'subsample': 0.9973016915740203, 'colsample_bytree': 0.8900851131908285, 'reg_alpha': 0.802476021196858, 'reg_lambda': 6.8049591860017165}. Best is trial 1 with value: 0.7666982178583996.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:34:58,270]\u001b[0m Trial 4 finished with value: 0.08127209985463488 and parameters: {'num_leaves': 2, 'max_depth': 7, 'n_estimators': 8, 'class_weight': 'balanced', 'min_child_samples': 47, 'subsample': 0.8265226849624556, 'colsample_bytree': 0.9916509550440045, 'reg_alpha': 0.12340466582290388, 'reg_lambda': 8.862804220330748}. Best is trial 1 with value: 0.7666982178583996.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:35:00,102]\u001b[0m Trial 5 finished with value: 0.6558968871318773 and parameters: {'num_leaves': 97, 'max_depth': 8, 'n_estimators': 50, 'class_weight': None, 'min_child_samples': 14, 'subsample': 0.9869843351228271, 'colsample_bytree': 0.809750709699518, 'reg_alpha': 0.1728496902239185, 'reg_lambda': 1.6384668683036263}. Best is trial 1 with value: 0.7666982178583996.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:35:01,516]\u001b[0m Trial 6 finished with value: 0.5940637886287646 and parameters: {'num_leaves': 157, 'max_depth': 9, 'n_estimators': 30, 'class_weight': None, 'min_child_samples': 36, 'subsample': 0.9923639733219549, 'colsample_bytree': 0.9205218731622028, 'reg_alpha': 0.012930146292185807, 'reg_lambda': 1.6462861637081705}. Best is trial 1 with value: 0.7666982178583996.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:35:06,137]\u001b[0m Trial 7 finished with value: 0.7235690290126127 and parameters: {'num_leaves': 203, 'max_depth': 9, 'n_estimators': 171, 'class_weight': 'balanced', 'min_child_samples': 37, 'subsample': 0.9191560023084696, 'colsample_bytree': 0.7492966705757972, 'reg_alpha': 0.2988376313715533, 'reg_lambda': 1.645693965528524}. Best is trial 1 with value: 0.7666982178583996.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:35:07,903]\u001b[0m Trial 8 finished with value: 0.5889701688253492 and parameters: {'num_leaves': 12, 'max_depth': 7, 'n_estimators': 128, 'class_weight': 'balanced', 'min_child_samples': 19, 'subsample': 0.7470253564469445, 'colsample_bytree': 0.8755572587117549, 'reg_alpha': 0.06590540583049298, 'reg_lambda': 3.6909240778893357}. Best is trial 1 with value: 0.7666982178583996.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:35:08,310]\u001b[0m Trial 9 finished with value: 0.24036400779996975 and parameters: {'num_leaves': 6, 'max_depth': 9, 'n_estimators': 13, 'class_weight': 'balanced', 'min_child_samples': 10, 'subsample': 0.8573387580363635, 'colsample_bytree': 0.9138303753806967, 'reg_alpha': 0.007892520854435925, 'reg_lambda': 1.2925820168087243}. Best is trial 1 with value: 0.7666982178583996.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:35:14,150]\u001b[0m Trial 10 finished with value: 0.6543104955667938 and parameters: {'num_leaves': 924, 'max_depth': 4, 'n_estimators': 514, 'class_weight': 'balanced', 'min_child_samples': 49, 'subsample': 0.7261929011888739, 'colsample_bytree': 0.9932553499262287, 'reg_alpha': 0.45464426270978375, 'reg_lambda': 9.779889348630006}. Best is trial 1 with value: 0.7666982178583996.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:35:20,070]\u001b[0m Trial 11 finished with value: 0.7274668559873527 and parameters: {'num_leaves': 378, 'max_depth': 10, 'n_estimators': 176, 'class_weight': 'balanced', 'min_child_samples': 37, 'subsample': 0.9057559217855364, 'colsample_bytree': 0.718713589862209, 'reg_alpha': 0.34555541597392314, 'reg_lambda': 5.268448955668682}. Best is trial 1 with value: 0.7666982178583996.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:35:28,328]\u001b[0m Trial 12 finished with value: 0.7480708788062136 and parameters: {'num_leaves': 459, 'max_depth': 10, 'n_estimators': 256, 'class_weight': 'balanced', 'min_child_samples': 30, 'subsample': 0.897846328823715, 'colsample_bytree': 0.8143231945752798, 'reg_alpha': 0.3730795536785745, 'reg_lambda': 5.758523010338295}. Best is trial 1 with value: 0.7666982178583996.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:35:34,350]\u001b[0m Trial 13 finished with value: 0.7303068982391364 and parameters: {'num_leaves': 39, 'max_depth': 10, 'n_estimators': 313, 'class_weight': 'balanced', 'min_child_samples': 30, 'subsample': 0.7794843894260843, 'colsample_bytree': 0.809302966670435, 'reg_alpha': 0.6220267875260637, 'reg_lambda': 6.517737773239777}. Best is trial 1 with value: 0.7666982178583996.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:35:42,181]\u001b[0m Trial 14 finished with value: 0.6806871993809676 and parameters: {'num_leaves': 30, 'max_depth': 4, 'n_estimators': 789, 'class_weight': 'balanced', 'min_child_samples': 24, 'subsample': 0.873724298917351, 'colsample_bytree': 0.8256740901786107, 'reg_alpha': 0.2902877981454371, 'reg_lambda': 5.004512659530233}. Best is trial 1 with value: 0.7666982178583996.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:36:18,890]\u001b[0m Trial 15 finished with value: 0.7747164672347465 and parameters: {'num_leaves': 431, 'max_depth': 10, 'n_estimators': 1014, 'class_weight': None, 'min_child_samples': 32, 'subsample': 0.7036012979827777, 'colsample_bytree': 0.9536236494067538, 'reg_alpha': 0.6939402733165729, 'reg_lambda': 8.023144990976599}. Best is trial 15 with value: 0.7747164672347465.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:36:32,118]\u001b[0m Trial 16 finished with value: 0.7244097269902597 and parameters: {'num_leaves': 57, 'max_depth': 5, 'n_estimators': 984, 'class_weight': None, 'min_child_samples': 42, 'subsample': 0.7077666097659603, 'colsample_bytree': 0.9496957945718004, 'reg_alpha': 0.6948783825621576, 'reg_lambda': 8.32671942146157}. Best is trial 15 with value: 0.7747164672347465.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:36:35,049]\u001b[0m Trial 17 finished with value: 0.6870048407303451 and parameters: {'num_leaves': 487, 'max_depth': 8, 'n_estimators': 84, 'class_weight': None, 'min_child_samples': 23, 'subsample': 0.7653845135721622, 'colsample_bytree': 0.953066839579787, 'reg_alpha': 0.992854471297437, 'reg_lambda': 7.986001103304029}. Best is trial 15 with value: 0.7747164672347465.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:36:40,167]\u001b[0m Trial 18 finished with value: 0.6948097141722279 and parameters: {'num_leaves': 14, 'max_depth': 8, 'n_estimators': 487, 'class_weight': None, 'min_child_samples': 32, 'subsample': 0.702356394600949, 'colsample_bytree': 0.8613119424105138, 'reg_alpha': 0.5827562762160348, 'reg_lambda': 9.675714788184312}. Best is trial 15 with value: 0.7747164672347465.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:36:42,224]\u001b[0m Trial 19 finished with value: 0.35245481956413727 and parameters: {'num_leaves': 74, 'max_depth': 1, 'n_estimators': 488, 'class_weight': None, 'min_child_samples': 42, 'subsample': 0.7935307662751858, 'colsample_bytree': 0.9492651408184389, 'reg_alpha': 0.7771293091912157, 'reg_lambda': 3.987205115292684}. Best is trial 15 with value: 0.7747164672347465.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: score 0.7747164672347465,\n",
            "params: {'num_leaves': 431, 'max_depth': 10, 'n_estimators': 1014, 'class_weight': None, 'min_child_samples': 32, 'subsample': 0.7036012979827777, 'colsample_bytree': 0.9536236494067538, 'reg_alpha': 0.6939402733165729, 'reg_lambda': 8.023144990976599}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:36:55,057]\u001b[0m A new study created in memory with name: no-name-ee92a48c-a40e-4eec-befb-3d17f29da00f\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------- P ---------------\n",
            "Train R^2 score is 0.5768\n",
            "Validation R^2 score is 0.5178\n",
            "\n",
            "--------------- B ---------------\n",
            "maximize\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:36:55,474]\u001b[0m Trial 0 finished with value: 0.0407711960647793 and parameters: {'num_leaves': 8, 'max_depth': 8, 'n_estimators': 18, 'class_weight': 'balanced', 'min_child_samples': 38, 'subsample': 0.995780592488503, 'colsample_bytree': 0.7753558115513475, 'reg_alpha': 0.4622562380193632, 'reg_lambda': 0.9601950662161185}. Best is trial 0 with value: 0.0407711960647793.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:37:09,340]\u001b[0m Trial 1 finished with value: 0.22525553561545858 and parameters: {'num_leaves': 479, 'max_depth': 7, 'n_estimators': 727, 'class_weight': None, 'min_child_samples': 30, 'subsample': 0.7221382596728128, 'colsample_bytree': 0.7803863555459272, 'reg_alpha': 0.8102894305375614, 'reg_lambda': 0.8402588220285234}. Best is trial 1 with value: 0.22525553561545858.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:37:10,643]\u001b[0m Trial 2 finished with value: 0.09998906408598665 and parameters: {'num_leaves': 90, 'max_depth': 6, 'n_estimators': 30, 'class_weight': None, 'min_child_samples': 39, 'subsample': 0.7075692809893546, 'colsample_bytree': 0.7962089945246261, 'reg_alpha': 0.6716032986221531, 'reg_lambda': 7.630802146146019}. Best is trial 1 with value: 0.22525553561545858.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:37:11,118]\u001b[0m Trial 3 finished with value: 0.04655197055843687 and parameters: {'num_leaves': 8, 'max_depth': 9, 'n_estimators': 22, 'class_weight': 'balanced', 'min_child_samples': 36, 'subsample': 0.7413524407055326, 'colsample_bytree': 0.8456739692944403, 'reg_alpha': 0.36102261884029596, 'reg_lambda': 9.07331999384568}. Best is trial 1 with value: 0.22525553561545858.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:37:13,565]\u001b[0m Trial 4 finished with value: 0.12171621672657189 and parameters: {'num_leaves': 478, 'max_depth': 3, 'n_estimators': 343, 'class_weight': None, 'min_child_samples': 24, 'subsample': 0.960572910543994, 'colsample_bytree': 0.8865806298767757, 'reg_alpha': 0.3540761228171003, 'reg_lambda': 4.085616437833562}. Best is trial 1 with value: 0.22525553561545858.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:37:15,009]\u001b[0m Trial 5 finished with value: 0.01861914815873662 and parameters: {'num_leaves': 3, 'max_depth': 2, 'n_estimators': 225, 'class_weight': 'balanced', 'min_child_samples': 12, 'subsample': 0.7156338585840318, 'colsample_bytree': 0.8985626323841177, 'reg_alpha': 0.3863747942772603, 'reg_lambda': 8.803283873677469}. Best is trial 1 with value: 0.22525553561545858.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:37:16,286]\u001b[0m Trial 6 finished with value: -0.016005821453703238 and parameters: {'num_leaves': 12, 'max_depth': 7, 'n_estimators': 96, 'class_weight': 'balanced', 'min_child_samples': 49, 'subsample': 0.9024187603103462, 'colsample_bytree': 0.8711203991652557, 'reg_alpha': 0.5661890671741524, 'reg_lambda': 0.1147451087613649}. Best is trial 1 with value: 0.22525553561545858.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:37:20,748]\u001b[0m Trial 7 finished with value: 0.16082991944010255 and parameters: {'num_leaves': 18, 'max_depth': 4, 'n_estimators': 551, 'class_weight': None, 'min_child_samples': 44, 'subsample': 0.9483775830648934, 'colsample_bytree': 0.824806291066169, 'reg_alpha': 0.24385469082198807, 'reg_lambda': 0.7144583863197074}. Best is trial 1 with value: 0.22525553561545858.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:37:23,739]\u001b[0m Trial 8 finished with value: 0.02050812459170661 and parameters: {'num_leaves': 2, 'max_depth': 2, 'n_estimators': 796, 'class_weight': 'balanced', 'min_child_samples': 21, 'subsample': 0.8724615476764583, 'colsample_bytree': 0.7971050296650424, 'reg_alpha': 0.40293947037120137, 'reg_lambda': 0.7680997365184894}. Best is trial 1 with value: 0.22525553561545858.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:37:33,888]\u001b[0m Trial 9 finished with value: -0.21690859005111443 and parameters: {'num_leaves': 88, 'max_depth': 9, 'n_estimators': 340, 'class_weight': 'balanced', 'min_child_samples': 10, 'subsample': 0.7216459246172918, 'colsample_bytree': 0.832069628827627, 'reg_alpha': 0.16817217498622816, 'reg_lambda': 0.20101860270254512}. Best is trial 1 with value: 0.22525553561545858.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:37:34,279]\u001b[0m Trial 10 finished with value: 0.04403329883268894 and parameters: {'num_leaves': 511, 'max_depth': 5, 'n_estimators': 8, 'class_weight': None, 'min_child_samples': 30, 'subsample': 0.7945178265455279, 'colsample_bytree': 0.7163886074942405, 'reg_alpha': 0.915643947337856, 'reg_lambda': 3.5792633821806015}. Best is trial 1 with value: 0.22525553561545858.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:37:42,921]\u001b[0m Trial 11 finished with value: 0.1768377357238581 and parameters: {'num_leaves': 33, 'max_depth': 4, 'n_estimators': 966, 'class_weight': None, 'min_child_samples': 50, 'subsample': 0.824530703561066, 'colsample_bytree': 0.9648167148042792, 'reg_alpha': 0.010282429169297835, 'reg_lambda': 2.3386541743139797}. Best is trial 1 with value: 0.22525553561545858.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:37:54,415]\u001b[0m Trial 12 finished with value: 0.2004736273325256 and parameters: {'num_leaves': 106, 'max_depth': 5, 'n_estimators': 945, 'class_weight': None, 'min_child_samples': 29, 'subsample': 0.7967656050895169, 'colsample_bytree': 0.9857580578986687, 'reg_alpha': 0.021321291941289802, 'reg_lambda': 2.491282278074571}. Best is trial 1 with value: 0.22525553561545858.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:37:57,235]\u001b[0m Trial 13 finished with value: 0.15310424668918188 and parameters: {'num_leaves': 197, 'max_depth': 6, 'n_estimators': 134, 'class_weight': None, 'min_child_samples': 29, 'subsample': 0.7798429423290019, 'colsample_bytree': 0.9989057006422846, 'reg_alpha': 0.954849663881948, 'reg_lambda': 6.156470865803518}. Best is trial 1 with value: 0.22525553561545858.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:38:10,311]\u001b[0m Trial 14 finished with value: 0.24459359130698402 and parameters: {'num_leaves': 964, 'max_depth': 10, 'n_estimators': 421, 'class_weight': None, 'min_child_samples': 22, 'subsample': 0.7670156627044649, 'colsample_bytree': 0.7106808689965187, 'reg_alpha': 0.7604981414376955, 'reg_lambda': 2.3809389624039263}. Best is trial 14 with value: 0.24459359130698402.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:38:16,966]\u001b[0m Trial 15 finished with value: 0.23037836621398716 and parameters: {'num_leaves': 989, 'max_depth': 10, 'n_estimators': 191, 'class_weight': None, 'min_child_samples': 17, 'subsample': 0.7571701427981812, 'colsample_bytree': 0.7037994481776587, 'reg_alpha': 0.7539396626274268, 'reg_lambda': 2.3320163120412594}. Best is trial 14 with value: 0.24459359130698402.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:38:24,650]\u001b[0m Trial 16 finished with value: 0.22943186086577497 and parameters: {'num_leaves': 742, 'max_depth': 10, 'n_estimators': 194, 'class_weight': None, 'min_child_samples': 17, 'subsample': 0.7623966221993517, 'colsample_bytree': 0.7069717350473032, 'reg_alpha': 0.7276458436519884, 'reg_lambda': 5.44258082017693}. Best is trial 14 with value: 0.24459359130698402.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:38:27,478]\u001b[0m Trial 17 finished with value: 0.18847078258834124 and parameters: {'num_leaves': 991, 'max_depth': 10, 'n_estimators': 59, 'class_weight': None, 'min_child_samples': 17, 'subsample': 0.8356887367506094, 'colsample_bytree': 0.7472894370571785, 'reg_alpha': 0.6207443534571787, 'reg_lambda': 2.3512530406277863}. Best is trial 14 with value: 0.24459359130698402.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:38:29,789]\u001b[0m Trial 18 finished with value: 0.17450773568650899 and parameters: {'num_leaves': 241, 'max_depth': 9, 'n_estimators': 67, 'class_weight': None, 'min_child_samples': 23, 'subsample': 0.8842968385520744, 'colsample_bytree': 0.739862625970139, 'reg_alpha': 0.8026956623476804, 'reg_lambda': 3.701357117973374}. Best is trial 14 with value: 0.24459359130698402.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:38:39,981]\u001b[0m Trial 19 finished with value: 0.235422493266673 and parameters: {'num_leaves': 194, 'max_depth': 8, 'n_estimators': 426, 'class_weight': None, 'min_child_samples': 15, 'subsample': 0.7541344263981677, 'colsample_bytree': 0.7417260258444978, 'reg_alpha': 0.8409137252338167, 'reg_lambda': 4.748343913855383}. Best is trial 14 with value: 0.24459359130698402.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: score 0.24459359130698402,\n",
            "params: {'num_leaves': 964, 'max_depth': 10, 'n_estimators': 421, 'class_weight': None, 'min_child_samples': 22, 'subsample': 0.7670156627044649, 'colsample_bytree': 0.7106808689965187, 'reg_alpha': 0.7604981414376955, 'reg_lambda': 2.3809389624039263}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:38:45,174]\u001b[0m A new study created in memory with name: no-name-038cf81a-9d51-4293-b5e1-ff1065e457db\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------- B ---------------\n",
            "Train R^2 score is 0.1043\n",
            "Validation R^2 score is 0.0693\n",
            "\n",
            "--------------- NA ---------------\n",
            "maximize\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:38:45,773]\u001b[0m Trial 0 finished with value: 0.18537239524615037 and parameters: {'num_leaves': 8, 'max_depth': 10, 'n_estimators': 51, 'class_weight': None, 'min_child_samples': 19, 'subsample': 0.8210398309543291, 'colsample_bytree': 0.7813004897560418, 'reg_alpha': 0.09881287406175521, 'reg_lambda': 2.6192221757628453}. Best is trial 0 with value: 0.18537239524615037.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:39:03,515]\u001b[0m Trial 1 finished with value: 0.1485102348222203 and parameters: {'num_leaves': 831, 'max_depth': 9, 'n_estimators': 792, 'class_weight': None, 'min_child_samples': 29, 'subsample': 0.7910928415870301, 'colsample_bytree': 0.7297404430235044, 'reg_alpha': 0.0033142220493213026, 'reg_lambda': 7.580562907409153}. Best is trial 0 with value: 0.18537239524615037.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:39:05,856]\u001b[0m Trial 2 finished with value: 0.0538716470356261 and parameters: {'num_leaves': 2, 'max_depth': 3, 'n_estimators': 540, 'class_weight': 'balanced', 'min_child_samples': 16, 'subsample': 0.7137371782707815, 'colsample_bytree': 0.9830510835827306, 'reg_alpha': 0.3118577824213057, 'reg_lambda': 3.7695886957993197}. Best is trial 0 with value: 0.18537239524615037.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:39:06,572]\u001b[0m Trial 3 finished with value: 0.18777847675712794 and parameters: {'num_leaves': 118, 'max_depth': 9, 'n_estimators': 23, 'class_weight': None, 'min_child_samples': 45, 'subsample': 0.9521363893245978, 'colsample_bytree': 0.7816803669705201, 'reg_alpha': 0.9483625553330098, 'reg_lambda': 3.023832354028931}. Best is trial 3 with value: 0.18777847675712794.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:39:06,913]\u001b[0m Trial 4 finished with value: -0.012206404400534642 and parameters: {'num_leaves': 16, 'max_depth': 8, 'n_estimators': 8, 'class_weight': 'balanced', 'min_child_samples': 14, 'subsample': 0.9729762377872988, 'colsample_bytree': 0.853054014742463, 'reg_alpha': 0.5229391214427149, 'reg_lambda': 3.3795637348600116}. Best is trial 3 with value: 0.18777847675712794.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:39:09,462]\u001b[0m Trial 5 finished with value: 0.2095716500931823 and parameters: {'num_leaves': 14, 'max_depth': 10, 'n_estimators': 240, 'class_weight': None, 'min_child_samples': 16, 'subsample': 0.7584966175483097, 'colsample_bytree': 0.8065227407647771, 'reg_alpha': 0.8108437235603795, 'reg_lambda': 4.697491126164023}. Best is trial 5 with value: 0.2095716500931823.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:39:09,853]\u001b[0m Trial 6 finished with value: 0.03576006650447676 and parameters: {'num_leaves': 438, 'max_depth': 5, 'n_estimators': 9, 'class_weight': 'balanced', 'min_child_samples': 18, 'subsample': 0.8984135616710369, 'colsample_bytree': 0.7640834270748993, 'reg_alpha': 0.659855463498581, 'reg_lambda': 8.63323713425561}. Best is trial 5 with value: 0.2095716500931823.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:39:24,823]\u001b[0m Trial 7 finished with value: 0.13076671662556233 and parameters: {'num_leaves': 226, 'max_depth': 8, 'n_estimators': 735, 'class_weight': None, 'min_child_samples': 20, 'subsample': 0.7678476163393265, 'colsample_bytree': 0.7949681249326555, 'reg_alpha': 0.905549696226914, 'reg_lambda': 2.8459156702917254}. Best is trial 5 with value: 0.2095716500931823.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:39:25,159]\u001b[0m Trial 8 finished with value: 0.04243018469862216 and parameters: {'num_leaves': 4, 'max_depth': 1, 'n_estimators': 21, 'class_weight': 'balanced', 'min_child_samples': 18, 'subsample': 0.807971479099548, 'colsample_bytree': 0.9747651468506134, 'reg_alpha': 0.7758080536165415, 'reg_lambda': 7.192648409415715}. Best is trial 5 with value: 0.2095716500931823.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:39:25,471]\u001b[0m Trial 9 finished with value: 0.06398919119066233 and parameters: {'num_leaves': 83, 'max_depth': 2, 'n_estimators': 12, 'class_weight': 'balanced', 'min_child_samples': 21, 'subsample': 0.9914703364747368, 'colsample_bytree': 0.8784484864390589, 'reg_alpha': 0.43754226440391475, 'reg_lambda': 2.4280487784334204}. Best is trial 5 with value: 0.2095716500931823.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:39:27,686]\u001b[0m Trial 10 finished with value: 0.22267442236308188 and parameters: {'num_leaves': 30, 'max_depth': 6, 'n_estimators': 181, 'class_weight': None, 'min_child_samples': 38, 'subsample': 0.7023413051900845, 'colsample_bytree': 0.909035068641337, 'reg_alpha': 0.6905921672432715, 'reg_lambda': 0.6193067342352263}. Best is trial 10 with value: 0.22267442236308188.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:39:30,234]\u001b[0m Trial 11 finished with value: 0.22972617228261524 and parameters: {'num_leaves': 26, 'max_depth': 6, 'n_estimators': 209, 'class_weight': None, 'min_child_samples': 42, 'subsample': 0.7010046530653782, 'colsample_bytree': 0.9063359832302875, 'reg_alpha': 0.7027834538648795, 'reg_lambda': 0.01959525342905366}. Best is trial 11 with value: 0.22972617228261524.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:39:32,382]\u001b[0m Trial 12 finished with value: 0.23176167364734052 and parameters: {'num_leaves': 34, 'max_depth': 6, 'n_estimators': 168, 'class_weight': None, 'min_child_samples': 44, 'subsample': 0.7092720152596096, 'colsample_bytree': 0.9280776663630528, 'reg_alpha': 0.6481046757134045, 'reg_lambda': 0.18516875868929036}. Best is trial 12 with value: 0.23176167364734052.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:39:33,601]\u001b[0m Trial 13 finished with value: 0.21427125238248204 and parameters: {'num_leaves': 55, 'max_depth': 5, 'n_estimators': 111, 'class_weight': None, 'min_child_samples': 50, 'subsample': 0.7354185488092213, 'colsample_bytree': 0.9306408596605725, 'reg_alpha': 0.5198202266420071, 'reg_lambda': 0.1475496617385421}. Best is trial 12 with value: 0.23176167364734052.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:39:37,663]\u001b[0m Trial 14 finished with value: 0.21716756893726155 and parameters: {'num_leaves': 34, 'max_depth': 6, 'n_estimators': 315, 'class_weight': None, 'min_child_samples': 39, 'subsample': 0.8742005677496855, 'colsample_bytree': 0.9256579281692939, 'reg_alpha': 0.6336257648552275, 'reg_lambda': 1.1775250731109823}. Best is trial 12 with value: 0.23176167364734052.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:39:38,351]\u001b[0m Trial 15 finished with value: 0.19747187050772663 and parameters: {'num_leaves': 9, 'max_depth': 4, 'n_estimators': 60, 'class_weight': None, 'min_child_samples': 35, 'subsample': 0.7361817691096789, 'colsample_bytree': 0.8822736063120092, 'reg_alpha': 0.3330162914153799, 'reg_lambda': 1.6077570066501257}. Best is trial 12 with value: 0.23176167364734052.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:39:40,145]\u001b[0m Trial 16 finished with value: 0.23029158504138197 and parameters: {'num_leaves': 171, 'max_depth': 7, 'n_estimators': 109, 'class_weight': None, 'min_child_samples': 45, 'subsample': 0.8431054295684289, 'colsample_bytree': 0.9461604050846932, 'reg_alpha': 0.8036723147235011, 'reg_lambda': 6.007097809122954}. Best is trial 12 with value: 0.23176167364734052.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:39:42,199]\u001b[0m Trial 17 finished with value: 0.23594821020589202 and parameters: {'num_leaves': 184, 'max_depth': 7, 'n_estimators': 116, 'class_weight': None, 'min_child_samples': 30, 'subsample': 0.85158683508494, 'colsample_bytree': 0.9500395761214919, 'reg_alpha': 0.9852785660926058, 'reg_lambda': 6.202705537013918}. Best is trial 17 with value: 0.23594821020589202.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:39:43,268]\u001b[0m Trial 18 finished with value: 0.2242506767382027 and parameters: {'num_leaves': 255, 'max_depth': 7, 'n_estimators': 44, 'class_weight': None, 'min_child_samples': 27, 'subsample': 0.9173565689655873, 'colsample_bytree': 0.9959159966438877, 'reg_alpha': 0.999625800461912, 'reg_lambda': 5.78507431439947}. Best is trial 17 with value: 0.23594821020589202.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:39:46,381]\u001b[0m Trial 19 finished with value: 0.20747876748138366 and parameters: {'num_leaves': 63, 'max_depth': 3, 'n_estimators': 346, 'class_weight': None, 'min_child_samples': 25, 'subsample': 0.8637706689450926, 'colsample_bytree': 0.9628404564241545, 'reg_alpha': 0.8795585956664713, 'reg_lambda': 9.282441169468733}. Best is trial 17 with value: 0.23594821020589202.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: score 0.23594821020589202,\n",
            "params: {'num_leaves': 184, 'max_depth': 7, 'n_estimators': 116, 'class_weight': None, 'min_child_samples': 30, 'subsample': 0.85158683508494, 'colsample_bytree': 0.9500395761214919, 'reg_alpha': 0.9852785660926058, 'reg_lambda': 6.202705537013918}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:39:47,254]\u001b[0m A new study created in memory with name: no-name-0d859691-0aad-4e5e-94d0-756115fad900\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------- NA ---------------\n",
            "Train R^2 score is 0.0253\n",
            "Validation R^2 score is 0.0082\n",
            "\n",
            "--------------- SAMPLE_TRANSFER_DAY ---------------\n",
            "maximize\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:39:48,195]\u001b[0m Trial 0 finished with value: 0.09555002443340285 and parameters: {'num_leaves': 419, 'max_depth': 1, 'n_estimators': 184, 'class_weight': None, 'min_child_samples': 17, 'subsample': 0.8006735105607549, 'colsample_bytree': 0.8590988704984908, 'reg_alpha': 0.4342213772250284, 'reg_lambda': 9.272941044763353}. Best is trial 0 with value: 0.09555002443340285.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:39:48,505]\u001b[0m Trial 1 finished with value: 0.1453835746848811 and parameters: {'num_leaves': 6, 'max_depth': 4, 'n_estimators': 16, 'class_weight': None, 'min_child_samples': 10, 'subsample': 0.9434541651845194, 'colsample_bytree': 0.7897513580385095, 'reg_alpha': 0.538270529671528, 'reg_lambda': 2.0959809382231054}. Best is trial 1 with value: 0.1453835746848811.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:39:54,633]\u001b[0m Trial 2 finished with value: -0.44434586984371804 and parameters: {'num_leaves': 104, 'max_depth': 6, 'n_estimators': 407, 'class_weight': 'balanced', 'min_child_samples': 37, 'subsample': 0.8573911250656587, 'colsample_bytree': 0.9602149614102553, 'reg_alpha': 0.8969729766465734, 'reg_lambda': 5.739562978686985}. Best is trial 1 with value: 0.1453835746848811.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:39:55,991]\u001b[0m Trial 3 finished with value: 0.2902421881915517 and parameters: {'num_leaves': 370, 'max_depth': 8, 'n_estimators': 47, 'class_weight': None, 'min_child_samples': 40, 'subsample': 0.7303686139305534, 'colsample_bytree': 0.9324546172120565, 'reg_alpha': 0.7475271931964175, 'reg_lambda': 4.622457826976944}. Best is trial 3 with value: 0.2902421881915517.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:39:57,289]\u001b[0m Trial 4 finished with value: 0.22079914402379383 and parameters: {'num_leaves': 958, 'max_depth': 2, 'n_estimators': 215, 'class_weight': None, 'min_child_samples': 19, 'subsample': 0.9119225349260437, 'colsample_bytree': 0.7639138146916258, 'reg_alpha': 0.16111452272673066, 'reg_lambda': 3.9141001991193325}. Best is trial 3 with value: 0.2902421881915517.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:39:58,457]\u001b[0m Trial 5 finished with value: 0.2820422502073277 and parameters: {'num_leaves': 366, 'max_depth': 5, 'n_estimators': 81, 'class_weight': None, 'min_child_samples': 12, 'subsample': 0.8276059842705278, 'colsample_bytree': 0.7970363618165526, 'reg_alpha': 0.6548213904887107, 'reg_lambda': 8.30257871955603}. Best is trial 3 with value: 0.2902421881915517.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:39:59,165]\u001b[0m Trial 6 finished with value: 0.21985207671134313 and parameters: {'num_leaves': 211, 'max_depth': 7, 'n_estimators': 22, 'class_weight': None, 'min_child_samples': 32, 'subsample': 0.7699598887492276, 'colsample_bytree': 0.9705100171864256, 'reg_alpha': 0.7809119894327462, 'reg_lambda': 3.4241801077810763}. Best is trial 3 with value: 0.2902421881915517.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:39:59,788]\u001b[0m Trial 7 finished with value: -0.017755555109227994 and parameters: {'num_leaves': 2, 'max_depth': 3, 'n_estimators': 103, 'class_weight': 'balanced', 'min_child_samples': 42, 'subsample': 0.914983884966075, 'colsample_bytree': 0.8524415865291852, 'reg_alpha': 0.9056089254586941, 'reg_lambda': 4.911778322988333}. Best is trial 3 with value: 0.2902421881915517.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:40:03,634]\u001b[0m Trial 8 finished with value: -0.41727742075687624 and parameters: {'num_leaves': 155, 'max_depth': 5, 'n_estimators': 311, 'class_weight': 'balanced', 'min_child_samples': 39, 'subsample': 0.7068255871821552, 'colsample_bytree': 0.8535563416901196, 'reg_alpha': 0.6684601681600344, 'reg_lambda': 2.954871743744013}. Best is trial 3 with value: 0.2902421881915517.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:40:07,500]\u001b[0m Trial 9 finished with value: 0.38712826990737403 and parameters: {'num_leaves': 112, 'max_depth': 9, 'n_estimators': 142, 'class_weight': None, 'min_child_samples': 24, 'subsample': 0.8457239209582655, 'colsample_bytree': 0.8532258557333876, 'reg_alpha': 0.7950744404991943, 'reg_lambda': 9.250146396682231}. Best is trial 9 with value: 0.38712826990737403.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:40:14,981]\u001b[0m Trial 10 finished with value: 0.40317861686407186 and parameters: {'num_leaves': 15, 'max_depth': 10, 'n_estimators': 776, 'class_weight': None, 'min_child_samples': 26, 'subsample': 0.9902526308924879, 'colsample_bytree': 0.706210451284598, 'reg_alpha': 0.3232564654382749, 'reg_lambda': 7.175211031579293}. Best is trial 10 with value: 0.40317861686407186.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:40:25,178]\u001b[0m Trial 11 finished with value: 0.42028265255962066 and parameters: {'num_leaves': 26, 'max_depth': 10, 'n_estimators': 858, 'class_weight': None, 'min_child_samples': 27, 'subsample': 0.9928107452017729, 'colsample_bytree': 0.707202814374043, 'reg_alpha': 0.2562040508153097, 'reg_lambda': 7.43426479332319}. Best is trial 11 with value: 0.42028265255962066.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:40:33,317]\u001b[0m Trial 12 finished with value: 0.4085516690420211 and parameters: {'num_leaves': 19, 'max_depth': 10, 'n_estimators': 815, 'class_weight': None, 'min_child_samples': 28, 'subsample': 0.9941656174464074, 'colsample_bytree': 0.7017061861007996, 'reg_alpha': 0.23686666858083166, 'reg_lambda': 6.995175928573807}. Best is trial 11 with value: 0.42028265255962066.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:40:45,973]\u001b[0m Trial 13 finished with value: 0.41578119884590753 and parameters: {'num_leaves': 29, 'max_depth': 10, 'n_estimators': 913, 'class_weight': None, 'min_child_samples': 32, 'subsample': 0.9964154747455786, 'colsample_bytree': 0.7024424304094458, 'reg_alpha': 0.012641837160439096, 'reg_lambda': 6.8884774447909765}. Best is trial 11 with value: 0.42028265255962066.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:41:00,879]\u001b[0m Trial 14 finished with value: 0.41743340328754525 and parameters: {'num_leaves': 43, 'max_depth': 8, 'n_estimators': 983, 'class_weight': None, 'min_child_samples': 33, 'subsample': 0.9482038361242444, 'colsample_bytree': 0.7421284230799241, 'reg_alpha': 0.009194156581755653, 'reg_lambda': 6.772205589187797}. Best is trial 11 with value: 0.42028265255962066.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:41:08,088]\u001b[0m Trial 15 finished with value: -0.5557691221113359 and parameters: {'num_leaves': 49, 'max_depth': 8, 'n_estimators': 453, 'class_weight': 'balanced', 'min_child_samples': 49, 'subsample': 0.9380447882997458, 'colsample_bytree': 0.7481758153598814, 'reg_alpha': 0.04653447273967487, 'reg_lambda': 5.922819490760505}. Best is trial 11 with value: 0.42028265255962066.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:41:14,611]\u001b[0m Trial 16 finished with value: 0.3789753497643615 and parameters: {'num_leaves': 8, 'max_depth': 8, 'n_estimators': 1024, 'class_weight': None, 'min_child_samples': 21, 'subsample': 0.9573866782740728, 'colsample_bytree': 0.7404664594716012, 'reg_alpha': 0.19330045416385877, 'reg_lambda': 0.2596272622071014}. Best is trial 11 with value: 0.42028265255962066.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:41:15,033]\u001b[0m Trial 17 finished with value: 0.10973091815028077 and parameters: {'num_leaves': 73, 'max_depth': 7, 'n_estimators': 9, 'class_weight': None, 'min_child_samples': 33, 'subsample': 0.8841755110692204, 'colsample_bytree': 0.8045506751920279, 'reg_alpha': 0.3483824388267594, 'reg_lambda': 8.158010902418015}. Best is trial 11 with value: 0.42028265255962066.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:41:18,003]\u001b[0m Trial 18 finished with value: -0.20128230568695446 and parameters: {'num_leaves': 4, 'max_depth': 9, 'n_estimators': 482, 'class_weight': 'balanced', 'min_child_samples': 46, 'subsample': 0.9648596728288886, 'colsample_bytree': 0.9056660224071431, 'reg_alpha': 0.07778518379538862, 'reg_lambda': 8.11267218710633}. Best is trial 11 with value: 0.42028265255962066.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:41:19,024]\u001b[0m Trial 19 finished with value: 0.306995071437556 and parameters: {'num_leaves': 39, 'max_depth': 9, 'n_estimators': 48, 'class_weight': None, 'min_child_samples': 34, 'subsample': 0.9066155938467622, 'colsample_bytree': 0.7397521164276499, 'reg_alpha': 0.30058944904930174, 'reg_lambda': 6.045068081013577}. Best is trial 11 with value: 0.42028265255962066.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: score 0.42028265255962066,\n",
            "params: {'num_leaves': 26, 'max_depth': 10, 'n_estimators': 858, 'class_weight': None, 'min_child_samples': 27, 'subsample': 0.9928107452017729, 'colsample_bytree': 0.707202814374043, 'reg_alpha': 0.2562040508153097, 'reg_lambda': 7.43426479332319}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:41:22,320]\u001b[0m A new study created in memory with name: no-name-ec5015a7-a8b1-46bf-958f-597dbb8c7f33\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------- SAMPLE_TRANSFER_DAY ---------------\n",
            "Train R^2 score is 0.2234\n",
            "Validation R^2 score is 0.0752\n",
            "\n",
            "--------------- CA ---------------\n",
            "maximize\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:41:22,577]\u001b[0m Trial 0 finished with value: 0.01645404459451818 and parameters: {'num_leaves': 54, 'max_depth': 1, 'n_estimators': 12, 'class_weight': None, 'min_child_samples': 46, 'subsample': 0.8613549155958559, 'colsample_bytree': 0.8381170112839098, 'reg_alpha': 0.561513052468215, 'reg_lambda': 7.246208698528532}. Best is trial 0 with value: 0.01645404459451818.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:41:39,903]\u001b[0m Trial 1 finished with value: 0.280889832076395 and parameters: {'num_leaves': 59, 'max_depth': 9, 'n_estimators': 669, 'class_weight': 'balanced', 'min_child_samples': 38, 'subsample': 0.77665453278455, 'colsample_bytree': 0.9610014653920284, 'reg_alpha': 0.7264758202367543, 'reg_lambda': 9.52112967520108}. Best is trial 1 with value: 0.280889832076395.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:41:40,332]\u001b[0m Trial 2 finished with value: 0.06587949050794237 and parameters: {'num_leaves': 42, 'max_depth': 3, 'n_estimators': 22, 'class_weight': 'balanced', 'min_child_samples': 33, 'subsample': 0.7162491901567049, 'colsample_bytree': 0.811679187245154, 'reg_alpha': 0.893301276021801, 'reg_lambda': 0.7111318214092865}. Best is trial 1 with value: 0.280889832076395.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:41:40,594]\u001b[0m Trial 3 finished with value: 0.01648107814324833 and parameters: {'num_leaves': 4, 'max_depth': 1, 'n_estimators': 12, 'class_weight': None, 'min_child_samples': 13, 'subsample': 0.9591889643787563, 'colsample_bytree': 0.8524603845578338, 'reg_alpha': 0.13187771817549476, 'reg_lambda': 2.2265119846117765}. Best is trial 1 with value: 0.280889832076395.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:41:47,264]\u001b[0m Trial 4 finished with value: 0.2657506693362971 and parameters: {'num_leaves': 35, 'max_depth': 10, 'n_estimators': 395, 'class_weight': 'balanced', 'min_child_samples': 18, 'subsample': 0.7938657061411678, 'colsample_bytree': 0.7477407550048558, 'reg_alpha': 0.13541365994067234, 'reg_lambda': 5.504303273106446}. Best is trial 1 with value: 0.280889832076395.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:41:48,530]\u001b[0m Trial 5 finished with value: 0.19129752025349148 and parameters: {'num_leaves': 32, 'max_depth': 7, 'n_estimators': 53, 'class_weight': None, 'min_child_samples': 47, 'subsample': 0.7057047935952143, 'colsample_bytree': 0.8421893771581994, 'reg_alpha': 0.8793057435412895, 'reg_lambda': 7.028267901275572}. Best is trial 1 with value: 0.280889832076395.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:41:49,585]\u001b[0m Trial 6 finished with value: 0.07358224541323681 and parameters: {'num_leaves': 44, 'max_depth': 1, 'n_estimators': 219, 'class_weight': None, 'min_child_samples': 29, 'subsample': 0.9346960883648043, 'colsample_bytree': 0.9279151951607828, 'reg_alpha': 0.5004042900634114, 'reg_lambda': 9.841864769559036}. Best is trial 1 with value: 0.280889832076395.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:41:49,874]\u001b[0m Trial 7 finished with value: 0.022044445894743615 and parameters: {'num_leaves': 3, 'max_depth': 6, 'n_estimators': 8, 'class_weight': None, 'min_child_samples': 24, 'subsample': 0.9619689782682275, 'colsample_bytree': 0.9304351273919851, 'reg_alpha': 0.8663260095941165, 'reg_lambda': 0.3362640032992037}. Best is trial 1 with value: 0.280889832076395.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:41:50,497]\u001b[0m Trial 8 finished with value: 0.06807739178065701 and parameters: {'num_leaves': 604, 'max_depth': 2, 'n_estimators': 50, 'class_weight': 'balanced', 'min_child_samples': 36, 'subsample': 0.757931017201531, 'colsample_bytree': 0.7491597862805084, 'reg_alpha': 0.6674864171821028, 'reg_lambda': 6.869528538334013}. Best is trial 1 with value: 0.280889832076395.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:41:52,471]\u001b[0m Trial 9 finished with value: 0.17165513599707094 and parameters: {'num_leaves': 11, 'max_depth': 6, 'n_estimators': 149, 'class_weight': 'balanced', 'min_child_samples': 31, 'subsample': 0.7806426335861244, 'colsample_bytree': 0.8831498998538738, 'reg_alpha': 0.6261762090877768, 'reg_lambda': 6.602950256977231}. Best is trial 1 with value: 0.280889832076395.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:42:21,697]\u001b[0m Trial 10 finished with value: 0.3007248392648403 and parameters: {'num_leaves': 305, 'max_depth': 10, 'n_estimators': 926, 'class_weight': 'balanced', 'min_child_samples': 41, 'subsample': 0.8597851209700245, 'colsample_bytree': 0.9698367060082156, 'reg_alpha': 0.29195256530795455, 'reg_lambda': 9.934822684963336}. Best is trial 10 with value: 0.3007248392648403.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:42:49,477]\u001b[0m Trial 11 finished with value: 0.29881321439835623 and parameters: {'num_leaves': 400, 'max_depth': 10, 'n_estimators': 761, 'class_weight': 'balanced', 'min_child_samples': 41, 'subsample': 0.8717836474293912, 'colsample_bytree': 0.9946739776761874, 'reg_alpha': 0.2945281478900803, 'reg_lambda': 9.989497562269758}. Best is trial 10 with value: 0.3007248392648403.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:43:13,280]\u001b[0m Trial 12 finished with value: 0.28143030564927907 and parameters: {'num_leaves': 677, 'max_depth': 8, 'n_estimators': 898, 'class_weight': 'balanced', 'min_child_samples': 41, 'subsample': 0.8859848265225883, 'colsample_bytree': 0.9894588503638984, 'reg_alpha': 0.30053874090446314, 'reg_lambda': 8.989085747214673}. Best is trial 10 with value: 0.3007248392648403.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:43:28,919]\u001b[0m Trial 13 finished with value: 0.27803629541671404 and parameters: {'num_leaves': 203, 'max_depth': 10, 'n_estimators': 378, 'class_weight': 'balanced', 'min_child_samples': 50, 'subsample': 0.905185091852055, 'colsample_bytree': 0.9933392104133079, 'reg_alpha': 0.3402642735526792, 'reg_lambda': 3.577044891830508}. Best is trial 10 with value: 0.3007248392648403.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:43:42,628]\u001b[0m Trial 14 finished with value: 0.27362543385927707 and parameters: {'num_leaves': 234, 'max_depth': 8, 'n_estimators': 513, 'class_weight': 'balanced', 'min_child_samples': 42, 'subsample': 0.8328856307969558, 'colsample_bytree': 0.919180183770583, 'reg_alpha': 0.38333775471992554, 'reg_lambda': 8.550664338504935}. Best is trial 10 with value: 0.3007248392648403.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:43:55,982]\u001b[0m Trial 15 finished with value: 0.22251799068495962 and parameters: {'num_leaves': 219, 'max_depth': 4, 'n_estimators': 1023, 'class_weight': 'balanced', 'min_child_samples': 25, 'subsample': 0.8314515841387693, 'colsample_bytree': 0.9625801515868034, 'reg_alpha': 0.22987895865526717, 'reg_lambda': 8.267685528203359}. Best is trial 10 with value: 0.3007248392648403.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:44:02,755]\u001b[0m Trial 16 finished with value: 0.26501952329363476 and parameters: {'num_leaves': 864, 'max_depth': 9, 'n_estimators': 216, 'class_weight': 'balanced', 'min_child_samples': 42, 'subsample': 0.8995666942755792, 'colsample_bytree': 0.895844810203951, 'reg_alpha': 0.02055594771101793, 'reg_lambda': 4.8146594004306}. Best is trial 10 with value: 0.3007248392648403.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:44:07,053]\u001b[0m Trial 17 finished with value: 0.25926510710024786 and parameters: {'num_leaves': 150, 'max_depth': 10, 'n_estimators': 110, 'class_weight': 'balanced', 'min_child_samples': 38, 'subsample': 0.9987395524404908, 'colsample_bytree': 0.9989329923134735, 'reg_alpha': 0.395508219616761, 'reg_lambda': 9.938906907158385}. Best is trial 10 with value: 0.3007248392648403.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:44:11,200]\u001b[0m Trial 18 finished with value: 0.20980953505931516 and parameters: {'num_leaves': 111, 'max_depth': 5, 'n_estimators': 285, 'class_weight': 'balanced', 'min_child_samples': 45, 'subsample': 0.8641398770470263, 'colsample_bytree': 0.9549881144953107, 'reg_alpha': 0.21319050024202274, 'reg_lambda': 8.254370419559672}. Best is trial 10 with value: 0.3007248392648403.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:44:25,788]\u001b[0m Trial 19 finished with value: 0.27007301883156737 and parameters: {'num_leaves': 387, 'max_depth': 8, 'n_estimators': 576, 'class_weight': 'balanced', 'min_child_samples': 50, 'subsample': 0.8145265708177928, 'colsample_bytree': 0.8874427652712594, 'reg_alpha': 0.03593513194534853, 'reg_lambda': 5.641326370046261}. Best is trial 10 with value: 0.3007248392648403.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: score 0.3007248392648403,\n",
            "params: {'num_leaves': 305, 'max_depth': 10, 'n_estimators': 926, 'class_weight': 'balanced', 'min_child_samples': 41, 'subsample': 0.8597851209700245, 'colsample_bytree': 0.9698367060082156, 'reg_alpha': 0.29195256530795455, 'reg_lambda': 9.934822684963336}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:44:41,276]\u001b[0m A new study created in memory with name: no-name-07f399e7-51c2-496a-a431-0d228af0bc43\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------- CA ---------------\n",
            "Train R^2 score is 0.2181\n",
            "Validation R^2 score is 0.1768\n",
            "\n",
            "--------------- S ---------------\n",
            "maximize\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 19:44:50,539]\u001b[0m Trial 0 finished with value: 0.8826755368793181 and parameters: {'num_leaves': 95, 'max_depth': 4, 'n_estimators': 979, 'class_weight': None, 'min_child_samples': 37, 'subsample': 0.9889358885611741, 'colsample_bytree': 0.759407692318821, 'reg_alpha': 0.01410097313624692, 'reg_lambda': 6.235230525855545}. Best is trial 0 with value: 0.8826755368793181.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:44:53,172]\u001b[0m Trial 1 finished with value: 0.8782435144009181 and parameters: {'num_leaves': 263, 'max_depth': 6, 'n_estimators': 181, 'class_weight': 'balanced', 'min_child_samples': 37, 'subsample': 0.7295177825060782, 'colsample_bytree': 0.7040843363442596, 'reg_alpha': 0.7129600470607999, 'reg_lambda': 2.544116647248591}. Best is trial 0 with value: 0.8826755368793181.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:44:55,416]\u001b[0m Trial 2 finished with value: 0.8741061851678171 and parameters: {'num_leaves': 45, 'max_depth': 10, 'n_estimators': 84, 'class_weight': None, 'min_child_samples': 24, 'subsample': 0.9636204131535171, 'colsample_bytree': 0.9724180768303592, 'reg_alpha': 0.5315100143839305, 'reg_lambda': 4.44074097302738}. Best is trial 0 with value: 0.8826755368793181.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:44:58,630]\u001b[0m Trial 3 finished with value: 0.8544956315553917 and parameters: {'num_leaves': 144, 'max_depth': 3, 'n_estimators': 436, 'class_weight': None, 'min_child_samples': 21, 'subsample': 0.941520921535542, 'colsample_bytree': 0.747795120010238, 'reg_alpha': 0.2865173796594612, 'reg_lambda': 8.470668933244884}. Best is trial 0 with value: 0.8826755368793181.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:44:58,945]\u001b[0m Trial 4 finished with value: 0.4284734860092104 and parameters: {'num_leaves': 561, 'max_depth': 1, 'n_estimators': 10, 'class_weight': None, 'min_child_samples': 22, 'subsample': 0.8404700001826767, 'colsample_bytree': 0.8487501352855118, 'reg_alpha': 0.32097543934635864, 'reg_lambda': 9.085287223999929}. Best is trial 0 with value: 0.8826755368793181.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:44:59,393]\u001b[0m Trial 5 finished with value: 0.7401266516123777 and parameters: {'num_leaves': 3, 'max_depth': 10, 'n_estimators': 46, 'class_weight': None, 'min_child_samples': 26, 'subsample': 0.7176553380737344, 'colsample_bytree': 0.7336146669255029, 'reg_alpha': 0.30716613453787156, 'reg_lambda': 4.889668437426438}. Best is trial 0 with value: 0.8826755368793181.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:45:00,334]\u001b[0m Trial 6 finished with value: 0.7977670744556165 and parameters: {'num_leaves': 5, 'max_depth': 3, 'n_estimators': 73, 'class_weight': 'balanced', 'min_child_samples': 10, 'subsample': 0.9587863566457862, 'colsample_bytree': 0.9275870569609846, 'reg_alpha': 0.43869361573581944, 'reg_lambda': 1.6660872862349296}. Best is trial 0 with value: 0.8826755368793181.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:45:06,748]\u001b[0m Trial 7 finished with value: 0.8961386069083417 and parameters: {'num_leaves': 893, 'max_depth': 10, 'n_estimators': 161, 'class_weight': None, 'min_child_samples': 23, 'subsample': 0.7691422775807989, 'colsample_bytree': 0.7897264605216, 'reg_alpha': 0.6372533557905845, 'reg_lambda': 3.222851565072763}. Best is trial 7 with value: 0.8961386069083417.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:45:11,899]\u001b[0m Trial 8 finished with value: 0.8683584831998623 and parameters: {'num_leaves': 8, 'max_depth': 8, 'n_estimators': 476, 'class_weight': None, 'min_child_samples': 27, 'subsample': 0.9031476562105638, 'colsample_bytree': 0.914172954350476, 'reg_alpha': 0.28777146676087906, 'reg_lambda': 2.586318540058855}. Best is trial 7 with value: 0.8961386069083417.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:45:12,383]\u001b[0m Trial 9 finished with value: 0.5377951878102174 and parameters: {'num_leaves': 107, 'max_depth': 8, 'n_estimators': 11, 'class_weight': None, 'min_child_samples': 40, 'subsample': 0.9708370462363997, 'colsample_bytree': 0.7616948542223412, 'reg_alpha': 0.6694435522753795, 'reg_lambda': 9.034063448812866}. Best is trial 7 with value: 0.8961386069083417.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:45:13,608]\u001b[0m Trial 10 finished with value: 0.7799638247387805 and parameters: {'num_leaves': 742, 'max_depth': 7, 'n_estimators': 27, 'class_weight': 'balanced', 'min_child_samples': 12, 'subsample': 0.7962471354296623, 'colsample_bytree': 0.8249549671122807, 'reg_alpha': 0.8579175267049521, 'reg_lambda': 5.9157933965451}. Best is trial 7 with value: 0.8961386069083417.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:45:22,195]\u001b[0m Trial 11 finished with value: 0.8835119753876718 and parameters: {'num_leaves': 22, 'max_depth': 4, 'n_estimators': 988, 'class_weight': None, 'min_child_samples': 34, 'subsample': 0.7859576464677093, 'colsample_bytree': 0.797824620190491, 'reg_alpha': 0.017315689636406076, 'reg_lambda': 6.318304860992297}. Best is trial 7 with value: 0.8961386069083417.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:45:24,704]\u001b[0m Trial 12 finished with value: 0.8659282750536452 and parameters: {'num_leaves': 16, 'max_depth': 5, 'n_estimators': 221, 'class_weight': None, 'min_child_samples': 32, 'subsample': 0.7826223542395025, 'colsample_bytree': 0.8137141027053939, 'reg_alpha': 0.008543024453246895, 'reg_lambda': 7.185690670487505}. Best is trial 7 with value: 0.8961386069083417.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:45:28,035]\u001b[0m Trial 13 finished with value: 0.7938781102391077 and parameters: {'num_leaves': 27, 'max_depth': 1, 'n_estimators': 1020, 'class_weight': None, 'min_child_samples': 50, 'subsample': 0.7806311692895384, 'colsample_bytree': 0.79693326956808, 'reg_alpha': 0.891175077331902, 'reg_lambda': 0.15032840243667334}. Best is trial 7 with value: 0.8961386069083417.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:45:31,014]\u001b[0m Trial 14 finished with value: 0.8722801332004906 and parameters: {'num_leaves': 45, 'max_depth': 5, 'n_estimators': 211, 'class_weight': None, 'min_child_samples': 16, 'subsample': 0.832496538418921, 'colsample_bytree': 0.8902349883168357, 'reg_alpha': 0.5902617980458004, 'reg_lambda': 3.5860245085062994}. Best is trial 7 with value: 0.8961386069083417.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:45:36,975]\u001b[0m Trial 15 finished with value: 0.8804265139144004 and parameters: {'num_leaves': 13, 'max_depth': 9, 'n_estimators': 489, 'class_weight': 'balanced', 'min_child_samples': 32, 'subsample': 0.7457867883656103, 'colsample_bytree': 0.7933396024199728, 'reg_alpha': 0.137638720396208, 'reg_lambda': 7.023486011327439}. Best is trial 7 with value: 0.8961386069083417.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:45:37,413]\u001b[0m Trial 16 finished with value: 0.6746046130301574 and parameters: {'num_leaves': 307, 'max_depth': 3, 'n_estimators': 21, 'class_weight': None, 'min_child_samples': 45, 'subsample': 0.886228252110931, 'colsample_bytree': 0.8681008307431508, 'reg_alpha': 0.779318440363184, 'reg_lambda': 3.8583216499719732}. Best is trial 7 with value: 0.8961386069083417.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:45:38,051]\u001b[0m Trial 17 finished with value: 0.7488968935075238 and parameters: {'num_leaves': 2, 'max_depth': 7, 'n_estimators': 135, 'class_weight': None, 'min_child_samples': 17, 'subsample': 0.8068415026351351, 'colsample_bytree': 0.7014495552780454, 'reg_alpha': 0.454848051385977, 'reg_lambda': 5.760034037832529}. Best is trial 7 with value: 0.8961386069083417.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:45:42,825]\u001b[0m Trial 18 finished with value: 0.8857685458101683 and parameters: {'num_leaves': 30, 'max_depth': 6, 'n_estimators': 324, 'class_weight': 'balanced', 'min_child_samples': 29, 'subsample': 0.7021349537666611, 'colsample_bytree': 0.8474477817122255, 'reg_alpha': 0.9838396201011912, 'reg_lambda': 7.699180062581684}. Best is trial 7 with value: 0.8961386069083417.\u001b[0m\n",
            "\u001b[32m[I 2022-11-22 19:45:51,360]\u001b[0m Trial 19 finished with value: 0.9002263324528078 and parameters: {'num_leaves': 67, 'max_depth': 9, 'n_estimators': 349, 'class_weight': 'balanced', 'min_child_samples': 18, 'subsample': 0.7008829764463023, 'colsample_bytree': 0.8499523433447692, 'reg_alpha': 0.9573261987641507, 'reg_lambda': 7.768649666460197}. Best is trial 19 with value: 0.9002263324528078.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: score 0.9002263324528078,\n",
            "params: {'num_leaves': 67, 'max_depth': 9, 'n_estimators': 349, 'class_weight': 'balanced', 'min_child_samples': 18, 'subsample': 0.7008829764463023, 'colsample_bytree': 0.8499523433447692, 'reg_alpha': 0.9573261987641507, 'reg_lambda': 7.768649666460197}\n",
            "--------------- S ---------------\n",
            "Train R^2 score is 0.4131\n",
            "Validation R^2 score is 0.4061\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = test.drop(columns=['SN'])\n",
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "aMYiRrce44Ge",
        "outputId": "2abe0230-2f19-406d-9d1f-1b92c4d9ed20"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      COMPONENT_ARBITRARY  ANONYMOUS_1      YEAR  ANONYMOUS_2        AG  \\\n",
              "0                       1    -0.226304  0.592112    -0.340760 -0.150214   \n",
              "1                       3    -0.083512 -0.669043    -0.340760 -0.150214   \n",
              "2                       2    -0.276115 -0.921274    -0.340760 -0.150214   \n",
              "3                       3    -0.413213 -1.173506    -0.340760 -0.150214   \n",
              "4                       2     1.204694 -0.164581    -0.340760 -0.150214   \n",
              "...                   ...          ...       ...          ...       ...   \n",
              "6036                    3    -0.339683  0.087650    -0.340760 -0.150214   \n",
              "6037                    3     0.233617  0.592112    -0.340760 -0.150214   \n",
              "6038                    3     0.279633  0.087650    -0.340760 -0.150214   \n",
              "6039                    2    -0.422701 -0.164581    -0.340760 -0.150214   \n",
              "6040                    1    -0.177679  0.592112     2.199256  5.666438   \n",
              "\n",
              "            CO        CR        CU        FE       H2O        MN        MO  \\\n",
              "0    -0.089633 -0.115388 -0.260252 -0.311651 -0.041588 -0.250456 -0.400998   \n",
              "1    -0.089633 -0.045445 -0.260252  0.187233 -0.041588  0.019051 -0.400998   \n",
              "2    -0.089633 -0.115388 -0.143932 -0.324780 -0.041588 -0.250456 -0.400998   \n",
              "3    -0.089633 -0.010473 -0.236988 -0.028450 -0.041588  0.108886 -0.350857   \n",
              "4    -0.089633 -0.115388 -0.221479 -0.309776 -0.041588 -0.250456 -0.400998   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "6036 -0.089633 -0.010473  0.740102  1.629495 -0.041588  5.588859 -0.317430   \n",
              "6037 -0.089633  0.059471 -0.252497  1.046214 -0.041588  0.198722 -0.400998   \n",
              "6038 -0.089633 -0.115388 -0.268007 -0.234755 -0.041588 -0.250456 -0.400998   \n",
              "6039 -0.089633 -0.115388  0.212784 -0.330406 -0.041588 -0.250456 -0.400998   \n",
              "6040 -0.089633 -0.115388 -0.268007 -0.326655 -0.041588 -0.250456 -0.367571   \n",
              "\n",
              "            NI   PQINDEX        TI        V       V40        ZN  \n",
              "0    -0.191804 -0.265133 -0.102635 -0.10655 -0.363951  0.944762  \n",
              "1    -0.191804  1.516121  0.042348 -0.10655  0.353638 -1.084484  \n",
              "2    -0.191804 -0.264479 -0.102635 -0.10655 -1.311328  0.235748  \n",
              "3    -0.191804  4.968037 -0.102635 -0.10655  0.674134 -0.930269  \n",
              "4    -0.191804 -0.261207 -0.102635 -0.10655 -0.926330 -0.225017  \n",
              "...        ...       ...       ...      ...       ...       ...  \n",
              "6036  0.333602  1.036452 -0.102635 -0.10655 -0.769106  1.080171  \n",
              "6037 -0.191804  0.181816 -0.102635 -0.10655  0.573349 -1.082603  \n",
              "6038 -0.191804 -0.226524 -0.102635 -0.10655  3.887155 -1.082603  \n",
              "6039 -0.191804 -0.268405 -0.102635 -0.10655 -1.174261 -0.208091  \n",
              "6040 -0.191804 -0.262516 -0.102635 -0.10655 -0.591724  0.717201  \n",
              "\n",
              "[6041 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-89eaa189-7a8d-4e79-98f5-f813c0e34c9d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COMPONENT_ARBITRARY</th>\n",
              "      <th>ANONYMOUS_1</th>\n",
              "      <th>YEAR</th>\n",
              "      <th>ANONYMOUS_2</th>\n",
              "      <th>AG</th>\n",
              "      <th>CO</th>\n",
              "      <th>CR</th>\n",
              "      <th>CU</th>\n",
              "      <th>FE</th>\n",
              "      <th>H2O</th>\n",
              "      <th>MN</th>\n",
              "      <th>MO</th>\n",
              "      <th>NI</th>\n",
              "      <th>PQINDEX</th>\n",
              "      <th>TI</th>\n",
              "      <th>V</th>\n",
              "      <th>V40</th>\n",
              "      <th>ZN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.226304</td>\n",
              "      <td>0.592112</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>-0.115388</td>\n",
              "      <td>-0.260252</td>\n",
              "      <td>-0.311651</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>-0.250456</td>\n",
              "      <td>-0.400998</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>-0.265133</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>-0.363951</td>\n",
              "      <td>0.944762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.083512</td>\n",
              "      <td>-0.669043</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>-0.045445</td>\n",
              "      <td>-0.260252</td>\n",
              "      <td>0.187233</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>0.019051</td>\n",
              "      <td>-0.400998</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>1.516121</td>\n",
              "      <td>0.042348</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>0.353638</td>\n",
              "      <td>-1.084484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.276115</td>\n",
              "      <td>-0.921274</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>-0.115388</td>\n",
              "      <td>-0.143932</td>\n",
              "      <td>-0.324780</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>-0.250456</td>\n",
              "      <td>-0.400998</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>-0.264479</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>-1.311328</td>\n",
              "      <td>0.235748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.413213</td>\n",
              "      <td>-1.173506</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>-0.010473</td>\n",
              "      <td>-0.236988</td>\n",
              "      <td>-0.028450</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>0.108886</td>\n",
              "      <td>-0.350857</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>4.968037</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>0.674134</td>\n",
              "      <td>-0.930269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>1.204694</td>\n",
              "      <td>-0.164581</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>-0.115388</td>\n",
              "      <td>-0.221479</td>\n",
              "      <td>-0.309776</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>-0.250456</td>\n",
              "      <td>-0.400998</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>-0.261207</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>-0.926330</td>\n",
              "      <td>-0.225017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6036</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.339683</td>\n",
              "      <td>0.087650</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>-0.010473</td>\n",
              "      <td>0.740102</td>\n",
              "      <td>1.629495</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>5.588859</td>\n",
              "      <td>-0.317430</td>\n",
              "      <td>0.333602</td>\n",
              "      <td>1.036452</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>-0.769106</td>\n",
              "      <td>1.080171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6037</th>\n",
              "      <td>3</td>\n",
              "      <td>0.233617</td>\n",
              "      <td>0.592112</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>0.059471</td>\n",
              "      <td>-0.252497</td>\n",
              "      <td>1.046214</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>0.198722</td>\n",
              "      <td>-0.400998</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>0.181816</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>0.573349</td>\n",
              "      <td>-1.082603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6038</th>\n",
              "      <td>3</td>\n",
              "      <td>0.279633</td>\n",
              "      <td>0.087650</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>-0.115388</td>\n",
              "      <td>-0.268007</td>\n",
              "      <td>-0.234755</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>-0.250456</td>\n",
              "      <td>-0.400998</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>-0.226524</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>3.887155</td>\n",
              "      <td>-1.082603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6039</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.422701</td>\n",
              "      <td>-0.164581</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.150214</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>-0.115388</td>\n",
              "      <td>0.212784</td>\n",
              "      <td>-0.330406</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>-0.250456</td>\n",
              "      <td>-0.400998</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>-0.268405</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>-1.174261</td>\n",
              "      <td>-0.208091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6040</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.177679</td>\n",
              "      <td>0.592112</td>\n",
              "      <td>2.199256</td>\n",
              "      <td>5.666438</td>\n",
              "      <td>-0.089633</td>\n",
              "      <td>-0.115388</td>\n",
              "      <td>-0.268007</td>\n",
              "      <td>-0.326655</td>\n",
              "      <td>-0.041588</td>\n",
              "      <td>-0.250456</td>\n",
              "      <td>-0.367571</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>-0.262516</td>\n",
              "      <td>-0.102635</td>\n",
              "      <td>-0.10655</td>\n",
              "      <td>-0.591724</td>\n",
              "      <td>0.717201</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6041 rows × 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89eaa189-7a8d-4e79-98f5-f813c0e34c9d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-89eaa189-7a8d-4e79-98f5-f813c0e34c9d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-89eaa189-7a8d-4e79-98f5-f813c0e34c9d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_test = copy.deepcopy(test)\n",
        "for col, reg in reg_dict.items():\n",
        "    test[col] = reg.predict(temp_test)\n",
        "\n",
        "X4 = X2.drop(columns=drop_target_list)\n",
        "test = test.drop(columns=list(set(test.columns) & set(drop_target_list)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "fIzKDeN8zRXc",
        "outputId": "27ec2cc2-d3cd-4307-bf09-78fead679f2a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(22314, 24)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      COMPONENT_ARBITRARY  ANONYMOUS_1      YEAR  ANONYMOUS_2        CU  \\\n",
              "0                       1    -0.226304  0.592112    -0.340760 -0.260252   \n",
              "1                       3    -0.083512 -0.669043    -0.340760 -0.260252   \n",
              "2                       2    -0.276115 -0.921274    -0.340760 -0.143932   \n",
              "3                       3    -0.413213 -1.173506    -0.340760 -0.236988   \n",
              "4                       2     1.204694 -0.164581    -0.340760 -0.221479   \n",
              "...                   ...          ...       ...          ...       ...   \n",
              "6036                    3    -0.339683  0.087650    -0.340760  0.740102   \n",
              "6037                    3     0.233617  0.592112    -0.340760 -0.252497   \n",
              "6038                    3     0.279633  0.087650    -0.340760 -0.268007   \n",
              "6039                    2    -0.422701 -0.164581    -0.340760  0.212784   \n",
              "6040                    1    -0.177679  0.592112     2.199256 -0.268007   \n",
              "\n",
              "            FE        MN        NI   PQINDEX       V40  ...        BA  \\\n",
              "0    -0.311651 -0.250456 -0.191804 -0.265133 -0.363951  ...  0.055797   \n",
              "1     0.187233  0.019051 -0.191804  1.516121  0.353638  ...  0.043019   \n",
              "2    -0.324780 -0.250456 -0.191804 -0.264479 -1.311328  ...  0.116648   \n",
              "3    -0.028450  0.108886 -0.191804  4.968037  0.674134  ...  0.135079   \n",
              "4    -0.309776 -0.250456 -0.191804 -0.261207 -0.926330  ...  0.079315   \n",
              "...        ...       ...       ...       ...       ...  ...       ...   \n",
              "6036  1.629495  5.588859  0.333602  1.036452 -0.769106  ...  0.038674   \n",
              "6037  1.046214  0.198722 -0.191804  0.181816  0.573349  ...  0.112377   \n",
              "6038 -0.234755 -0.250456 -0.191804 -0.226524  3.887155  ...  0.230124   \n",
              "6039 -0.330406 -0.250456 -0.191804 -0.268405 -1.174261  ...  0.189227   \n",
              "6040 -0.326655 -0.250456 -0.191804 -0.262516 -0.591724  ...  0.021107   \n",
              "\n",
              "             K        SB        MG         P         B        NA  \\\n",
              "0    -0.035889 -0.042211 -0.019420  0.015864 -0.055288 -0.037761   \n",
              "1    -0.036443 -0.039079 -0.151049 -0.021043  0.030347 -0.033065   \n",
              "2    -0.072055 -0.039252 -0.159362 -0.498529  0.053086 -0.049470   \n",
              "3    -0.042690 -0.030689 -0.159589  0.899772 -0.072943 -0.033763   \n",
              "4    -0.066293 -0.042211 -0.159515 -0.602955 -0.086792 -0.049470   \n",
              "...        ...       ...       ...       ...       ...       ...   \n",
              "6036 -0.034305 -0.031132 -0.136388  0.173202 -0.074085  0.098416   \n",
              "6037 -0.017438 -0.041666 -0.159589 -0.356289  0.073039 -0.032586   \n",
              "6038 -0.071560 -0.036161 -0.159589 -0.234197  0.142459 -0.045417   \n",
              "6039 -0.073518 -0.042211 -0.159515 -0.602397 -0.076221 -0.049470   \n",
              "6040 -0.038999 -0.041796 -0.008616 -0.044623 -0.105898 -0.037761   \n",
              "\n",
              "      SAMPLE_TRANSFER_DAY        CA         S  \n",
              "0               -0.023695 -0.143779 -0.186826  \n",
              "1               -0.064101 -0.251675  0.243825  \n",
              "2               -0.044722 -0.390146 -0.291371  \n",
              "3               -0.036019 -0.255913  0.409802  \n",
              "4               -0.078945 -0.468910 -0.184057  \n",
              "...                   ...       ...       ...  \n",
              "6036            -0.040400  0.211205 -0.089998  \n",
              "6037            -0.062172 -0.239836  0.231019  \n",
              "6038            -0.065732 -0.258209  0.262499  \n",
              "6039            -0.023402 -0.004008 -0.271546  \n",
              "6040             0.082556 -0.310286 -0.186099  \n",
              "\n",
              "[6041 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b9756f14-c107-4a6d-bae3-387094d3b4f0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COMPONENT_ARBITRARY</th>\n",
              "      <th>ANONYMOUS_1</th>\n",
              "      <th>YEAR</th>\n",
              "      <th>ANONYMOUS_2</th>\n",
              "      <th>CU</th>\n",
              "      <th>FE</th>\n",
              "      <th>MN</th>\n",
              "      <th>NI</th>\n",
              "      <th>PQINDEX</th>\n",
              "      <th>V40</th>\n",
              "      <th>...</th>\n",
              "      <th>BA</th>\n",
              "      <th>K</th>\n",
              "      <th>SB</th>\n",
              "      <th>MG</th>\n",
              "      <th>P</th>\n",
              "      <th>B</th>\n",
              "      <th>NA</th>\n",
              "      <th>SAMPLE_TRANSFER_DAY</th>\n",
              "      <th>CA</th>\n",
              "      <th>S</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.226304</td>\n",
              "      <td>0.592112</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.260252</td>\n",
              "      <td>-0.311651</td>\n",
              "      <td>-0.250456</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>-0.265133</td>\n",
              "      <td>-0.363951</td>\n",
              "      <td>...</td>\n",
              "      <td>0.055797</td>\n",
              "      <td>-0.035889</td>\n",
              "      <td>-0.042211</td>\n",
              "      <td>-0.019420</td>\n",
              "      <td>0.015864</td>\n",
              "      <td>-0.055288</td>\n",
              "      <td>-0.037761</td>\n",
              "      <td>-0.023695</td>\n",
              "      <td>-0.143779</td>\n",
              "      <td>-0.186826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.083512</td>\n",
              "      <td>-0.669043</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.260252</td>\n",
              "      <td>0.187233</td>\n",
              "      <td>0.019051</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>1.516121</td>\n",
              "      <td>0.353638</td>\n",
              "      <td>...</td>\n",
              "      <td>0.043019</td>\n",
              "      <td>-0.036443</td>\n",
              "      <td>-0.039079</td>\n",
              "      <td>-0.151049</td>\n",
              "      <td>-0.021043</td>\n",
              "      <td>0.030347</td>\n",
              "      <td>-0.033065</td>\n",
              "      <td>-0.064101</td>\n",
              "      <td>-0.251675</td>\n",
              "      <td>0.243825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.276115</td>\n",
              "      <td>-0.921274</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.143932</td>\n",
              "      <td>-0.324780</td>\n",
              "      <td>-0.250456</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>-0.264479</td>\n",
              "      <td>-1.311328</td>\n",
              "      <td>...</td>\n",
              "      <td>0.116648</td>\n",
              "      <td>-0.072055</td>\n",
              "      <td>-0.039252</td>\n",
              "      <td>-0.159362</td>\n",
              "      <td>-0.498529</td>\n",
              "      <td>0.053086</td>\n",
              "      <td>-0.049470</td>\n",
              "      <td>-0.044722</td>\n",
              "      <td>-0.390146</td>\n",
              "      <td>-0.291371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.413213</td>\n",
              "      <td>-1.173506</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.236988</td>\n",
              "      <td>-0.028450</td>\n",
              "      <td>0.108886</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>4.968037</td>\n",
              "      <td>0.674134</td>\n",
              "      <td>...</td>\n",
              "      <td>0.135079</td>\n",
              "      <td>-0.042690</td>\n",
              "      <td>-0.030689</td>\n",
              "      <td>-0.159589</td>\n",
              "      <td>0.899772</td>\n",
              "      <td>-0.072943</td>\n",
              "      <td>-0.033763</td>\n",
              "      <td>-0.036019</td>\n",
              "      <td>-0.255913</td>\n",
              "      <td>0.409802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>1.204694</td>\n",
              "      <td>-0.164581</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.221479</td>\n",
              "      <td>-0.309776</td>\n",
              "      <td>-0.250456</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>-0.261207</td>\n",
              "      <td>-0.926330</td>\n",
              "      <td>...</td>\n",
              "      <td>0.079315</td>\n",
              "      <td>-0.066293</td>\n",
              "      <td>-0.042211</td>\n",
              "      <td>-0.159515</td>\n",
              "      <td>-0.602955</td>\n",
              "      <td>-0.086792</td>\n",
              "      <td>-0.049470</td>\n",
              "      <td>-0.078945</td>\n",
              "      <td>-0.468910</td>\n",
              "      <td>-0.184057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6036</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.339683</td>\n",
              "      <td>0.087650</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>0.740102</td>\n",
              "      <td>1.629495</td>\n",
              "      <td>5.588859</td>\n",
              "      <td>0.333602</td>\n",
              "      <td>1.036452</td>\n",
              "      <td>-0.769106</td>\n",
              "      <td>...</td>\n",
              "      <td>0.038674</td>\n",
              "      <td>-0.034305</td>\n",
              "      <td>-0.031132</td>\n",
              "      <td>-0.136388</td>\n",
              "      <td>0.173202</td>\n",
              "      <td>-0.074085</td>\n",
              "      <td>0.098416</td>\n",
              "      <td>-0.040400</td>\n",
              "      <td>0.211205</td>\n",
              "      <td>-0.089998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6037</th>\n",
              "      <td>3</td>\n",
              "      <td>0.233617</td>\n",
              "      <td>0.592112</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.252497</td>\n",
              "      <td>1.046214</td>\n",
              "      <td>0.198722</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>0.181816</td>\n",
              "      <td>0.573349</td>\n",
              "      <td>...</td>\n",
              "      <td>0.112377</td>\n",
              "      <td>-0.017438</td>\n",
              "      <td>-0.041666</td>\n",
              "      <td>-0.159589</td>\n",
              "      <td>-0.356289</td>\n",
              "      <td>0.073039</td>\n",
              "      <td>-0.032586</td>\n",
              "      <td>-0.062172</td>\n",
              "      <td>-0.239836</td>\n",
              "      <td>0.231019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6038</th>\n",
              "      <td>3</td>\n",
              "      <td>0.279633</td>\n",
              "      <td>0.087650</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.268007</td>\n",
              "      <td>-0.234755</td>\n",
              "      <td>-0.250456</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>-0.226524</td>\n",
              "      <td>3.887155</td>\n",
              "      <td>...</td>\n",
              "      <td>0.230124</td>\n",
              "      <td>-0.071560</td>\n",
              "      <td>-0.036161</td>\n",
              "      <td>-0.159589</td>\n",
              "      <td>-0.234197</td>\n",
              "      <td>0.142459</td>\n",
              "      <td>-0.045417</td>\n",
              "      <td>-0.065732</td>\n",
              "      <td>-0.258209</td>\n",
              "      <td>0.262499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6039</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.422701</td>\n",
              "      <td>-0.164581</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>0.212784</td>\n",
              "      <td>-0.330406</td>\n",
              "      <td>-0.250456</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>-0.268405</td>\n",
              "      <td>-1.174261</td>\n",
              "      <td>...</td>\n",
              "      <td>0.189227</td>\n",
              "      <td>-0.073518</td>\n",
              "      <td>-0.042211</td>\n",
              "      <td>-0.159515</td>\n",
              "      <td>-0.602397</td>\n",
              "      <td>-0.076221</td>\n",
              "      <td>-0.049470</td>\n",
              "      <td>-0.023402</td>\n",
              "      <td>-0.004008</td>\n",
              "      <td>-0.271546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6040</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.177679</td>\n",
              "      <td>0.592112</td>\n",
              "      <td>2.199256</td>\n",
              "      <td>-0.268007</td>\n",
              "      <td>-0.326655</td>\n",
              "      <td>-0.250456</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>-0.262516</td>\n",
              "      <td>-0.591724</td>\n",
              "      <td>...</td>\n",
              "      <td>0.021107</td>\n",
              "      <td>-0.038999</td>\n",
              "      <td>-0.041796</td>\n",
              "      <td>-0.008616</td>\n",
              "      <td>-0.044623</td>\n",
              "      <td>-0.105898</td>\n",
              "      <td>-0.037761</td>\n",
              "      <td>0.082556</td>\n",
              "      <td>-0.310286</td>\n",
              "      <td>-0.186099</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6041 rows × 24 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9756f14-c107-4a6d-bae3-387094d3b4f0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b9756f14-c107-4a6d-bae3-387094d3b4f0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b9756f14-c107-4a6d-bae3-387094d3b4f0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "Daeas1yt5abT",
        "outputId": "e85cfdb0-7be5-48f1-8380-6dc1897d2105"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       COMPONENT_ARBITRARY  ANONYMOUS_1      YEAR  SAMPLE_TRANSFER_DAY  \\\n",
              "0                        3    -0.393763 -0.669043            -0.051413   \n",
              "1                        2    -0.426022  1.853268             3.715319   \n",
              "2                        3    -0.410367  0.339881            -0.051413   \n",
              "3                        3     0.411276  0.087650            -0.051413   \n",
              "4                        3    -0.468243  1.096575            -0.222628   \n",
              "...                    ...          ...       ...                  ...   \n",
              "22309                    1    -0.189589 -1.662718            -0.142197   \n",
              "22310                    3    -0.209092  0.305027            -0.246288   \n",
              "22311                    3    -0.215672  1.801752            -0.495120   \n",
              "22312                    1    -0.106748 -1.496417            -0.147370   \n",
              "22313                    3     0.937084 -0.343892            -0.209239   \n",
              "\n",
              "       ANONYMOUS_2        AL         B        BA        CA        CU  ...  \\\n",
              "0        -0.340760 -0.111628  0.281646 -0.238453  1.141962  0.336858  ...   \n",
              "1        -0.022576 -0.123127 -0.437686 -0.238453  1.087302 -0.027612  ...   \n",
              "2         0.415608 -0.146124 -0.418245 -0.238453 -0.834591 -0.244743  ...   \n",
              "3        -0.340760 -0.146124 -0.612659 -0.238453 -0.914895  0.701328  ...   \n",
              "4        -0.022576 -0.111628 -0.602938  0.105735  0.646643 -0.268007  ...   \n",
              "...            ...       ...       ...       ...       ...       ...  ...   \n",
              "22309     0.646648  0.624704 -0.565231  0.429113 -0.717098  0.003660  ...   \n",
              "22310    -0.340760 -0.123127 -0.572115  0.354800 -0.745044 -0.140210  ...   \n",
              "22311     2.740946  1.169934 -0.618409 -0.168156 -0.902890 -0.214157  ...   \n",
              "22312    -0.251598  0.101291 -0.077057  0.504764 -0.254774 -0.252497  ...   \n",
              "22313    -0.340760  0.357593 -0.561015  1.627665 -0.876328 -0.181860  ...   \n",
              "\n",
              "             NA        NI         P   PQINDEX         S        SB        SI  \\\n",
              "0      0.672881  1.384414  1.845136  5.293270  1.001652 -0.174727  2.006643   \n",
              "1     -0.164468 -0.191804 -0.598302 -0.259244 -1.170187 -0.174727 -0.179489   \n",
              "2     -0.108644 -0.191804 -1.027099 -0.254663  0.455823 -0.174727 -0.174370   \n",
              "3     -0.108644  0.859008 -0.812700 -0.217362  0.421508 -0.174727 -0.169250   \n",
              "4     -0.164468 -0.191804 -1.089115 -0.180717  0.129828 -0.174727 -0.179489   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "22309 -0.106957  0.062957 -0.015643 -0.262893 -0.825583  0.568990 -0.123017   \n",
              "22310 -0.060535 -0.191804  0.283263 -0.213244 -0.733527 -0.174727 -0.144526   \n",
              "22311 -0.085842 -0.191804 -1.062114 -0.180376  0.571305  1.865800 -0.105939   \n",
              "22312 -0.180111 -0.191804  0.254767 -0.261836 -0.821648  0.088943 -0.134846   \n",
              "22313 -0.140922 -0.191804  0.148236 -0.213101  0.729147 -0.174727 -0.175850   \n",
              "\n",
              "             SN       V40        ZN  \n",
              "0      0.302478  0.899892 -0.966002  \n",
              "1     -0.252439 -1.317376  0.119147  \n",
              "2     -0.252439  0.789028 -1.061916  \n",
              "3     -0.252439  0.631804 -0.939672  \n",
              "4     -0.252439  1.299000 -1.099530  \n",
              "...         ...       ...       ...  \n",
              "22309  0.571548  0.016880  1.019857  \n",
              "22310 -0.013321 -0.941650  1.230105  \n",
              "22311 -0.195770  0.371037 -1.072193  \n",
              "22312  0.302478  0.019453  1.274882  \n",
              "22313 -0.252439  0.347075 -1.080268  \n",
              "\n",
              "[22314 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f100d1e1-567c-4083-b85a-43e4a39f4a0b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COMPONENT_ARBITRARY</th>\n",
              "      <th>ANONYMOUS_1</th>\n",
              "      <th>YEAR</th>\n",
              "      <th>SAMPLE_TRANSFER_DAY</th>\n",
              "      <th>ANONYMOUS_2</th>\n",
              "      <th>AL</th>\n",
              "      <th>B</th>\n",
              "      <th>BA</th>\n",
              "      <th>CA</th>\n",
              "      <th>CU</th>\n",
              "      <th>...</th>\n",
              "      <th>NA</th>\n",
              "      <th>NI</th>\n",
              "      <th>P</th>\n",
              "      <th>PQINDEX</th>\n",
              "      <th>S</th>\n",
              "      <th>SB</th>\n",
              "      <th>SI</th>\n",
              "      <th>SN</th>\n",
              "      <th>V40</th>\n",
              "      <th>ZN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.393763</td>\n",
              "      <td>-0.669043</td>\n",
              "      <td>-0.051413</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.111628</td>\n",
              "      <td>0.281646</td>\n",
              "      <td>-0.238453</td>\n",
              "      <td>1.141962</td>\n",
              "      <td>0.336858</td>\n",
              "      <td>...</td>\n",
              "      <td>0.672881</td>\n",
              "      <td>1.384414</td>\n",
              "      <td>1.845136</td>\n",
              "      <td>5.293270</td>\n",
              "      <td>1.001652</td>\n",
              "      <td>-0.174727</td>\n",
              "      <td>2.006643</td>\n",
              "      <td>0.302478</td>\n",
              "      <td>0.899892</td>\n",
              "      <td>-0.966002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.426022</td>\n",
              "      <td>1.853268</td>\n",
              "      <td>3.715319</td>\n",
              "      <td>-0.022576</td>\n",
              "      <td>-0.123127</td>\n",
              "      <td>-0.437686</td>\n",
              "      <td>-0.238453</td>\n",
              "      <td>1.087302</td>\n",
              "      <td>-0.027612</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.164468</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>-0.598302</td>\n",
              "      <td>-0.259244</td>\n",
              "      <td>-1.170187</td>\n",
              "      <td>-0.174727</td>\n",
              "      <td>-0.179489</td>\n",
              "      <td>-0.252439</td>\n",
              "      <td>-1.317376</td>\n",
              "      <td>0.119147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.410367</td>\n",
              "      <td>0.339881</td>\n",
              "      <td>-0.051413</td>\n",
              "      <td>0.415608</td>\n",
              "      <td>-0.146124</td>\n",
              "      <td>-0.418245</td>\n",
              "      <td>-0.238453</td>\n",
              "      <td>-0.834591</td>\n",
              "      <td>-0.244743</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108644</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>-1.027099</td>\n",
              "      <td>-0.254663</td>\n",
              "      <td>0.455823</td>\n",
              "      <td>-0.174727</td>\n",
              "      <td>-0.174370</td>\n",
              "      <td>-0.252439</td>\n",
              "      <td>0.789028</td>\n",
              "      <td>-1.061916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.411276</td>\n",
              "      <td>0.087650</td>\n",
              "      <td>-0.051413</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.146124</td>\n",
              "      <td>-0.612659</td>\n",
              "      <td>-0.238453</td>\n",
              "      <td>-0.914895</td>\n",
              "      <td>0.701328</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108644</td>\n",
              "      <td>0.859008</td>\n",
              "      <td>-0.812700</td>\n",
              "      <td>-0.217362</td>\n",
              "      <td>0.421508</td>\n",
              "      <td>-0.174727</td>\n",
              "      <td>-0.169250</td>\n",
              "      <td>-0.252439</td>\n",
              "      <td>0.631804</td>\n",
              "      <td>-0.939672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.468243</td>\n",
              "      <td>1.096575</td>\n",
              "      <td>-0.222628</td>\n",
              "      <td>-0.022576</td>\n",
              "      <td>-0.111628</td>\n",
              "      <td>-0.602938</td>\n",
              "      <td>0.105735</td>\n",
              "      <td>0.646643</td>\n",
              "      <td>-0.268007</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.164468</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>-1.089115</td>\n",
              "      <td>-0.180717</td>\n",
              "      <td>0.129828</td>\n",
              "      <td>-0.174727</td>\n",
              "      <td>-0.179489</td>\n",
              "      <td>-0.252439</td>\n",
              "      <td>1.299000</td>\n",
              "      <td>-1.099530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22309</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.189589</td>\n",
              "      <td>-1.662718</td>\n",
              "      <td>-0.142197</td>\n",
              "      <td>0.646648</td>\n",
              "      <td>0.624704</td>\n",
              "      <td>-0.565231</td>\n",
              "      <td>0.429113</td>\n",
              "      <td>-0.717098</td>\n",
              "      <td>0.003660</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.106957</td>\n",
              "      <td>0.062957</td>\n",
              "      <td>-0.015643</td>\n",
              "      <td>-0.262893</td>\n",
              "      <td>-0.825583</td>\n",
              "      <td>0.568990</td>\n",
              "      <td>-0.123017</td>\n",
              "      <td>0.571548</td>\n",
              "      <td>0.016880</td>\n",
              "      <td>1.019857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22310</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.209092</td>\n",
              "      <td>0.305027</td>\n",
              "      <td>-0.246288</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>-0.123127</td>\n",
              "      <td>-0.572115</td>\n",
              "      <td>0.354800</td>\n",
              "      <td>-0.745044</td>\n",
              "      <td>-0.140210</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.060535</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>0.283263</td>\n",
              "      <td>-0.213244</td>\n",
              "      <td>-0.733527</td>\n",
              "      <td>-0.174727</td>\n",
              "      <td>-0.144526</td>\n",
              "      <td>-0.013321</td>\n",
              "      <td>-0.941650</td>\n",
              "      <td>1.230105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22311</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.215672</td>\n",
              "      <td>1.801752</td>\n",
              "      <td>-0.495120</td>\n",
              "      <td>2.740946</td>\n",
              "      <td>1.169934</td>\n",
              "      <td>-0.618409</td>\n",
              "      <td>-0.168156</td>\n",
              "      <td>-0.902890</td>\n",
              "      <td>-0.214157</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.085842</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>-1.062114</td>\n",
              "      <td>-0.180376</td>\n",
              "      <td>0.571305</td>\n",
              "      <td>1.865800</td>\n",
              "      <td>-0.105939</td>\n",
              "      <td>-0.195770</td>\n",
              "      <td>0.371037</td>\n",
              "      <td>-1.072193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22312</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.106748</td>\n",
              "      <td>-1.496417</td>\n",
              "      <td>-0.147370</td>\n",
              "      <td>-0.251598</td>\n",
              "      <td>0.101291</td>\n",
              "      <td>-0.077057</td>\n",
              "      <td>0.504764</td>\n",
              "      <td>-0.254774</td>\n",
              "      <td>-0.252497</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.180111</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>0.254767</td>\n",
              "      <td>-0.261836</td>\n",
              "      <td>-0.821648</td>\n",
              "      <td>0.088943</td>\n",
              "      <td>-0.134846</td>\n",
              "      <td>0.302478</td>\n",
              "      <td>0.019453</td>\n",
              "      <td>1.274882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22313</th>\n",
              "      <td>3</td>\n",
              "      <td>0.937084</td>\n",
              "      <td>-0.343892</td>\n",
              "      <td>-0.209239</td>\n",
              "      <td>-0.340760</td>\n",
              "      <td>0.357593</td>\n",
              "      <td>-0.561015</td>\n",
              "      <td>1.627665</td>\n",
              "      <td>-0.876328</td>\n",
              "      <td>-0.181860</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.140922</td>\n",
              "      <td>-0.191804</td>\n",
              "      <td>0.148236</td>\n",
              "      <td>-0.213101</td>\n",
              "      <td>0.729147</td>\n",
              "      <td>-0.174727</td>\n",
              "      <td>-0.175850</td>\n",
              "      <td>-0.252439</td>\n",
              "      <td>0.347075</td>\n",
              "      <td>-1.080268</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22314 rows × 24 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f100d1e1-567c-4083-b85a-43e4a39f4a0b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f100d1e1-567c-4083-b85a-43e4a39f4a0b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f100d1e1-567c-4083-b85a-43e4a39f4a0b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set(X4.columns) - set(test.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccz8rSP5-y_0",
        "outputId": "c1b05d64-80fb-4d6b-aa85-d29d3db6eda5"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sampler 하나 \n",
        "variable_dict = {\n",
        "    \"categorical_feature\": \"COMPONENT_ARBITRARY\", \n",
        "    \"test_size\": 0.1, \n",
        "    \"learner\": (\"classification\", \"XGB\"), \n",
        "    \"sampler\": (\"hybrid\", \"SMOTEENN\"), \n",
        "    \"random_state_\": 42,\n",
        "    \"dimensionality\": PCA\n",
        "}\n",
        "sec_try = Preprocessing(**variable_dict)\n",
        "print()\n",
        "\n",
        "# 샘플링 그룹핑 스플릿\n",
        "grouped_dic = sec_try.grouping_df(X4, y2, y_column='Y_LABEL')        \n",
        "split_X_y_bundle = first_try.split_X_y_bundle(grouped_dic)\n",
        "\n",
        "print()\n",
        "\n",
        "test_final = pd.DataFrame()\n",
        "\n",
        "for cat, (X_train, X_val, y_train, y_val) in split_X_y_bundle.items():\n",
        "    test_temp = test[test.COMPONENT_ARBITRARY == cat]\n",
        "    test_temp = test_temp.drop(columns=['COMPONENT_ARBITRARY'])\n",
        "\n",
        "    clf = BinaryCalssifier(learner='xgb')\n",
        "\n",
        "    # model training\n",
        "    clf.fit(X_train, y_train, n_trials=20, cv=5)    \n",
        "\n",
        "    # prediction\n",
        "    y_pred = clf.predict(X_val)\n",
        "\n",
        "    # scoring\n",
        "    score = clf.score(y_val, y_pred)\n",
        "    print(\"F1_score is %.4f\" % (score))\n",
        "\n",
        "    # fill prediction value in test data\n",
        "    test_temp['Y_LABEL'] = clf.predict(test_temp)\n",
        "    test_final = pd.concat([test_final, test_temp], axis=0)\n",
        "\n",
        "\n",
        "if 'submission_oil.csv' in os.listdir(save_path):\n",
        "    count = 0\n",
        "    for name in os.listdir(save_path):\n",
        "        if 'submission_oil' in name:\n",
        "            count += 1\n",
        "    filename = f\"submission_oil{count + 1}.csv\"\n",
        "else:\n",
        "    filename = 'submission_oil.csv'\n",
        "\n",
        "# Export submission file\n",
        "submission.Y_LABEL = test_final.Y_LABEL\n",
        "submission.to_csv(save_path + filename, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        },
        "id": "_aw4c75ETzNj",
        "outputId": "db1006f7-830d-4042-b5f7-8838b9570e8c"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-22 21:10:20,227]\u001b[0m A new study created in memory with name: no-name-4204dbd0-d524-448f-b415-e6e1cc0656c0\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "COMPONENT_ARBITRARY\n",
            "dividing my df on 1\n",
            "dividing my df on 2\n",
            "dividing my df on 3\n",
            "dividing my df on 4\n",
            "\n",
            "maximize\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[33m[W 2022-11-22 21:10:39,658]\u001b[0m Trial 0 failed because of the following error: KeyboardInterrupt()\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-50-571448d82f09>\", line 289, in <lambda>\n",
            "    study.optimize(lambda trial : self.objective(trial, X, y, learner, cv), n_trials=n_trials)\n",
            "  File \"<ipython-input-50-571448d82f09>\", line 279, in objective\n",
            "    scores = self.K_fold(model, X, y, cv)\n",
            "  File \"<ipython-input-50-571448d82f09>\", line 224, in K_fold\n",
            "    model.fit(X_train, y_train)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\", line 732, in fit\n",
            "    callbacks=callbacks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/xgboost/training.py\", line 216, in train\n",
            "    xgb_model=xgb_model, callbacks=callbacks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/xgboost/training.py\", line 74, in _train_internal\n",
            "    bst.update(dtrain, i, obj)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/xgboost/core.py\", line 1109, in update\n",
            "    dtrain.handle))\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-28e504c0b8f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# model training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-571448d82f09>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, n_trials, cv, N)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlearner\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearner_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;31m# RF, XGB, LGBM 순서대로 hyper-parameter tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0;31m# Hyper-parameter fix + tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-571448d82f09>\u001b[0m in \u001b[0;36moptimizer\u001b[0;34m(self, X, y, learner, n_trials, cv)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best trial: score {},\\nparams: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         )\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     ):\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-571448d82f09>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best trial: score {},\\nparams: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-571448d82f09>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(self, trial, X, y, learner, cv)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# K-fold cross validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-571448d82f09>\u001b[0m in \u001b[0;36mK_fold\u001b[0;34m(self, model, X, y, cv)\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lt75arsg91Ha"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}